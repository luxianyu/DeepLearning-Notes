{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 词向量运算\n",
    "\n",
    "由于训练词向量计算量非常大，大多数机器学习从业者会加载**预训练词向量**。\n",
    "\n",
    "**完成本作业后，你将能够：**\n",
    "\n",
    "- 加载预训练词向量，并使用余弦相似度（cosine similarity）衡量相似性  \n",
    "- 使用词向量解决类比问题，例如：Man 对应 Woman，King 对应 ______  \n",
    "- 修改词向量以减少性别偏差  \n",
    "\n",
    "让我们开始吧！运行以下代码单元以加载所需的包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- 导入库 ---------------------------- #\n",
    "\n",
    "# os: 用于操作系统相关功能，如文件路径、文件夹操作等\n",
    "import os\n",
    "\n",
    "# urllib.request: 用于从网络下载文件，例如下载数据集或预训练模型\n",
    "import urllib.request\n",
    "\n",
    "# zipfile: 用于解压 zip 文件\n",
    "import zipfile\n",
    "\n",
    "# collections: 提供额外的数据结构工具，如 Counter、defaultdict 等\n",
    "import collections\n",
    "\n",
    "# numpy: 数值计算库，支持多维数组操作、矩阵运算等\n",
    "import numpy as np\n",
    "\n",
    "# torch: PyTorch 核心库，用于张量操作、自动求导和深度学习模型构建\n",
    "import torch\n",
    "\n",
    "# torch.nn: PyTorch 的神经网络模块，包含各种神经网络层、损失函数等\n",
    "import torch.nn as nn\n",
    "\n",
    "# torch.nn.functional: 提供各种函数形式的神经网络操作，如激活函数、卷积操作等\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- 超参数设置 ---------------------------- #\n",
    "\n",
    "# window_size: 上下文窗口大小（Skip-gram 或 CBOW 模型中使用）\n",
    "# - 意味着每个目标词的上下文词的范围为 window_size\n",
    "window_size = 3\n",
    "\n",
    "# vector_dim: 词向量的维度（embedding size）\n",
    "# - 每个词会被映射为一个 300 维的向量\n",
    "vector_dim = 300\n",
    "\n",
    "# epochs: 模型训练轮数\n",
    "# - 表示整个训练数据将被迭代多少次\n",
    "epochs = 1000\n",
    "\n",
    "# ---------------------------- 验证集参数 ---------------------------- #\n",
    "\n",
    "# valid_size: 从词汇表中随机选择多少个词作为验证样本\n",
    "valid_size = 16\n",
    "\n",
    "# valid_window: 从最常出现的前 valid_window 个词中选择验证样本\n",
    "# - 这里设置为 100，意味着从频率最高的 100 个词中随机挑选\n",
    "valid_window = 100\n",
    "\n",
    "# valid_examples: 随机选择 valid_size 个词作为验证样本的索引\n",
    "# - np.random.choice(a, size, replace=False) 从 0~a-1 中随机选择 size 个不重复的索引\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- 数据下载与处理 ---------------------------- #\n",
    "\n",
    "# ----------------------------\n",
    "# 函数: maybe_download\n",
    "# ----------------------------\n",
    "def maybe_download(filename, url, expected_bytes):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "        检查文件是否存在，如果不存在则从指定 URL 下载，并验证文件大小。\n",
    "    \n",
    "    参数：\n",
    "        filename (str): 文件名（下载后保存的本地名称）\n",
    "        url (str): 下载 URL 的前缀\n",
    "        expected_bytes (int): 期望文件大小，用于验证下载是否正确\n",
    "    \n",
    "    返回：\n",
    "        filename (str): 本地文件路径\n",
    "    \"\"\"\n",
    "    # 如果文件不存在，则从网络下载\n",
    "    if not os.path.exists(filename):\n",
    "        filename, _ = urllib.request.urlretrieve(url + filename, filename)\n",
    "    \n",
    "    # 获取文件信息\n",
    "    statinfo = os.stat(filename)\n",
    "    \n",
    "    # 检查文件大小是否匹配\n",
    "    if statinfo.st_size == expected_bytes:\n",
    "        print('Found and verified', filename)\n",
    "    else:\n",
    "        # 文件大小不对，抛出异常\n",
    "        raise Exception(f'Failed to verify {filename}')\n",
    "    \n",
    "    return filename\n",
    "\n",
    "# ----------------------------\n",
    "# 函数: read_data\n",
    "# ----------------------------\n",
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "        读取 zip 文件中的文本数据，并拆分为单词列表。\n",
    "    \n",
    "    参数：\n",
    "        filename (str): 本地 zip 文件路径\n",
    "    \n",
    "    返回：\n",
    "        data (list of str): 文本中的所有单词组成的列表\n",
    "    \"\"\"\n",
    "    # 打开 zip 文件\n",
    "    with zipfile.ZipFile(filename) as f:\n",
    "        # 读取 zip 中的第一个文件，并解码为 utf-8\n",
    "        data = f.read(f.namelist()[0]).decode('utf-8').split()\n",
    "    \n",
    "    return data\n",
    "\n",
    "# ----------------------------\n",
    "# 函数: build_dataset\n",
    "# ----------------------------\n",
    "def build_dataset(words, n_words):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "        构建词汇表和数据集，将单词映射为索引。\n",
    "    \n",
    "    参数：\n",
    "        words (list of str): 文本中所有单词\n",
    "        n_words (int): 词汇表大小（只保留最常用的 n_words 个词，其余标记为 'UNK'）\n",
    "    \n",
    "    返回：\n",
    "        data (list of int): 文本单词对应的索引列表\n",
    "        count (list of [word, count]): 词频统计，首个元素为 'UNK'\n",
    "        dictionary (dict): {word: index} 词到索引的映射\n",
    "        reversed_dictionary (dict): {index: word} 索引到词的映射\n",
    "    \"\"\"\n",
    "    # 初始化 count 列表，首个元素为 'UNK'，-1表示尚未计算的词频\n",
    "    count = [['UNK', -1]]\n",
    "    \n",
    "    # 统计词频，并加入到 count，最多 n_words-1 个\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    \n",
    "    # 构建词到索引的映射字典\n",
    "    dictionary = {word: i for i, (word, _) in enumerate(count)}\n",
    "    \n",
    "    # 将文本中的单词转换为索引\n",
    "    data = []\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 0)  # 如果不在字典中，索引为 0，对应 'UNK'\n",
    "        if index == 0:\n",
    "            unk_count += 1  # 统计未知词数量\n",
    "        data.append(index)\n",
    "    \n",
    "    # 更新 'UNK' 的计数\n",
    "    count[0][1] = unk_count\n",
    "    \n",
    "    # 构建索引到单词的映射\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    \n",
    "    return data, count, dictionary, reversed_dictionary\n",
    "\n",
    "# ----------------------------\n",
    "# 函数: collect_data\n",
    "# ----------------------------\n",
    "def collect_data(vocabulary_size=10000):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "        下载数据集、读取文本、构建词汇表及索引映射。\n",
    "    \n",
    "    参数：\n",
    "        vocabulary_size (int): 词汇表大小，默认为 10000\n",
    "    \n",
    "    返回：\n",
    "        data (list of int): 文本单词对应索引列表\n",
    "        count (list of [word, count]): 词频统计\n",
    "        dictionary (dict): 词到索引映射\n",
    "        reverse_dictionary (dict): 索引到词映射\n",
    "    \"\"\"\n",
    "    # 数据集 URL\n",
    "    url = 'http://mattmahoney.net/dc/'\n",
    "    \n",
    "    # 下载 text8.zip 文件，如果已经存在则直接使用\n",
    "    filename = maybe_download('text8.zip', url, 31344016)\n",
    "    \n",
    "    # 读取文本，得到单词列表\n",
    "    vocabulary = read_data(filename)\n",
    "    print(vocabulary[:7])  # 打印前 7 个单词做检查\n",
    "    \n",
    "    # 构建数据集：索引列表 + 词频统计 + 字典映射\n",
    "    data, count, dictionary, reverse_dictionary = build_dataset(vocabulary, vocabulary_size)\n",
    "    \n",
    "    # 删除原始单词列表，释放内存\n",
    "    del vocabulary\n",
    "    \n",
    "    return data, count, dictionary, reverse_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- GloVe 读取 ---------------------------- #\n",
    "\n",
    "def read_glove_vecs(glove_file):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "        从 GloVe 文件中读取预训练词向量，将每个单词映射为向量。\n",
    "    \n",
    "    参数：\n",
    "        glove_file (str): GloVe 文件路径（例如 'glove.6B.50d.txt'）\n",
    "    \n",
    "    返回：\n",
    "        words (set): 所有单词的集合\n",
    "        word_to_vec_map (dict): {word: vector} 映射字典，vector 为 numpy 数组\n",
    "    \"\"\"\n",
    "\n",
    "    # 用于存储所有单词的集合（避免重复）\n",
    "    words = set()\n",
    "\n",
    "    # 用于存储单词到向量的映射\n",
    "    word_to_vec_map = {}\n",
    "\n",
    "    # 打开 GloVe 文件\n",
    "    # 每一行格式：word val1 val2 val3 ... valN\n",
    "    # encoding='utf-8' 避免中文或特殊符号报错\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            # 去除首尾空格并按空格拆分\n",
    "            line = line.strip().split()\n",
    "\n",
    "            # 第一个元素是单词\n",
    "            curr_word = line[0]\n",
    "\n",
    "            # 将单词加入集合\n",
    "            words.add(curr_word)\n",
    "\n",
    "            # 将剩余元素转换为 numpy 数组，作为该单词的向量表示\n",
    "            # dtype=np.float64 确保浮点精度\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "\n",
    "    return words, word_to_vec_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，让我们加载词向量。  \n",
    "在本作业中，我们将使用 **50 维 GloVe 向量**来表示单词。  \n",
    "运行以下代码单元以加载 `word_to_vec_map`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词向量示例:\n",
      "1. wars: vector shape = (50,)\n",
      "2. bahru: vector shape = (50,)\n",
      "3. one-to-many: vector shape = (50,)\n",
      "4. surinaamse: vector shape = (50,)\n",
      "5. densa: vector shape = (50,)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 读取 GloVe 词向量\n",
    "# ----------------------------\n",
    "\n",
    "# 调用之前定义的 read_glove_vecs 函数\n",
    "# 参数: 'data/glove.6B.50d.txt' 是 GloVe 预训练词向量文件路径\n",
    "# 返回两个变量:\n",
    "#   words: 包含所有单词的集合 (set)，用于快速判断某个单词是否在词向量中\n",
    "#   word_to_vec_map: 字典 {word: vector}，将每个单词映射到对应的 numpy 向量\n",
    "words, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')\n",
    "\n",
    "# 打印前 5 个单词及其向量维度作为示例\n",
    "print(\"词向量示例:\")\n",
    "for i, word in enumerate(list(words)[:5]):\n",
    "    print(f\"{i+1}. {word}: vector shape = {word_to_vec_map[word].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你已经加载了：\n",
    "\n",
    "- `words`：词汇表中的单词集合  \n",
    "- `word_to_vec_map`：将单词映射到其 GloVe 向量表示的字典\n",
    "\n",
    "你已经看到，独热向量（one-hot vectors）并不能很好地捕捉单词之间的相似性。  \n",
    "GloVe 向量能够提供关于单词语义的更有用信息。  \n",
    "现在让我们看看如何使用 GloVe 向量来判断两个单词的相似程度。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - 余弦相似度（Cosine similarity）\n",
    "\n",
    "为了衡量两个单词的相似度，我们需要一种方法来测量它们对应词向量之间的相似程度。  \n",
    "给定两个向量 $u$ 和 $v$，余弦相似度定义如下：\n",
    "\n",
    "$$\\text{CosineSimilarity(u, v)} = \\frac {u \\cdot v} {||u||_2 \\, ||v||_2} = \\cos(\\theta) \\tag{1}$$\n",
    "\n",
    "其中：\n",
    "- $u \\cdot v$ 表示两个向量的点积（或内积）  \n",
    "- $||u||_2$ 是向量 $u$ 的范数（或长度）  \n",
    "- $\\theta$ 是 $u$ 和 $v$ 之间的夹角  \n",
    "\n",
    "该相似度取决于 $u$ 和 $v$ 之间的角度。如果 $u$ 和 $v$ 非常相似，它们的余弦相似度接近 1；如果不相似，余弦相似度会较小。\n",
    "\n",
    "<img src=\"images/cosine_sim.png\" style=\"width:800px;height:250px;\">\n",
    "<caption><center> **图 1**：两个向量夹角的余弦值，用于衡量它们的相似程度</center></caption>\n",
    "\n",
    "**练习**：实现函数 `cosine_similarity()` 来评估词向量之间的相似度。\n",
    "\n",
    "**提示**：向量 $u$ 的范数定义为：\n",
    "$$ ||u||_2 = \\sqrt{\\sum_{i=1}^{n} u_i^2} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- 相似度计算 ---------------------------- #\n",
    "def cosine_similarity(u, v):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "        计算两个向量之间的余弦相似度 (Cosine Similarity)，衡量方向相似性。\n",
    "        在 NLP 中常用于词向量相似度计算。\n",
    "    \n",
    "    参数：\n",
    "        u (numpy.ndarray): 向量 u，任意维度\n",
    "        v (numpy.ndarray): 向量 v，维度须与 u 一致\n",
    "    \n",
    "    返回：\n",
    "        similarity (float): 余弦相似度，取值范围 [-1, 1]\n",
    "            - 1 表示两个向量方向完全相同\n",
    "            - 0 表示两个向量正交（无相似性）\n",
    "            - -1 表示两个向量方向完全相反\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1. 计算点积 u · v\n",
    "    # ----------------------------\n",
    "    dot = np.dot(u, v)\n",
    "    # np.dot(u, v) → u 向量和 v 向量的内积\n",
    "    # 点积越大 → 向量方向越相似\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2. 计算向量的 L2 范数（长度）\n",
    "    # ----------------------------\n",
    "    norm_u = np.linalg.norm(u)  # ||u||\n",
    "    norm_v = np.linalg.norm(v)  # ||v||\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3. 计算余弦相似度\n",
    "    # cosθ = (u·v) / (||u|| * ||v||)\n",
    "    # ----------------------------\n",
    "    return dot / (norm_u * norm_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity(father, mother) =  0.8909038442893615\n",
      "cosine_similarity(ball, crocodile) =  0.2743924626137943\n",
      "cosine_similarity(france - paris, rome - italy) =  -0.6751479308174204\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 词向量示例\n",
    "# ----------------------------\n",
    "\n",
    "# 从 GloVe 词向量字典中获取单词对应向量\n",
    "father = word_to_vec_map[\"father\"]       # \"father\" 的词向量\n",
    "mother = word_to_vec_map[\"mother\"]       # \"mother\" 的词向量\n",
    "ball = word_to_vec_map[\"ball\"]           # \"ball\" 的词向量\n",
    "crocodile = word_to_vec_map[\"crocodile\"] # \"crocodile\" 的词向量\n",
    "france = word_to_vec_map[\"france\"]       # \"france\" 的词向量\n",
    "italy = word_to_vec_map[\"italy\"]         # \"italy\" 的词向量\n",
    "paris = word_to_vec_map[\"paris\"]         # \"paris\" 的词向量\n",
    "rome = word_to_vec_map[\"rome\"]           # \"rome\" 的词向量\n",
    "\n",
    "# ----------------------------\n",
    "# 1. 计算 father 与 mother 的相似度\n",
    "# ----------------------------\n",
    "# 预期结果：相似度较高，因为语义上都是父母相关\n",
    "print(\"cosine_similarity(father, mother) = \", cosine_similarity(father, mother))\n",
    "\n",
    "# ----------------------------\n",
    "# 2. 计算 ball 与 crocodile 的相似度\n",
    "# ----------------------------\n",
    "# 预期结果：相似度较低，因为语义上不相关\n",
    "print(\"cosine_similarity(ball, crocodile) = \", cosine_similarity(ball, crocodile))\n",
    "\n",
    "# ----------------------------\n",
    "# 3. 计算 analogy 示例：france - paris 与 rome - italy\n",
    "# ----------------------------\n",
    "# 解释：\n",
    "#   - \"france - paris\" 表示从法国减去首都信息\n",
    "#   - \"rome - italy\" 表示从罗马减去国家信息\n",
    "#   - 对比向量差的余弦相似度，用于验证词向量能够捕捉国家-首都关系\n",
    "print(\"cosine_similarity(france - paris, rome - italy) = \", \n",
    "      cosine_similarity(france - paris, rome - italy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(father, mother)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         0.890903844289\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(ball, crocodile)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         0.274392462614\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(france - paris, rome - italy)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         -0.675147930817\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在得到正确的预期输出后，你可以自由修改输入，测量其他单词对之间的余弦相似度！  \n",
    "尝试不同输入的余弦相似度可以帮助你更好地理解词向量的行为。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - 词类比任务（Word analogy task）\n",
    "\n",
    "在词类比任务中，我们要完成句子：<font color='brown'>\"*a* is to *b* as *c* is to **____**\"</font>。  \n",
    "一个例子是：<font color='brown'> '*man* is to *woman* as *king* is to *queen*' </font>。  \n",
    "\n",
    "具体来说，我们试图找到一个单词 *d*，使得对应的词向量 $e_a, e_b, e_c, e_d$ 满足关系：\n",
    "\n",
    "$$e_b - e_a \\approx e_d - e_c$$\n",
    "\n",
    "我们将使用余弦相似度来衡量 $e_b - e_a$ 与 $e_d - e_c$ 之间的相似性。\n",
    "\n",
    "**练习**：完成下面的代码，实现词类比任务！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 类比问题求解函数\n",
    "# ----------------------------\n",
    "def complete_analogy(word_a, word_b, word_c, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "        给定三个单词 word_a, word_b, word_c，找到最符合类比关系 \"a:b :: c:?\" 的单词。\n",
    "        例如: \"man:king :: woman:?\" → 答案应该是 \"queen\"\n",
    "    \n",
    "    参数：\n",
    "        word_a (str): 单词 a\n",
    "        word_b (str): 单词 b\n",
    "        word_c (str): 单词 c\n",
    "        word_to_vec_map (dict): 词向量字典 {word: vector}\n",
    "    \n",
    "    返回：\n",
    "        best_word (str): 最符合类比关系的单词\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1. 转为小写，保证大小写不影响查找\n",
    "    # ----------------------------\n",
    "    word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2. 获取三个单词对应的词向量\n",
    "    # ----------------------------\n",
    "    e_a, e_b, e_c = word_to_vec_map[word_a], word_to_vec_map[word_b], word_to_vec_map[word_c]\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3. 遍历所有单词，寻找最匹配的类比\n",
    "    # ----------------------------\n",
    "    words = word_to_vec_map.keys()  # 获取所有单词\n",
    "    max_cosine_sim = -100           # 初始化最大余弦相似度为很小的值\n",
    "    best_word = None                # 初始化最佳单词为空\n",
    "\n",
    "    for word in words:\n",
    "        # 跳过输入的三个单词，避免自己匹配自己\n",
    "        if word in [word_a, word_b, word_c]:\n",
    "            continue\n",
    "\n",
    "        # 计算余弦相似度\n",
    "        # 类比公式: vec_b - vec_a ≈ vec_best - vec_c → vec_best ≈ vec_c + (vec_b - vec_a)\n",
    "        # 实际计算余弦相似度: cos((b - a), (word - c))\n",
    "        cosine_sim = cosine_similarity(e_b - e_a, word_to_vec_map[word] - e_c)\n",
    "\n",
    "        # 如果相似度更大，则更新最佳单词\n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = word\n",
    "\n",
    "    # 返回找到的最佳单词\n",
    "    return best_word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下方代码单元以测试你的代码，这可能需要 1-2 分钟。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italy -> italian :: spain -> spanish\n",
      "india -> delhi :: japan -> tokyo\n",
      "man -> woman :: boy -> girl\n",
      "small -> smaller :: large -> larger\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 类比实验：测试多个三元组\n",
    "# ----------------------------\n",
    "\n",
    "# triads_to_try: 待测试的三元组列表，每个三元组格式 (word_a, word_b, word_c)\n",
    "# 意思是求 \"a : b :: c : ?\" 的类比结果\n",
    "triads_to_try = [\n",
    "    ('italy', 'italian', 'spain'),   # 意大利:意大利语 :: 西班牙: ?\n",
    "    ('india', 'delhi', 'japan'),     # 印度:德里 :: 日本: ?\n",
    "    ('man', 'woman', 'boy'),         # 男人:女人 :: 男孩: ?\n",
    "    ('small', 'smaller', 'large')    # 小:更小 :: 大: ?\n",
    "]\n",
    "\n",
    "# 遍历每个三元组，调用 complete_analogy() 找出最符合类比的单词\n",
    "for triad in triads_to_try:\n",
    "    # *triad 将三元组拆开作为函数参数传入\n",
    "    result_word = complete_analogy(*triad, word_to_vec_map)\n",
    "\n",
    "    # 格式化输出：a -> b :: c -> 预测结果\n",
    "    print('{} -> {} :: {} -> {}'.format(*triad, result_word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **italy -> italian** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         spain -> spanish\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **india -> delhi** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         japan -> tokyo\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **man -> woman ** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         boy -> girl\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **small -> smaller ** ::\n",
    "        </td>\n",
    "        <td>\n",
    "         large -> larger\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在得到正确的预期输出后，你可以自由修改上方的输入单元，测试你自己的类比题。  \n",
    "尝试找到一些算法能够正确解决的类比对，也尝试一些算法无法给出正确答案的类比，例如：small -> smaller as big -> ?。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 恭喜！\n",
    "\n",
    "你已经完成了本次作业。以下是你需要记住的主要内容：\n",
    "\n",
    "- **余弦相似度**是比较词向量对相似性的一种有效方法。（虽然 L2 距离也可用）  \n",
    "- 对于 NLP 应用，从网上获取预训练的词向量通常是一个很好的起点。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - 消除词向量偏差\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在接下来的练习中，你将观察词向量中可能反映出的性别偏差，并探索减少偏差的算法。  \n",
    "除了学习去偏置（debiasing）相关知识外，这个练习还能帮助你加深对词向量行为的直观理解。  \n",
    "\n",
    "本部分涉及一些线性代数知识，但即使你不是线性代数专家，也可以完成练习，我们鼓励你尝试。\n",
    "\n",
    "首先，让我们看看 GloVe 词向量是如何与性别相关的。  \n",
    "你将首先计算向量：\n",
    "\n",
    "$$g = e_{woman} - e_{man}$$\n",
    "\n",
    "其中，$e_{woman}$ 表示单词 *woman* 的词向量，$e_{man}$ 表示单词 *man* 的词向量。  \n",
    "得到的向量 $g$ 大致编码了“性别”这一概念。（如果你计算 $g_1 = e_{mother}-e_{father}$、$g_2 = e_{girl}-e_{boy}$ 等并取平均，可能会得到更准确的表示，但仅使用 $e_{woman}-e_{man}$ 对当前练习来说已经足够。）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.087144    0.2182     -0.40986    -0.03922    -0.1032      0.94165\n",
      " -0.06042     0.32988     0.46144    -0.35962     0.31102    -0.86824\n",
      "  0.96006     0.01073     0.24337     0.08193    -1.02722    -0.21122\n",
      "  0.695044   -0.00222     0.29106     0.5053     -0.099454    0.40445\n",
      "  0.30181     0.1355     -0.0606     -0.07131    -0.19245    -0.06115\n",
      " -0.3204      0.07165    -0.13337    -0.25068714 -0.14293    -0.224957\n",
      " -0.149       0.048882    0.12191    -0.27362    -0.165476   -0.20426\n",
      "  0.54376    -0.271425   -0.10245    -0.32108     0.2516     -0.33455\n",
      " -0.04371     0.01258   ]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 计算词向量差\n",
    "# ----------------------------\n",
    "\n",
    "# 计算向量差 g = vec(woman) - vec(man)\n",
    "# 这个向量 g 捕捉了 “从 man 到 woman 的语义方向”\n",
    "g = word_to_vec_map['woman'] - word_to_vec_map['man']\n",
    "\n",
    "# 打印向量 g\n",
    "# 输出是一个 numpy 数组，长度等于词向量维度（例如 50、100、300）\n",
    "# 每个元素表示在该维度上 woman 相对于 man 的向量差\n",
    "print(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，你将考虑不同单词与向量 $g$ 的余弦相似度。  \n",
    "请思考余弦相似度为正值意味着什么，以及为负值又意味着什么。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of names and their similarities with constructed vector:\n",
      "john -0.23163356145973724\n",
      "marie 0.315597935396073\n",
      "sophie 0.31868789859418784\n",
      "ronaldo -0.3124479685032943\n",
      "priya 0.17632041839009402\n",
      "rahul -0.1691547103923172\n",
      "danielle 0.24393299216283895\n",
      "reza -0.07930429672199552\n",
      "katy 0.2831068659572615\n",
      "yasmin 0.23313857767928758\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 输出与构建向量 g 相似度的名字列表\n",
    "# ----------------------------\n",
    "\n",
    "print('List of names and their similarities with constructed vector:')\n",
    "\n",
    "# name_list: 待比较的名字列表，可以包含男性、女性或其他名字\n",
    "name_list = ['john', 'marie', 'sophie', 'ronaldo', 'priya', 'rahul', 'danielle', 'reza', 'katy', 'yasmin']\n",
    "\n",
    "# 遍历每个名字，计算其词向量与向量 g 的余弦相似度\n",
    "for w in name_list:\n",
    "    # word_to_vec_map[w]: 获取名字 w 的词向量\n",
    "    # g: 之前计算的向量差 g = vec('woman') - vec('man')\n",
    "    # cosine_similarity(u, v): 计算两个向量的余弦相似度\n",
    "    sim = cosine_similarity(word_to_vec_map[w], g)\n",
    "    \n",
    "    # 打印名字和相似度\n",
    "    # 余弦相似度越接近 1，说明该名字的词向量方向与 g 越接近\n",
    "    print(w, sim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如你所见，女性名字的余弦相似度通常与我们构建的向量 $g$ 为正，而男性名字通常为负。  \n",
    "这并不令人惊讶，结果看起来也可以接受。\n",
    "\n",
    "接下来，让我们尝试一些其他单词。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other words and their similarities:\n",
      "lipstick 0.27691916256382665\n",
      "guns -0.1888485567898898\n",
      "science -0.060829065409296994\n",
      "arts 0.008189312385880328\n",
      "literature 0.06472504433459927\n",
      "warrior -0.20920164641125288\n",
      "doctor 0.11895289410935041\n",
      "tree -0.07089399175478091\n",
      "receptionist 0.33077941750593737\n",
      "technology -0.131937324475543\n",
      "fashion 0.03563894625772699\n",
      "teacher 0.17920923431825664\n",
      "engineer -0.08039280494524072\n",
      "pilot 0.001076449899191679\n",
      "computer -0.10330358873850498\n",
      "singer 0.1850051813649629\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 输出其他单词与向量 g 的相似度\n",
    "# ----------------------------\n",
    "\n",
    "print('Other words and their similarities:')\n",
    "\n",
    "# word_list: 待比较的词列表，可以包含职业、物品、概念等\n",
    "word_list = [\n",
    "    'lipstick', 'guns', 'science', 'arts', 'literature', 'warrior',\n",
    "    'doctor', 'tree', 'receptionist', 'technology', 'fashion', \n",
    "    'teacher', 'engineer', 'pilot', 'computer', 'singer'\n",
    "]\n",
    "\n",
    "# 遍历每个单词，计算其词向量与向量 g 的余弦相似度\n",
    "for w in word_list:\n",
    "    # word_to_vec_map[w]: 获取单词 w 的词向量\n",
    "    # g: 之前计算的向量差 g = vec('woman') - vec('man')\n",
    "    # cosine_similarity(u, v): 计算两个向量的余弦相似度\n",
    "    sim = cosine_similarity(word_to_vec_map[w], g)\n",
    "    \n",
    "    # 打印单词和相似度\n",
    "    # 余弦相似度越接近 1，说明该词向量方向与 g 越接近\n",
    "    print(w, sim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你注意到什么令人惊讶的现象了吗？这些结果惊人地反映了某些不健康的性别刻板印象。例如，“computer”更接近“man”，而“literature”更接近“woman”。哎呀！\n",
    "\n",
    "下面我们将展示如何使用 [Bolukbasi et al., 2016](https://arxiv.org/abs/1607.06520) 的算法来减少这些向量的偏差。  \n",
    "注意，有些词对（如 \"actor\"/\"actress\" 或 \"grandmother\"/\"grandfather\"）应保持性别特定，而其他词（如 \"receptionist\" 或 \"technology\"）应被中性化，即不再与性别相关。去偏置时，需要对这两类词采取不同的处理方式。\n",
    "\n",
    "### 3.1 - 对非性别特定词进行中性化\n",
    "\n",
    "下图有助于你理解中性化操作的效果。  \n",
    "如果你使用的是 50 维词向量，50 维空间可以分为两部分：  \n",
    "- 偏置方向 $g$  \n",
    "- 剩余 49 维，我们称之为 $g_{\\perp}$  \n",
    "\n",
    "在线性代数中，$g_{\\perp}$ 与 $g$ 垂直（或“正交”），即两者夹角为 90 度。  \n",
    "中性化步骤将诸如 $e_{receptionist}$ 的向量在 $g$ 方向上的分量置零，从而得到 $e_{receptionist}^{debiased}$。\n",
    "\n",
    "虽然 $g_{\\perp}$ 是 49 维的，但由于屏幕绘图的限制，我们使用 1 维轴来示意。\n",
    "\n",
    "<img src=\"images/neutral.png\" style=\"width:800px;height:300px;\">\n",
    "<caption><center> **图 2**：“receptionist”的词向量，在应用中性化操作前后表示。</center></caption>\n",
    "\n",
    "**练习**：实现 `neutralize()`，去除诸如 \"receptionist\" 或 \"scientist\" 等词的偏差。  \n",
    "给定输入嵌入 $e$，你可以使用以下公式计算 $e^{debiased}$：\n",
    "\n",
    "$$e^{bias\\_component} = \\frac{e \\cdot g}{||g||_2^2} * g\\tag{2}$$\n",
    "$$e^{debiased} = e - e^{bias\\_component}\\tag{3}$$\n",
    "\n",
    "如果你是线性代数专家，你可能会认出 $e^{bias\\_component}$ 是 $e$ 在 $g$ 方向上的投影。  \n",
    "如果不是专家，也无需担心。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 词向量偏差消除（Neutralize）\n",
    "# ----------------------------\n",
    "\n",
    "def neutralize(word, g, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "        对单词的词向量进行性别偏差消除（neutralize）。\n",
    "        将词向量中沿着性别方向 g 的分量去除，使其与性别无关。\n",
    "    \n",
    "    参数：\n",
    "        word (str): 待处理的单词\n",
    "        g (np.array): 性别方向向量（通常 g = vec('woman') - vec('man')）\n",
    "        word_to_vec_map (dict): 单词到词向量的映射字典\n",
    "    \n",
    "    返回：\n",
    "        e_debiased (np.array): 去除性别偏差后的词向量\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1. 获取单词的原始词向量\n",
    "    # ----------------------------\n",
    "    e = word_to_vec_map[word]\n",
    "    # e: shape = (vector_dim,)，例如 (300,)\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2. 计算沿性别方向 g 的分量\n",
    "    # ----------------------------\n",
    "    # np.dot(e, g) -> 计算 e 在 g 方向的投影长度\n",
    "    # np.linalg.norm(g)**2 -> g 的平方模，用于归一化\n",
    "    # * g -> 投影向量，即 e 在 g 方向上的成分\n",
    "    e_biascomponent = np.dot(e, g) / np.square(np.linalg.norm(g)) * g\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3. 去除偏差分量\n",
    "    # ----------------------------\n",
    "    # 原始词向量减去性别方向上的分量\n",
    "    e_debiased = e - e_biascomponent\n",
    "\n",
    "    # 返回去偏后的词向量\n",
    "    return e_debiased\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity between receptionist and g, before neutralizing:  0.33077941750593737\n",
      "cosine similarity between receptionist and g, after neutralizing:  1.1682064664487028e-17\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 性别偏差消除示例\n",
    "# ----------------------------\n",
    "\n",
    "# 定义待处理的单词\n",
    "e = \"receptionist\"\n",
    "\n",
    "# ----------------------------\n",
    "# 1. 计算并打印去偏前的词向量与性别方向 g 的相似度\n",
    "# ----------------------------\n",
    "# word_to_vec_map[\"receptionist\"]: 获取 \"receptionist\" 的原始词向量\n",
    "# cosine_similarity(..., g): 计算词向量与性别方向向量 g 的余弦相似度\n",
    "print(\"cosine similarity between \" + e + \" and g, before neutralizing: \", \n",
    "      cosine_similarity(word_to_vec_map[\"receptionist\"], g))\n",
    "# 余弦相似度越接近 1，说明原词向量沿性别方向偏差越明显\n",
    "\n",
    "# ----------------------------\n",
    "# 2. 对词向量进行性别偏差消除\n",
    "# ----------------------------\n",
    "# 调用 neutralize 函数，将词向量中沿性别方向 g 的分量去除\n",
    "e_debiased = neutralize(\"receptionist\", g, word_to_vec_map)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. 计算并打印去偏后的词向量与性别方向 g 的相似度\n",
    "# ----------------------------\n",
    "# 此时余弦相似度应接近 0，说明性别方向成分已被去除\n",
    "print(\"cosine similarity between \" + e + \" and g, after neutralizing: \", \n",
    "      cosine_similarity(e_debiased, g))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: The second result is essentially 0, up to numerical roundof (on the order of $10^{-17}$).\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **cosine similarity between receptionist and g, before neutralizing:** :\n",
    "        </td>\n",
    "        <td>\n",
    "         0.330779417506\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **cosine similarity between receptionist and g, after neutralizing:** :\n",
    "        </td>\n",
    "        <td>\n",
    "         -3.26732746085e-17\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - 针对性别特定词的均衡算法（Equalization）\n",
    "\n",
    "接下来，让我们看看去偏置如何应用于诸如 \"actress\" 和 \"actor\" 这类词对。  \n",
    "均衡算法应用于那些你希望仅在性别属性上有所差异的词对。  \n",
    "\n",
    "具体例子：假设 \"actress\" 比 \"actor\" 更接近 \"babysit\"。通过对 \"babysit\" 进行中性化操作，可以减少与性别刻板印象相关的偏差。但这仍无法保证 \"actor\" 和 \"actress\" 到 \"babysit\" 的距离相等。均衡算法可以解决这一问题。\n",
    "\n",
    "均衡算法的关键思想是确保特定词对在 49 维 $g_\\perp$ 空间中等距分布。  \n",
    "均衡步骤还确保两个经过均衡的词与 $e_{receptionist}^{debiased}$ 或其他已中性化词保持相同距离。  \n",
    "\n",
    "下图展示了均衡操作的原理：\n",
    "\n",
    "<img src=\"images/equalize10.png\" style=\"width:800px;height:400px;\">\n",
    "\n",
    "线性代数的推导稍微复杂一些。（详细内容请参见 Bolukbasi et al., 2016。）  \n",
    "关键方程如下：\n",
    "\n",
    "$$ \\mu = \\frac{e_{w1} + e_{w2}}{2}\\tag{4}$$ \n",
    "\n",
    "$$\n",
    "\\mu_B = \\frac{\\mu \\cdot \\text{bias\\_axis}}{||\\text{bias\\_axis}||_2^2} \\cdot \\text{bias\\_axis} \\tag{5}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\\mu_{\\perp} = \\mu - \\mu_{B} \\tag{6}$$\n",
    "\n",
    "$$e_{w1B} = \\sqrt{ |{1 - ||\\mu_{\\perp} ||^2_2} |} * \\frac{(e_{\\text{w1}} - \\mu_{\\perp}) - \\mu_B} {|(e_{w1} - \\mu_{\\perp}) - \\mu_B)|} \\tag{7}$$\n",
    "\n",
    "$$e_{w2B} = \\sqrt{ |{1 - ||\\mu_{\\perp} ||^2_2} |} * \\frac{(e_{\\text{w2}} - \\mu_{\\perp}) - \\mu_B} {|(e_{w2} - \\mu_{\\perp}) - \\mu_B)|} \\tag{8}$$\n",
    "\n",
    "$$e_{w1B}^{corrected} = \\sqrt{ |1 - ||\\mu_{\\perp} ||^2_2| } * \\frac{e_{w1B} - \\mu_B}{|(e_{w1} - \\mu_{\\perp}) - \\mu_B|} \\tag{9}$$\n",
    "\n",
    "$$e_{w2B}^{corrected} = \\sqrt{ |1 - ||\\mu_{\\perp} ||^2_2| } * \\frac{e_{w2B} - \\mu_B}{|(e_{w2} - \\mu_{\\perp}) - \\mu_B|} \\tag{10}$$\n",
    "\n",
    "$$e_1 = e_{w1B}^{corrected} + \\mu_{\\perp} \\tag{11}$$\n",
    "$$e_2 = e_{w2B}^{corrected} + \\mu_{\\perp} \\tag{12}$$\n",
    "\n",
    "**练习**：实现下面的函数，使用以上公式得到词对的最终均衡版本。祝你好运！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 词向量对齐（Equalize）函数\n",
    "# ----------------------------\n",
    "def equalize(pair, bias_axis, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "        对一对词（如 'actor' vs 'actress'）进行性别偏差校正，使它们在性别方向上对称，\n",
    "        并保持它们在性别方向正交部分的平均值不变。\n",
    "    \n",
    "    参数：\n",
    "        pair (tuple of str): 待处理的词对，例如 ('actor', 'actress')\n",
    "        bias_axis (np.array): 性别方向向量 g\n",
    "        word_to_vec_map (dict): 词到词向量的映射\n",
    "        \n",
    "    返回：\n",
    "        e1, e2 (np.array): 校正后的两词向量\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1. 获取词对的原始向量\n",
    "    # ----------------------------\n",
    "    w1, w2 = pair\n",
    "    e_w1, e_w2 = word_to_vec_map[w1], word_to_vec_map[w2]\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2. 计算两向量的均值向量\n",
    "    # ----------------------------\n",
    "    mu = (e_w1 + e_w2) / 2.0  # 平均向量\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3. 计算均值向量在性别方向上的投影\n",
    "    # ----------------------------\n",
    "    # mu_B 是 mu 在 bias_axis 上的分量\n",
    "    mu_B = np.dot(mu, bias_axis) / np.square(np.linalg.norm(bias_axis)) * bias_axis\n",
    "\n",
    "    # ----------------------------\n",
    "    # 4. 计算均值向量在性别方向正交部分\n",
    "    # ----------------------------\n",
    "    # mu_orth 是 mu 在性别方向上的正交分量\n",
    "    mu_orth = mu - mu_B\n",
    "\n",
    "    # ----------------------------\n",
    "    # 5. 计算每个词向量在性别方向上的投影\n",
    "    # ----------------------------\n",
    "    e_w1B = np.dot(e_w1, bias_axis) / np.square(np.linalg.norm(bias_axis)) * bias_axis\n",
    "    e_w2B = np.dot(e_w2, bias_axis) / np.square(np.linalg.norm(bias_axis)) * bias_axis\n",
    "\n",
    "    # ----------------------------\n",
    "    # 6. 计算校正后的性别方向分量\n",
    "    # ----------------------------\n",
    "    # 公式中保证校正后的向量在性别方向上对称，并保留在正交方向的均值\n",
    "    corrected_e_w1B = np.sqrt(abs(1 - np.square(np.linalg.norm(mu_orth)))) * (e_w1B - mu_B) / abs(e_w1 - mu_orth - mu_B)\n",
    "    corrected_e_w2B = np.sqrt(abs(1 - np.square(np.linalg.norm(mu_orth)))) * (e_w2B - mu_B) / abs(e_w2 - mu_orth - mu_B)\n",
    "\n",
    "    # ----------------------------\n",
    "    # 7. 将校正后的性别分量加回正交部分\n",
    "    # ----------------------------\n",
    "    e1 = corrected_e_w1B + mu_orth\n",
    "    e2 = corrected_e_w2B + mu_orth\n",
    "\n",
    "    # 返回校正后的向量\n",
    "    return e1, e2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarities before equalizing:\n",
      "cosine_similarity(word_to_vec_map[\"man\"], gender) =  -0.1171109576533683\n",
      "cosine_similarity(word_to_vec_map[\"woman\"], gender) =  0.3566661884627037\n",
      "\n",
      "cosine similarities after equalizing:\n",
      "cosine_similarity(e1, gender) =  -0.7165727525843935\n",
      "cosine_similarity(e2, gender) =  0.7396596474928908\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 测试 equalize 函数\n",
    "# ----------------------------\n",
    "\n",
    "print(\"cosine similarities before equalizing:\")\n",
    "# 输出校正前 \"man\" 和 \"woman\" 与性别向量 g 的余弦相似度\n",
    "print(\"cosine_similarity(word_to_vec_map[\\\"man\\\"], gender) = \", \n",
    "      cosine_similarity(word_to_vec_map[\"man\"], g))\n",
    "print(\"cosine_similarity(word_to_vec_map[\\\"woman\\\"], gender) = \", \n",
    "      cosine_similarity(word_to_vec_map[\"woman\"], g))\n",
    "print()  # 空行用于美观\n",
    "\n",
    "# ----------------------------\n",
    "# 对 ('man', 'woman') 进行 equalize 校正\n",
    "# ----------------------------\n",
    "# 调用 equalize 函数，返回校正后的词向量 e1 和 e2\n",
    "e1, e2 = equalize((\"man\", \"woman\"), g, word_to_vec_map)\n",
    "\n",
    "print(\"cosine similarities after equalizing:\")\n",
    "# 输出校正后词向量与性别向量 g 的余弦相似度\n",
    "print(\"cosine_similarity(e1, gender) = \", cosine_similarity(e1, g))\n",
    "print(\"cosine_similarity(e2, gender) = \", cosine_similarity(e2, g))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "cosine similarities before equalizing:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(word_to_vec_map[\"man\"], gender)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         -0.117110957653\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(word_to_vec_map[\"woman\"], gender)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         0.356666188463\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "cosine similarities after equalizing:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(u1, gender)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         -0.700436428931\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **cosine_similarity(u2, gender)** =\n",
    "        </td>\n",
    "        <td>\n",
    "         0.700436428931\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "请随意修改上面单元格中的输入词，将均衡算法应用于其他词对。\n",
    "\n",
    "这些去偏置算法在减少偏见方面非常有帮助，但并不完美，不能完全消除所有偏见痕迹。  \n",
    "例如，本实现的一大缺点是偏置方向 $g$ 仅使用了 _woman_ 和 _man_ 这对词来定义。正如之前讨论的，如果通过计算 $g_1 = e_{woman} - e_{man}$；$g_2 = e_{mother} - e_{father}$；$g_3 = e_{girl} - e_{boy}$ 等并对它们取平均，你将得到更准确的“性别”维度估计，用于 50 维的词向量空间。  \n",
    "你也可以尝试这种变体来进行实验。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 恭喜\n",
    "\n",
    "你已经完成了本笔记本，并了解了词向量的多种应用方式以及如何对其进行修改。\n",
    "\n",
    "恭喜你完成本笔记本的学习！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**参考文献**：\n",
    "- 去偏置算法来自 Bolukbasi 等人, 2016，[Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf)\n",
    "- GloVe 词向量由 Jeffrey Pennington, Richard Socher 和 Christopher D. Manning 提出。(https://nlp.stanford.edu/projects/glove/)\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "8hb5s",
   "launcher_item_id": "5NrJ6"
  },
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
