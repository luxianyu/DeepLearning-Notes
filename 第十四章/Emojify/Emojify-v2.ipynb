{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è¡¨æƒ…ç¬¦å·ç”Ÿæˆå™¨ï¼ˆEmojify!ï¼‰\n",
    "\n",
    "åœ¨æœ¬èŠ‚ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•åˆ©ç”¨**è¯å‘é‡è¡¨ç¤ºï¼ˆword vector representationsï¼‰**æ¥æ„å»ºä¸€ä¸ªâ€œè¡¨æƒ…ç¬¦å·ç”Ÿæˆå™¨â€ï¼ˆEmojifierï¼‰ã€‚\n",
    "\n",
    "\n",
    "### é¡¹ç›®ç›®æ ‡\n",
    "\n",
    "ä½ æ˜¯å¦æ›¾ç»å¸Œæœ›è‡ªå·±çš„çŸ­ä¿¡æ›´ç”ŸåŠ¨ã€æ›´æœ‰è¡¨ç°åŠ›ï¼Ÿè¿™ä¸ªè¡¨æƒ…ç¬¦å·ç”Ÿæˆå™¨åº”ç”¨ç¨‹åºï¼ˆemojifier appï¼‰å°†å¸®åŠ©ä½ å®ç°è¿™ä¸€ç‚¹ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼Œå°†ä¸‹é¢è¿™å¥è¯ï¼š\n",
    "\n",
    "> â€œCongratulations on the promotion! Lets get coffee and talk. Love you!â€\n",
    "\n",
    "è‡ªåŠ¨å˜æˆï¼š\n",
    "\n",
    "> â€œCongratulations on the promotion! ğŸ‘ Lets get coffee and talk. â˜•ï¸ Love you! â¤ï¸â€\n",
    "\n",
    "### ä»»åŠ¡è¯´æ˜\n",
    "\n",
    "ä½ å°†å®ç°ä¸€ä¸ªæ¨¡å‹ï¼Œå®ƒèƒ½å¤Ÿè¾“å…¥ä¸€å¥è¯ï¼ˆä¾‹å¦‚ â€œLet's go see the baseball game tonight!â€ï¼‰ï¼Œå¹¶è¾“å‡ºæœ€åˆé€‚çš„è¡¨æƒ…ç¬¦å·ï¼ˆâš¾ï¸ï¼‰ã€‚\n",
    "\n",
    "åœ¨è®¸å¤šè¡¨æƒ…ç•Œé¢ä¸­ï¼Œä½ å¿…é¡»è®°ä½ â¤ï¸ æ˜¯â€œheartâ€ï¼ˆå¿ƒå½¢ï¼‰ç¬¦å·ï¼Œè€Œä¸æ˜¯â€œloveâ€ï¼ˆçˆ±ï¼‰ç¬¦å·ã€‚ä½†é€šè¿‡ä½¿ç”¨**è¯å‘é‡**ï¼Œä½ ä¼šçœ‹åˆ°å³ä½¿è®­ç»ƒé›†ä¸­ä»…æ˜ç¡®åœ°å°†å°‘æ•°å•è¯ä¸æŸä¸ªè¡¨æƒ…ç¬¦å·å…³è”èµ·æ¥ï¼Œä½ çš„ç®—æ³•ä»ç„¶èƒ½å¤Ÿ**æ³›åŒ–ï¼ˆgeneralizeï¼‰**åˆ°æµ‹è¯•é›†ä¸­çš„å…¶ä»–å•è¯ä¸Šâ€”â€”å³ä¾¿è¿™äº›å•è¯åœ¨è®­ç»ƒé›†ä¸­ä»æœªå‡ºç°è¿‡ã€‚\n",
    "\n",
    "è¿™ç§ç‰¹æ€§è®©ä½ èƒ½å¤Ÿåœ¨**å°è§„æ¨¡è®­ç»ƒé›†**çš„åŸºç¡€ä¸Šï¼Œä¾ç„¶æ„å»ºä¸€ä¸ªå‡†ç¡®çš„â€œå¥å­åˆ°è¡¨æƒ…ç¬¦å·â€çš„åˆ†ç±»å™¨ï¼ˆclassifierï¼‰ã€‚\n",
    "\n",
    "\n",
    "### æ¨¡å‹ç‰ˆæœ¬\n",
    "\n",
    "åœ¨æœ¬ç»ƒä¹ ä¸­ï¼Œä½ å°†ä¾æ¬¡æ„å»ºä¸¤ä¸ªæ¨¡å‹ï¼š\n",
    "\n",
    "1. **Emojifier-V1**ï¼šä¸€ä¸ªä½¿ç”¨è¯åµŒå…¥ï¼ˆword embeddingsï¼‰çš„åŸºç¡€æ¨¡å‹ã€‚\n",
    "2. **Emojifier-V2**ï¼šä¸€ä¸ªè¿›ä¸€æ­¥ç»“åˆ **LSTMï¼ˆé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼‰** çš„é«˜çº§æ¨¡å‹ã€‚\n",
    "\n",
    "\n",
    "### å‡†å¤‡å¼€å§‹\n",
    "\n",
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ï¼è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒä»¥åŠ è½½æ‰€éœ€çš„åŒ…ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "   ---------------------------------------- 0.0/608.4 kB ? eta -:--:--\n",
      "   - ------------------------------------- 20.5/608.4 kB 682.7 kB/s eta 0:00:01\n",
      "   --------- ------------------------------ 143.4/608.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  604.2/608.4 kB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 608.4/608.4 kB 4.8 MB/s eta 0:00:00\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.15.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# å¯¼å…¥å¸¸ç”¨åº“\n",
    "# ----------------------------\n",
    "\n",
    "import numpy as np\n",
    "# numpyï¼šPython çš„ç§‘å­¦è®¡ç®—åº“ï¼Œæä¾›é«˜æ•ˆæ•°ç»„æ“ä½œä¸çº¿æ€§ä»£æ•°å‡½æ•°\n",
    "\n",
    "import emoji\n",
    "# emojiï¼šç”¨äºå¤„ç†æ–‡æœ¬ä¸­çš„è¡¨æƒ…ç¬¦å·ï¼Œä¾‹å¦‚è¯†åˆ«ã€æ›¿æ¢æˆ–è§£æè¡¨æƒ…\n",
    "\n",
    "import csv\n",
    "# csvï¼šç”¨äºè¯»å–å’Œå†™å…¥ CSV æ–‡ä»¶\n",
    "\n",
    "import pandas as pd\n",
    "# pandasï¼šPython æ•°æ®åˆ†æåº“ï¼Œæä¾›é«˜æ•ˆçš„ DataFrame æ•°æ®ç»“æ„\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.pyplotï¼šç»˜å›¾åº“ï¼Œç”¨äºç»˜åˆ¶æŠ˜çº¿å›¾ã€æ•£ç‚¹å›¾ã€æŸ±çŠ¶å›¾ç­‰\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# sklearn.metrics.confusion_matrixï¼šç”¨äºè®¡ç®—åˆ†ç±»æ¨¡å‹çš„æ··æ·†çŸ©é˜µ\n",
    "\n",
    "# Jupyter Notebook ä¸“ç”¨è®¾ç½®\n",
    "%matplotlib inline\n",
    "# åœ¨ Jupyter Notebook ä¸­ç›´æ¥æ˜¾ç¤º matplotlib ç»˜åˆ¶çš„å›¾ï¼Œè€Œä¸æ˜¯å¼¹å‡ºæ–°çª—å£\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¾…åŠ©å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# è¯»å– GloVe è¯å‘é‡å‡½æ•°\n",
    "# ----------------------------\n",
    "def read_glove_vecs(glove_file):\n",
    "    \"\"\"\n",
    "    åŠŸèƒ½ï¼š\n",
    "    ä» GloVe æ–‡ä»¶è¯»å–è¯å‘é‡ï¼Œå¹¶æ„å»ºä¸‰ç§æ˜ å°„ï¼š\n",
    "        1. words_to_index: å•è¯ -> ç´¢å¼•ï¼ˆæ•´æ•°ï¼‰\n",
    "        2. index_to_words: ç´¢å¼• -> å•è¯ï¼ˆåå‘æ˜ å°„ï¼‰\n",
    "        3. word_to_vec_map: å•è¯ -> è¯å‘é‡ï¼ˆnumpy æ•°ç»„ï¼‰\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "    - glove_file : str\n",
    "        GloVe æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ \"glove.6B.50d.txt\"\n",
    "        æ–‡ä»¶æ ¼å¼ï¼š\n",
    "            æ¯è¡Œç”±å•è¯å’Œå…¶å‘é‡ç»„æˆï¼Œç©ºæ ¼åˆ†éš”ï¼Œä¾‹å¦‚ï¼š\n",
    "                king 0.2134 0.1153 ... -0.4123\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "    - words_to_index : dict\n",
    "        å•è¯ -> ç´¢å¼•ï¼ˆç´¢å¼•ä»1å¼€å§‹ï¼Œ0å¯ç•™ä½œPADï¼‰\n",
    "    - index_to_words : dict\n",
    "        ç´¢å¼• -> å•è¯\n",
    "    - word_to_vec_map : dict\n",
    "        å•è¯ -> numpy å‘é‡ï¼ˆdtype=float64ï¼‰\n",
    "    \"\"\"\n",
    "\n",
    "    # ä½¿ç”¨ UTF-8 ç¼–ç æ‰“å¼€æ–‡ä»¶\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "\n",
    "        # ä½¿ç”¨ set æ¥å­˜å‚¨æ‰€æœ‰å•è¯ï¼ˆè‡ªåŠ¨å»é‡ï¼‰\n",
    "        words = set()                 # åˆå§‹åŒ–ç©ºé›†åˆï¼Œç”¨äºå­˜å‚¨è¯è¡¨\n",
    "        # å­—å…¸ç”¨äºå­˜å‚¨å•è¯ -> å‘é‡çš„æ˜ å°„\n",
    "        word_to_vec_map = {}          \n",
    "\n",
    "        # éå† GloVe æ–‡ä»¶ä¸­çš„æ¯ä¸€è¡Œ\n",
    "        for line in f:\n",
    "            # å»é™¤è¡Œé¦–è¡Œå°¾ç©ºæ ¼ï¼Œå¹¶æŒ‰ç©ºæ ¼æ‹†åˆ†æˆåˆ—è¡¨\n",
    "            line = line.strip().split()  \n",
    "\n",
    "            # ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å•è¯æœ¬èº«\n",
    "            curr_word = line[0]  \n",
    "\n",
    "            # å°†å•è¯åŠ å…¥é›†åˆï¼ˆå»é‡ï¼‰\n",
    "            words.add(curr_word)  \n",
    "\n",
    "            # å‰©ä½™éƒ¨åˆ†æ˜¯å‘é‡ï¼Œå°†å…¶è½¬æ¢ä¸º numpy æ•°ç»„\n",
    "            # dtype=np.float64 ä¿è¯é«˜ç²¾åº¦\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "\n",
    "        # ----------------------------\n",
    "        # æ„å»ºå•è¯ç´¢å¼•æ˜ å°„\n",
    "        # ----------------------------\n",
    "        # ç´¢å¼•ä» 1 å¼€å§‹ï¼Œé€šå¸¸ 0 ç•™ä½œ PAD\n",
    "        i = 1\n",
    "        words_to_index = {}   # å•è¯ -> ç´¢å¼•\n",
    "        index_to_words = {}   # ç´¢å¼• -> å•è¯ï¼ˆåå‘æ˜ å°„ï¼‰\n",
    "\n",
    "        # æŒ‰å­—å…¸åºæ’åºå•è¯ï¼Œä¿è¯ç´¢å¼•å›ºå®š\n",
    "        for w in sorted(words):  \n",
    "            words_to_index[w] = i   # ç»™å•è¯åˆ†é…ç´¢å¼•\n",
    "            index_to_words[i] = w   # å»ºç«‹ç´¢å¼• -> å•è¯æ˜ å°„\n",
    "            i += 1                  # ç´¢å¼•é€’å¢\n",
    "\n",
    "    # è¿”å›ä¸‰ä¸ªæ˜ å°„\n",
    "    return words_to_index, index_to_words, word_to_vec_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Softmax å‡½æ•°\n",
    "# ----------------------------\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    åŠŸèƒ½ï¼š\n",
    "    å¯¹è¾“å…¥å‘é‡æˆ–çŸ©é˜µè®¡ç®— softmax æ¦‚ç‡åˆ†å¸ƒã€‚\n",
    "    softmax å¸¸ç”¨äºå¤šåˆ†ç±»æ¨¡å‹çš„è¾“å‡ºï¼Œå°†ä»»æ„å®æ•°æ˜ å°„åˆ° (0,1) åŒºé—´ï¼Œå¹¶ä¸”æ€»å’Œä¸º1ã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "    - x : numpy.ndarray\n",
    "        è¾“å…¥å‘é‡æˆ–çŸ©é˜µï¼Œå¯ä»¥æ˜¯ä¸€ç»´å‘é‡æˆ–äºŒç»´çŸ©é˜µ\n",
    "        1D ç¤ºä¾‹: [2.0, 1.0, 0.1]\n",
    "        2D ç¤ºä¾‹: [[2.0, 1.0, 0.1], [1.2, 0.7, 0.5]]\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "    - softmax è¾“å‡º : numpy.ndarray\n",
    "        ä¸ x å½¢çŠ¶ç›¸åŒï¼Œä½†æ¯è¡Œï¼ˆæˆ–æ•´å‘é‡ï¼‰è¢«æ˜ å°„ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œæ€»å’Œä¸º1\n",
    "    \"\"\"\n",
    "    \n",
    "    # ----------------------------\n",
    "    # æ•°å€¼ç¨³å®šçš„æŒ‡æ•°è®¡ç®—\n",
    "    # ----------------------------\n",
    "    # np.max(x) è¿”å› x ä¸­çš„æœ€å¤§å€¼\n",
    "    # x - np.max(x) å¯ä»¥é˜²æ­¢æŒ‡æ•°å‡½æ•° exp() è®¡ç®—æ—¶æº¢å‡º\n",
    "    # ä¾‹å¦‚ exp(1000) ä¼šæº¢å‡ºï¼Œç”¨ x - max(x) å¯ä»¥é¿å…\n",
    "    e_x = np.exp(x - np.max(x))  \n",
    "    \n",
    "    # ----------------------------\n",
    "    # softmax å…¬å¼ï¼šexp(x_i)/sum(exp(x_j))\n",
    "    # ----------------------------\n",
    "    # å°†æ¯ä¸ªå…ƒç´ é™¤ä»¥æ‰€æœ‰å…ƒç´ çš„å’Œï¼Œå¾—åˆ°æ¦‚ç‡åˆ†å¸ƒ\n",
    "    return e_x / e_x.sum()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# è¯»å– CSV æ•°æ®é›†\n",
    "# ----------------------------\n",
    "def read_csv(filename='data/emojify_data.csv'):\n",
    "    \"\"\"\n",
    "    åŠŸèƒ½ï¼š\n",
    "    ä» CSV æ–‡ä»¶ä¸­è¯»å–å¥å­å’Œå¯¹åº”çš„ emoji æ ‡ç­¾ï¼Œç”¨äºè¡¨æƒ…ç¬¦å·åˆ†ç±»ä»»åŠ¡ã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "    - filename : str, å¯é€‰ï¼Œé»˜è®¤ 'data/emojify_data.csv'\n",
    "        CSV æ–‡ä»¶è·¯å¾„ï¼Œæ–‡ä»¶å†…å®¹ä¸€èˆ¬ä¸ºä¸¤åˆ—ï¼š\n",
    "            ç¬¬ä¸€åˆ—ï¼šæ–‡æœ¬å¥å­ï¼ˆstringï¼‰\n",
    "            ç¬¬äºŒåˆ—ï¼šå¯¹åº”çš„ emoji æ ‡ç­¾ï¼ˆæ•´æ•°æˆ–ç±»åˆ«ï¼‰\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "    - X : numpy.ndarray\n",
    "        åŒ…å«æ‰€æœ‰å¥å­çš„æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (num_samples,)\n",
    "    \n",
    "    - Y : numpy.ndarray\n",
    "        åŒ…å«å¯¹åº”æ ‡ç­¾çš„æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (num_samples,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # åˆå§‹åŒ–åˆ—è¡¨ï¼Œç”¨äºå­˜æ”¾å¥å­å’Œæ ‡ç­¾\n",
    "    phrase = []    # å­˜æ”¾å¥å­\n",
    "    emoji = []     # å­˜æ”¾å¯¹åº”çš„ emoji æ ‡ç­¾\n",
    "\n",
    "    # æ‰“å¼€ CSV æ–‡ä»¶\n",
    "    with open(filename) as csvDataFile:\n",
    "        # åˆ›å»º CSV é˜…è¯»å™¨å¯¹è±¡\n",
    "        csvReader = csv.reader(csvDataFile)\n",
    "        \n",
    "        # éå† CSV ä¸­çš„æ¯ä¸€è¡Œ\n",
    "        for row in csvReader:\n",
    "            phrase.append(row[0])        # row[0] æ˜¯å¥å­ï¼ŒåŠ å…¥ phrase åˆ—è¡¨\n",
    "            emoji.append(row[1])         # row[1] æ˜¯æ ‡ç­¾ï¼ŒåŠ å…¥ emoji åˆ—è¡¨\n",
    "\n",
    "    # å°†åˆ—è¡¨è½¬æ¢ä¸º numpy æ•°ç»„ï¼Œä¾¿äºåç»­å¤„ç†\n",
    "    X = np.asarray(phrase)                     # å¥å­æ•°ç»„ï¼Œdtype é»˜è®¤ä¸º string\n",
    "    Y = np.asarray(emoji, dtype=int)          # æ ‡ç­¾æ•°ç»„ï¼Œdtype æŒ‡å®šä¸º int\n",
    "\n",
    "    # è¿”å›å¥å­æ•°ç»„å’Œæ ‡ç­¾æ•°ç»„\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# è½¬æ¢æ ‡ç­¾ä¸º one-hot ç¼–ç \n",
    "# ----------------------------\n",
    "def convert_to_one_hot(Y, C):\n",
    "    \"\"\"\n",
    "    åŠŸèƒ½ï¼š\n",
    "    å°†æ•´æ•°æ ‡ç­¾æ•°ç»„ Y è½¬æ¢ä¸º one-hot ç¼–ç å½¢å¼ï¼Œé€‚åˆåˆ†ç±»ä»»åŠ¡çš„ç¥ç»ç½‘ç»œè¾“å…¥ã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "    - Y : numpy.ndarray\n",
    "        æ ‡ç­¾æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (m,) æˆ– (m,1)\n",
    "        æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªæ•´æ•°ï¼Œè¡¨ç¤ºç±»åˆ«ç´¢å¼•ï¼Œä¾‹å¦‚ 0,1,2,...,C-1\n",
    "    - C : int\n",
    "        ç±»åˆ«æ€»æ•°ï¼Œä¾‹å¦‚æœ‰ 5 ä¸ªç±»åˆ«ï¼ŒC=5\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "    - one-hot ç¼–ç  : numpy.ndarray\n",
    "        å½¢çŠ¶ä¸º (m, C)\n",
    "        æ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªæ ·æœ¬çš„ one-hot ç¼–ç ï¼Œä¾‹å¦‚ï¼š\n",
    "            Y[i] = 2, C=5 -> [0,0,1,0,0]\n",
    "    \"\"\"\n",
    "\n",
    "    # np.eye(C) ç”Ÿæˆä¸€ä¸ª C x C çš„å•ä½çŸ©é˜µ\n",
    "    # æ¯ä¸€è¡Œå°±æ˜¯ä¸€ä¸ªç±»åˆ«çš„ one-hot å‘é‡\n",
    "    # Y.reshape(-1) å°† Y å±•å¹³ä¸ºä¸€ç»´æ•°ç»„ï¼Œä¿è¯ç´¢å¼•æ­£ç¡®\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "\n",
    "    # è¿”å›è½¬æ¢åçš„ one-hot ç¼–ç \n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# emoji æ˜ å°„å­—å…¸\n",
    "# ----------------------------\n",
    "emoji_dictionary = {\n",
    "    \"0\": \"\\u2764\\uFE0F\",   # â¤ï¸ å¿ƒï¼ŒUnicode è¡¨ç¤ºæ³• \\u2764 æ˜¯çº¢å¿ƒç¬¦å·ï¼Œ\\uFE0F æ˜¯å˜ä½“é€‰æ‹©å™¨ï¼Œç”¨äºæ˜¾ç¤º emoji æ ·å¼\n",
    "    \"1\": \":baseball:\",     # âš¾ æ£’çƒï¼Œè¿™é‡Œä½¿ç”¨äº†ç®€å†™æ ¼å¼ \":baseball:\"ï¼Œé€šå¸¸åœ¨æŸäº› Markdown æˆ– Slack ä¸­å¯è‡ªåŠ¨æ¸²æŸ“ä¸ºæ£’çƒ emoji\n",
    "    \"2\": \":smile:\",        # ğŸ˜„ å¾®ç¬‘ï¼Œè¡¨ç¤ºå¼€å¿ƒæˆ–é«˜å…´çš„è¡¨æƒ…\n",
    "    \"3\": \":disappointed:\", # ğŸ˜ å¤±æœ›ï¼Œç”¨äºè¡¨ç¤ºæ²®ä¸§æˆ–ä¸æ»¡\n",
    "    \"4\": \":fork_and_knife:\"# ğŸ´ é¤å…·ï¼Œè¡¨ç¤ºä¸åƒé¥­æˆ–é£Ÿç‰©ç›¸å…³\n",
    "}\n",
    "\n",
    "# æ³¨è§£ï¼š\n",
    "# - é”® \"0\"-\"4\" å¯¹åº”æ•´æ•°æ ‡ç­¾ï¼Œé€šå¸¸ä¸æ¨¡å‹è¾“å‡ºç±»åˆ«ç´¢å¼•ä¸€è‡´\n",
    "# - å€¼ä¸ºå¯¹åº”çš„ emoji å­—ç¬¦æˆ–ç®€å†™ï¼Œå¯åœ¨æ˜¾ç¤ºé¢„æµ‹ç»“æœæ—¶ä½¿ç”¨\n",
    "# - Unicode å½¢å¼å¯ç¡®ä¿åœ¨å„ç§å¹³å°ä¸Šéƒ½èƒ½æ˜¾ç¤ºæ ‡å‡† emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# æ ‡ç­¾è½¬ emoji\n",
    "# ----------------------------\n",
    "def label_to_emoji(label):\n",
    "    \"\"\"\n",
    "    å°†æ•´æ•°æ ‡ç­¾æˆ–å­—ç¬¦ä¸²æ ‡ç­¾è½¬ä¸º emoji å­—ç¬¦\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "        label -- æ ‡ç­¾ï¼Œå¯ä»¥æ˜¯æ•´æ•°ï¼ˆå¦‚ 0,1,2,...ï¼‰æˆ–è€…å­—ç¬¦ä¸²ï¼ˆå¦‚ \"0\",\"1\",...ï¼‰\n",
    "                 å¯¹åº”æ¨¡å‹è¾“å‡ºçš„ç±»åˆ«ç´¢å¼•\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "        emoji å­—ç¬¦ä¸² -- å¯¹åº”æ ‡ç­¾çš„ emoji è¡¨ç¤ºï¼Œä¾‹å¦‚ â¤ï¸, âš¾, ğŸ˜„ ç­‰\n",
    "    \"\"\"\n",
    "\n",
    "    # å°†æ ‡ç­¾è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œç”¨äºåœ¨ emoji_dictionary ä¸­æŸ¥æ‰¾å¯¹åº”çš„ emoji\n",
    "    # emoji_dictionary[str(label)] è¿”å›å¯¹åº”çš„ emoji ç®€å†™æˆ– Unicode\n",
    "    # emoji.emojize() å°† emoji ç®€å†™ï¼ˆå¦‚ \":baseball:\"ï¼‰è½¬æ¢ä¸ºå¯æ˜¾ç¤ºçš„ emoji å­—ç¬¦\n",
    "    return emoji.emojize(emoji_dictionary[str(label)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# æ‰“å°é¢„æµ‹ç»“æœ\n",
    "# ----------------------------\n",
    "def print_predictions(X, pred):\n",
    "    \"\"\"\n",
    "    æ‰“å°æ¯ä¸ªå¥å­åŠå¯¹åº”çš„é¢„æµ‹ emoji\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "        X    -- å¥å­æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (m,)ï¼Œm æ˜¯å¥å­æ•°é‡\n",
    "                ä¾‹å¦‚ï¼š[\"I love you\", \"Baseball is fun\", ...]\n",
    "        pred -- æ¨¡å‹é¢„æµ‹æ ‡ç­¾æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (m, 1) æˆ– (m,)\n",
    "                æ¯ä¸ªå…ƒç´ æ˜¯æ•´æ•°æ ‡ç­¾ï¼ˆå¦‚ 0,1,2,...ï¼‰ï¼Œå¯¹åº” emoji ç±»åˆ«\n",
    "    \"\"\"\n",
    "\n",
    "    # æ‰“å°ç©ºè¡Œï¼Œç¾è§‚\n",
    "    print()\n",
    "\n",
    "    # éå†æ¯ä¸ªå¥å­\n",
    "    for i in range(X.shape[0]):\n",
    "        # X[i]ï¼šå½“å‰å¥å­\n",
    "        # pred[i]ï¼šå¯¹åº”é¢„æµ‹æ ‡ç­¾ï¼Œä½¿ç”¨ int() è½¬ä¸ºæ•´æ•°\n",
    "        # label_to_emoji()ï¼šå°†æ ‡ç­¾è½¬æ¢ä¸º emoji\n",
    "        # print()ï¼šæ‰“å°å¥å­å’Œå¯¹åº”çš„ emoji\n",
    "        print(X[i], label_to_emoji(int(pred[i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# ç»˜åˆ¶æ··æ·†çŸ©é˜µ\n",
    "# ----------------------------\n",
    "def plot_confusion_matrix(y_actu, y_pred, title='Confusion matrix', cmap=plt.cm.gray_r):\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶æ··æ·†çŸ©é˜µï¼Œç”¨äºå¯è§†åŒ–æ¨¡å‹é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾çš„å¯¹æ¯”\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "        y_actu -- çœŸå®æ ‡ç­¾æ•°ç»„ï¼Œå½¢çŠ¶ (m,)ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºç±»åˆ«æ•´æ•°\n",
    "        y_pred -- æ¨¡å‹é¢„æµ‹æ ‡ç­¾æ•°ç»„ï¼Œå½¢çŠ¶ (m,1) æˆ– (m,)ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºé¢„æµ‹ç±»åˆ«æ•´æ•°\n",
    "        title  -- å›¾è¡¨æ ‡é¢˜ï¼Œé»˜è®¤ä¸º 'Confusion matrix'\n",
    "        cmap   -- é¢œè‰²æ˜ å°„ï¼Œé»˜è®¤ä½¿ç”¨ç°è‰²åè½¬ colormap (plt.cm.gray_r)\n",
    "    \"\"\"\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # ä½¿ç”¨ pandas è®¡ç®—äº¤å‰è¡¨ï¼ˆæ··æ·†çŸ©é˜µçš„åŸå§‹æ•°æ®ï¼‰\n",
    "    # --------------------------------------------\n",
    "    df_confusion = pd.crosstab(\n",
    "        y_actu,                         # è¡Œï¼šçœŸå®æ ‡ç­¾\n",
    "        y_pred.reshape(y_pred.shape[0],), # åˆ—ï¼šé¢„æµ‹æ ‡ç­¾ï¼Œå°† y_pred å±•å¹³ä¸º 1D æ•°ç»„\n",
    "        rownames=['Actual'],            # è¡Œåç§°\n",
    "        colnames=['Predicted'],         # åˆ—åç§°\n",
    "        margins=True                    # æ·»åŠ è¡Œ/åˆ—æ€»è®¡\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # å½’ä¸€åŒ–æ··æ·†çŸ©é˜µï¼ˆæ¯è¡Œé™¤ä»¥æ€»å’Œï¼‰\n",
    "    # ä¾¿äºæ˜¾ç¤ºæ¯”ä¾‹è€Œéç»å¯¹æ•°å€¼\n",
    "    # --------------------------------------------\n",
    "    df_conf_norm = df_confusion / df_confusion.sum(axis=1)\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # ç»˜åˆ¶çŸ©é˜µå›¾\n",
    "    # plt.matshow() ç»˜åˆ¶çŸ©é˜µå½¢å¼çš„å›¾åƒ\n",
    "    # --------------------------------------------\n",
    "    plt.matshow(df_confusion, cmap=cmap)  # ä½¿ç”¨æŒ‡å®š colormap\n",
    "    plt.colorbar()                        # æ·»åŠ é¢œè‰²æ¡\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # è®¾ç½®åæ ‡è½´åˆ»åº¦\n",
    "    # tick_marks = ç±»åˆ«ç´¢å¼•åˆ—è¡¨\n",
    "    # --------------------------------------------\n",
    "    tick_marks = np.arange(len(df_confusion.columns))  # åˆ—ç´¢å¼•\n",
    "    plt.xticks(tick_marks, df_confusion.columns, rotation=45) # xè½´åˆ»åº¦åŠæ—‹è½¬\n",
    "    plt.yticks(tick_marks, df_confusion.index)                # yè½´åˆ»åº¦\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # è®¾ç½®åæ ‡è½´æ ‡ç­¾\n",
    "    # --------------------------------------------\n",
    "    plt.ylabel(df_confusion.index.name)    # yè½´æ ‡ç­¾ä¸º 'Actual'\n",
    "    plt.xlabel(df_confusion.columns.name)  # xè½´æ ‡ç­¾ä¸º 'Predicted'\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # è®¾ç½®å›¾æ ‡é¢˜\n",
    "    # --------------------------------------------\n",
    "    plt.title(title)\n",
    "    plt.show()  # æ˜¾ç¤ºå›¾åƒ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# é¢„æµ‹å‡½æ•°\n",
    "# ----------------------------\n",
    "def predict(X, Y, W, b, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    ç»™å®šå¥å­ Xã€æƒé‡çŸ©é˜µ W å’Œåç½® bï¼Œé¢„æµ‹å¯¹åº”çš„ emoji æ ‡ç­¾ï¼Œå¹¶è®¡ç®—é¢„æµ‹å‡†ç¡®ç‡\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "        X              -- è¾“å…¥å¥å­æ•°ç»„ï¼Œå½¢çŠ¶ (m,)ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºå­—ç¬¦ä¸²å¥å­\n",
    "        Y              -- æ ‡ç­¾æ•°ç»„ï¼Œå½¢çŠ¶ (m,1)ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºæ•´æ•°ç±»åˆ«\n",
    "        W              -- æƒé‡çŸ©é˜µï¼Œå½¢çŠ¶ (num_classes, word_vector_dim)ï¼Œç”¨äºçº¿æ€§å±‚\n",
    "        b              -- åç½®å‘é‡ï¼Œå½¢çŠ¶ (num_classes,1)\n",
    "        word_to_vec_map -- å­—å…¸ï¼Œå•è¯ -> è¯å‘é‡æ˜ å°„\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "        pred -- é¢„æµ‹æ ‡ç­¾æ•°ç»„ï¼Œå½¢çŠ¶ (m,1)ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºé¢„æµ‹ç±»åˆ«ç´¢å¼•\n",
    "    \"\"\"\n",
    "\n",
    "    m = X.shape[0]                    # æ ·æœ¬æ•°é‡ï¼Œå³å¥å­æ•°é‡\n",
    "    pred = np.zeros((m, 1))           # åˆå§‹åŒ–é¢„æµ‹æ•°ç»„ï¼Œå…¨ä¸º 0ï¼Œå½¢çŠ¶ (m,1)\n",
    "\n",
    "    # éå†æ¯ä¸ªæ ·æœ¬å¥å­\n",
    "    for j in range(m):\n",
    "        words = X[j].lower().split()  # å°†å¥å­è½¬ä¸ºå°å†™å¹¶æ‹†åˆ†ä¸ºå•è¯åˆ—è¡¨\n",
    "        avg = np.zeros((50,))         # åˆå§‹åŒ–å¹³å‡è¯å‘é‡ï¼ˆå‡è®¾æ¯ä¸ªè¯å‘é‡ç»´åº¦ä¸º 50ï¼‰\n",
    "        \n",
    "        # éå†å¥å­ä¸­æ¯ä¸ªå•è¯\n",
    "        for w in words:\n",
    "            avg += word_to_vec_map[w] # ç´¯åŠ å•è¯å‘é‡\n",
    "\n",
    "        avg = avg / len(words)        # è®¡ç®—å¥å­çš„å¹³å‡è¯å‘é‡ï¼ˆå¥å­çº§è¡¨ç¤ºï¼‰\n",
    "\n",
    "        # ----------------------------\n",
    "        # çº¿æ€§å±‚è®¡ç®—\n",
    "        # ----------------------------\n",
    "        Z = np.dot(W, avg) + b        # çº¿æ€§å˜æ¢: Z = W * avg + b\n",
    "                                      # Z å½¢çŠ¶ä¸º (num_classes,1)\n",
    "\n",
    "        A = softmax(Z)                # è®¡ç®—æ¦‚ç‡åˆ†å¸ƒï¼Œsoftmax å°† Z è½¬æ¢ä¸ºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡\n",
    "                                      # A å½¢çŠ¶ä¸º (num_classes,1)ï¼Œæ‰€æœ‰å€¼åŠ å’Œä¸º 1\n",
    "\n",
    "        pred[j] = np.argmax(A)        # é€‰æ‹©æ¦‚ç‡æœ€å¤§çš„ç±»åˆ«ç´¢å¼•ä½œä¸ºé¢„æµ‹æ ‡ç­¾\n",
    "                                      # np.argmax è¿”å›æ²¿æŒ‡å®šè½´æœ€å¤§å€¼çš„ç´¢å¼•ï¼Œè¿™é‡Œä¸ºé¢„æµ‹ç±»åˆ«\n",
    "\n",
    "    # ----------------------------\n",
    "    # è®¡ç®—å¹¶è¾“å‡ºå‡†ç¡®ç‡\n",
    "    # ----------------------------\n",
    "    accuracy = np.mean((pred[:] == Y.reshape(Y.shape[0],1)[:]))  # ä¸çœŸå®æ ‡ç­¾æ¯”è¾ƒ\n",
    "    print(\"Accuracy: \" + str(accuracy))\n",
    "\n",
    "    return pred  # è¿”å›é¢„æµ‹æ ‡ç­¾æ•°ç»„ï¼Œå½¢çŠ¶ (m,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - åŸºçº¿æ¨¡å‹ï¼šEmojifier-V1\n",
    "\n",
    "### 1.1 - æ•°æ®é›† EMOJISET\n",
    "\n",
    "è®©æˆ‘ä»¬ä»æ„å»ºä¸€ä¸ªç®€å•çš„åŸºçº¿åˆ†ç±»å™¨å¼€å§‹ã€‚\n",
    "\n",
    "åœ¨è¿™ä¸ªå®éªŒä¸­ï¼Œä½ å°†ä½¿ç”¨ä¸€ä¸ªéå¸¸å°çš„æ•°æ®é›† **(X, Y)**ï¼Œå…¶ä¸­ï¼š\n",
    "\n",
    "- **X** åŒ…å« **127 æ¡å¥å­ï¼ˆå­—ç¬¦ä¸²ï¼‰**  \n",
    "- **Y** ä¸ºæ¯æ¡å¥å­å¯¹åº”çš„ **æ•´æ•°æ ‡ç­¾ï¼ˆ0 åˆ° 4 ä¹‹é—´ï¼‰**ï¼Œæ¯ä¸ªæ ‡ç­¾ä»£è¡¨ä¸€ç§è¡¨æƒ…ç¬¦å·\n",
    "\n",
    "\n",
    "<img src=\"images/data_set.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> **å›¾ 1**ï¼šEMOJISET â€”â€” ä¸€ä¸ªåŒ…å« 5 ä¸ªç±»åˆ«çš„åˆ†ç±»é—®é¢˜ã€‚ä¸Šå›¾å±•ç¤ºäº†éƒ¨åˆ†å¥å­ç¤ºä¾‹ã€‚</center></caption>\n",
    "\n",
    "\n",
    "æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç åŠ è½½è¯¥æ•°æ®é›†ã€‚  \n",
    "æˆ‘ä»¬å°†æ•°æ®é›†åˆ’åˆ†ä¸ºï¼š\n",
    "- **è®­ç»ƒé›†ï¼ˆ127 ä¸ªæ ·æœ¬ï¼‰**\n",
    "- **æµ‹è¯•é›†ï¼ˆ56 ä¸ªæ ·æœ¬ï¼‰**\n",
    "\n",
    "ï¼ˆä»¥ä¸‹ä»£ç å°†åœ¨åç»­å•å…ƒä¸­æ‰§è¡Œï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒé›†æ ·æœ¬æ•°é‡: 132\n",
      "æµ‹è¯•é›†æ ·æœ¬æ•°é‡: 56\n",
      "è®­ç»ƒé›†å‰5æ¡æ ·æœ¬å¥å­: ['never talk to me again' 'I am proud of your achievements'\n",
      " 'It is the worst day in my life' 'Miss you so much' 'food is life']\n",
      "è®­ç»ƒé›†å‰5æ¡æ ·æœ¬æ ‡ç­¾: [3 2 3 0 4]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# è¯»å–è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "# ----------------------------\n",
    "\n",
    "# è¯»å–è®­ç»ƒé›† CSV æ•°æ®\n",
    "# X_train: è®­ç»ƒå¥å­æ•°ç»„ï¼Œå½¢çŠ¶ (m_train,)\n",
    "# Y_train: è®­ç»ƒæ ‡ç­¾æ•°ç»„ï¼Œå½¢çŠ¶ (m_train,)\n",
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "\n",
    "# è¯»å–æµ‹è¯•é›† CSV æ•°æ®\n",
    "# X_test: æµ‹è¯•å¥å­æ•°ç»„ï¼Œå½¢çŠ¶ (m_test,)\n",
    "# Y_test: æµ‹è¯•æ ‡ç­¾æ•°ç»„ï¼Œå½¢çŠ¶ (m_test,)\n",
    "X_test, Y_test = read_csv('data/tesss.csv')\n",
    "\n",
    "# è¾“å‡ºæ ·æœ¬æ•°é‡ä¸å‰å‡ ä¸ªæ ·æœ¬ï¼Œä¾¿äºæ£€æŸ¥\n",
    "print(\"è®­ç»ƒé›†æ ·æœ¬æ•°é‡:\", X_train.shape[0])\n",
    "print(\"æµ‹è¯•é›†æ ·æœ¬æ•°é‡:\", X_test.shape[0])\n",
    "print(\"è®­ç»ƒé›†å‰5æ¡æ ·æœ¬å¥å­:\", X_train[:5])\n",
    "print(\"è®­ç»ƒé›†å‰5æ¡æ ·æœ¬æ ‡ç­¾:\", Y_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒé›†ä¸­æœ€é•¿å¥å­çš„å•è¯æ•°: 10\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# è®¡ç®—è®­ç»ƒé›†ä¸­å¥å­çš„æœ€å¤§é•¿åº¦\n",
    "# ----------------------------\n",
    "\n",
    "# max(X_train, key=len)  \n",
    "# - æ‰¾åˆ°è®­ç»ƒé›†ä¸­æœ€é•¿çš„å¥å­ï¼ˆæŒ‰å­—ç¬¦æ•°æ¯”è¾ƒï¼‰\n",
    "# .split()  \n",
    "# - å°†è¯¥å¥å­æŒ‰ç©ºæ ¼æ‹†åˆ†ä¸ºå•è¯åˆ—è¡¨\n",
    "# len(...)  \n",
    "# - è®¡ç®—è¯¥å¥å­çš„å•è¯æ•°\n",
    "# maxLen: è®­ç»ƒé›†ä¸­æœ€é•¿å¥å­çš„å•è¯æ•°ï¼Œç”¨äºä¹‹åå¥å­å‘é‡åŒ–å’Œå¡«å……\n",
    "maxLen = len(max(X_train, key=len).split())\n",
    "\n",
    "print(\"è®­ç»ƒé›†ä¸­æœ€é•¿å¥å­çš„å•è¯æ•°:\", maxLen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒï¼Œä»¥æ‰“å°å‡ºæ¥è‡ª **X_train** çš„å¥å­åŠå…¶åœ¨ **Y_train** ä¸­å¯¹åº”çš„æ ‡ç­¾ã€‚  \n",
    "ä½ å¯ä»¥ä¿®æ”¹å˜é‡ `index` çš„å€¼ï¼Œä»¥æŸ¥çœ‹ä¸åŒçš„ç¤ºä¾‹ã€‚\n",
    "\n",
    ">  æ³¨æ„ï¼šç”±äº iPython Notebook ä½¿ç”¨çš„å­—ä½“åŸå› ï¼Œå¿ƒå½¢è¡¨æƒ…ç¬¦å· â¤ï¸ å¯èƒ½ä¼šæ˜¾ç¤ºä¸ºé»‘è‰²ï¼ˆğŸ–¤ï¼‰ï¼Œè¿™æ˜¯æ­£å¸¸ç°è±¡ã€‚\n",
    "\n",
    "```python\n",
    "# ç¤ºä¾‹ä»£ç \n",
    "index = 10  # å¯ä¿®æ”¹ä»¥æŸ¥çœ‹ä¸åŒæ ·æœ¬\n",
    "print(X_train[index], label_to_emoji(Y_train[index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you two are cute â¤ï¸\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# æŸ¥çœ‹è®­ç»ƒé›†ä¸­çš„æŸä¸ªæ ·æœ¬åŠå…¶å¯¹åº”çš„ emoji æ ‡ç­¾\n",
    "# ----------------------------\n",
    "\n",
    "# è®¾ç½®è¦æŸ¥çœ‹çš„æ ·æœ¬ç´¢å¼•\n",
    "index = 45\n",
    "\n",
    "# æ‰“å°è®­ç»ƒé›† X_train ä¸­è¯¥ç´¢å¼•å¯¹åº”çš„å¥å­\n",
    "# åŒæ—¶è°ƒç”¨ label_to_emoji() å‡½æ•°å°† Y_train ä¸­çš„æ ‡ç­¾è½¬æ¢ä¸º emoji\n",
    "print(X_train[index], label_to_emoji(Y_train[index]))\n",
    "\n",
    "# è¯´æ˜ï¼š\n",
    "# X_train[index] -> ç¬¬ 45 ä¸ªè®­ç»ƒæ ·æœ¬ï¼ˆå¥å­ï¼‰\n",
    "# Y_train[index] -> ç¬¬ 45 ä¸ªè®­ç»ƒæ ·æœ¬å¯¹åº”çš„æ ‡ç­¾ï¼ˆæ•°å­— 0~4ï¼‰\n",
    "# label_to_emoji(...) -> å°†æ•°å­—æ ‡ç­¾æ˜ å°„ä¸ºå¯¹åº” emojiï¼Œä¾¿äºå¯è§†åŒ–\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Emojifier-V1 æ¨¡å‹æ¦‚è§ˆ\n",
    "\n",
    "åœ¨æœ¬éƒ¨åˆ†ä¸­ï¼Œä½ å°†å®ç°ä¸€ä¸ªåŸºçº¿æ¨¡å‹ï¼Œåä¸º **â€œEmojifier-V1â€**ã€‚\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"images/image_1.png\" style=\"width:900px;height:300px;\">\n",
    "<caption><center>**å›¾ 2**ï¼šåŸºçº¿æ¨¡å‹ï¼ˆEmojifier-V1ï¼‰ã€‚</center></caption>\n",
    "</center>\n",
    "\n",
    "\n",
    "è¯¥æ¨¡å‹çš„è¾“å…¥æ˜¯ä¸€ä¸ªä»£è¡¨å¥å­çš„å­—ç¬¦ä¸²ï¼ˆä¾‹å¦‚ï¼šâ€œI love youâ€ï¼‰ã€‚  \n",
    "æ¨¡å‹çš„è¾“å‡ºæ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º **(1, 5)** çš„**æ¦‚ç‡å‘é‡ï¼ˆprobability vectorï¼‰**ï¼Œè¡¨ç¤ºè¯¥å¥å­å±äºäº”ä¸ªè¡¨æƒ…ç±»åˆ«ä¸­æ¯ä¸€ç±»çš„æ¦‚ç‡ã€‚\n",
    "\n",
    "æœ€ç»ˆï¼Œä½ å°†æŠŠè¿™ä¸ªæ¦‚ç‡å‘é‡ä¼ å…¥ä¸€ä¸ª **argmax å±‚**ï¼Œä»¥æå–å‡º**æœ€å¯èƒ½çš„è¡¨æƒ…ç¬¦å·å¯¹åº”çš„ç´¢å¼•**ï¼Œä¹Ÿå°±æ˜¯æ¨¡å‹é¢„æµ‹çš„ç»“æœã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†è®©æ ‡ç­¾ **Y** é€‚ç”¨äº **Softmax åˆ†ç±»å™¨ï¼ˆsoftmax classifierï¼‰** çš„è®­ç»ƒï¼Œæˆ‘ä»¬éœ€è¦å°†å®ƒä»å½“å‰çš„å½¢çŠ¶  \n",
    "$(m, 1)$ è½¬æ¢ä¸º **â€œç‹¬çƒ­è¡¨ç¤ºâ€ï¼ˆone-hot representationï¼‰**ï¼Œå½¢çŠ¶ä¸º $(m, 5)$ã€‚\n",
    "\n",
    "åœ¨è¿™ç§è¡¨ç¤ºæ–¹å¼ä¸­ï¼Œæ¯ä¸€è¡Œæ˜¯ä¸€ä¸ª **one-hot å‘é‡**ï¼Œç”¨äºæŒ‡ç¤ºæŸä¸ªæ ·æœ¬æ‰€å±çš„ç±»åˆ«ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼š\n",
    "- è‹¥æ ‡ç­¾ä¸º 2ï¼Œåˆ™å¯¹åº”çš„ one-hot å‘é‡ä¸º `[0, 0, 1, 0, 0]`ã€‚\n",
    "\n",
    "ä¸‹é¢çš„ä»£ç ç‰‡æ®µå¯ä»¥å®Œæˆè¿™ä¸€è½¬æ¢æ“ä½œã€‚  \n",
    "å…¶ä¸­ï¼Œå˜é‡å `Y_oh_train` å’Œ `Y_oh_test` ä¸­çš„ `Y_oh` è¡¨ç¤º **â€œY çš„ one-hot å½¢å¼ï¼ˆY-one-hotï¼‰â€**ã€‚\n",
    "\n",
    "```python\n",
    "# å°†æ ‡ç­¾è½¬æ¢ä¸º one-hot å‘é‡è¡¨ç¤º\n",
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# å°†æ ‡ç­¾è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç ï¼ˆOne-Hot Encodingï¼‰\n",
    "# ----------------------------\n",
    "\n",
    "# å°†è®­ç»ƒé›†æ ‡ç­¾ Y_train è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç å½¢å¼\n",
    "# å‚æ•°è¯´æ˜ï¼š\n",
    "#   Y_train : åŸå§‹æ ‡ç­¾æ•°ç»„ï¼Œå½¢çŠ¶ (m, )ï¼Œæ¯ä¸ªå€¼ä¸º 0~4 ä¹‹é—´çš„æ•´æ•°\n",
    "#   C       : ç±»åˆ«æ€»æ•°ï¼Œè¿™é‡Œæ˜¯ 5 ä¸ª emoji\n",
    "# è¿”å›ï¼š\n",
    "#   Y_oh_train : è®­ç»ƒé›†æ ‡ç­¾çš„ç‹¬çƒ­ç¼–ç ï¼Œå½¢çŠ¶ (m, 5)\n",
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
    "\n",
    "# å°†æµ‹è¯•é›†æ ‡ç­¾ Y_test è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç å½¢å¼\n",
    "# å‚æ•°è¯´æ˜åŒä¸Š\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)\n",
    "\n",
    "# è¯´æ˜ï¼š\n",
    "# 1. ç‹¬çƒ­ç¼–ç çš„å¥½å¤„ï¼š\n",
    "#    - å¯ä»¥ç›´æ¥ç”¨äºç¥ç»ç½‘ç»œçš„è¾“å‡ºå±‚è®­ç»ƒ\n",
    "#    - å°†ç±»åˆ«æ ‡ç­¾ä»æ ‡é‡è½¬æ¢ä¸ºå‘é‡ï¼Œä¾‹å¦‚ï¼š\n",
    "#      æ ‡ç­¾ 2 â†’ [0, 0, 1, 0, 0]\n",
    "# 2. convert_to_one_hot å‡½æ•°å†…éƒ¨é€šè¿‡ np.eye(C)[Y.reshape(-1)] å®ç°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ `convert_to_one_hot()` å‡½æ•°çš„è¿è¡Œç»“æœã€‚  \n",
    "ä½ å¯ä»¥ä¿®æ”¹å˜é‡ `index` çš„å€¼ï¼Œä»¥æ‰“å°å¹¶æŸ¥çœ‹ä¸åŒæ ·æœ¬å¯¹åº”çš„ **one-hot å‘é‡è¡¨ç¤º**ã€‚\n",
    "\n",
    "```python\n",
    "# æŸ¥çœ‹æŸä¸ªæ ·æœ¬çš„ one-hot è½¬æ¢ç»“æœ\n",
    "index = 1  # å¯æ›´æ”¹ç´¢å¼•ä»¥æŸ¥çœ‹ä¸åŒæ ·æœ¬\n",
    "print(f\"æ ‡ç­¾å€¼: {Y_train[index]}\")\n",
    "print(f\"One-hot è¡¨ç¤º: {Y_oh_train[index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 is converted into one hot [0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# æŸ¥çœ‹æŸä¸ªæ ·æœ¬çš„æ ‡ç­¾åŠå…¶ç‹¬çƒ­ç¼–ç \n",
    "# ----------------------------\n",
    "\n",
    "# è®¾ç½®è¦æŸ¥çœ‹çš„æ ·æœ¬ç´¢å¼•\n",
    "index = 25\n",
    "\n",
    "# æ‰“å°è¯¥æ ·æœ¬çš„åŸå§‹æ ‡ç­¾ä»¥åŠå¯¹åº”çš„ç‹¬çƒ­ç¼–ç \n",
    "# Y_train[index]       : åŸå§‹æ ‡ç­¾ï¼ˆæ•´æ•°ï¼‰ï¼Œè¡¨ç¤ºç¬¬ index ä¸ªè®­ç»ƒæ ·æœ¬çš„ emoji ç±»åˆ«\n",
    "# Y_oh_train[index]    : ç‹¬çƒ­ç¼–ç å‘é‡ï¼Œå¯¹åº”ç±»åˆ«ä½ç½®ä¸º 1ï¼Œå…¶ä½™ä½ç½®ä¸º 0\n",
    "print(Y_train[index], \"is converted into one hot\", Y_oh_train[index])\n",
    "\n",
    "# ç¤ºä¾‹è¯´æ˜ï¼š\n",
    "# å‡è®¾ Y_train[25] = 3ï¼Œåˆ™è¾“å‡ºå¯èƒ½ä¸ºï¼š\n",
    "# 3 is converted into one hot [0. 0. 0. 1. 0.]\n",
    "# è¿™é‡Œ [0. 0. 0. 1. 0.] è¡¨ç¤ºç‹¬çƒ­ç¼–ç å½¢å¼\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨ï¼Œæ‰€æœ‰æ•°æ®éƒ½å·²ç»å‡†å¤‡å®Œæ¯•ï¼Œå¯ä»¥è¾“å…¥åˆ° **Emojifier-V1 æ¨¡å‹** ä¸­è¿›è¡Œè®­ç»ƒäº†ã€‚  \n",
    "æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å¼€å§‹å®ç°è¿™ä¸ªæ¨¡å‹å§ï¼ ğŸš€\n",
    "\n",
    "```python\n",
    "# å®ç° Emojifier-V1 æ¨¡å‹çš„å‡½æ•°æ¡†æ¶\n",
    "def model(X, Y, word_to_vec_map, learning_rate=0.01, num_iterations=400):\n",
    "    \"\"\"\n",
    "    å®ç° Emojifier-V1 æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "    X -- å¥å­åˆ—è¡¨ï¼ˆæ¯ä¸ªå…ƒç´ ä¸ºå­—ç¬¦ä¸²ï¼‰\n",
    "    Y -- å¥å­å¯¹åº”çš„æ ‡ç­¾ï¼ˆ0~4ï¼‰\n",
    "    word_to_vec_map -- è¯å‘é‡å­—å…¸ï¼šæ¯ä¸ªå•è¯æ˜ å°„åˆ°å…¶å¯¹åº”çš„ GloVe å‘é‡\n",
    "    learning_rate -- å­¦ä¹ ç‡ï¼ˆé»˜è®¤ 0.01ï¼‰\n",
    "    num_iterations -- è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤ 400ï¼‰\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    pred -- æ¨¡å‹å¯¹æ‰€æœ‰æ ·æœ¬çš„é¢„æµ‹ç»“æœ\n",
    "    \"\"\"\n",
    "    # æ¨¡å‹å®ç°ç»†èŠ‚å°†åœ¨åç»­å°èŠ‚ä¸­å®Œæˆ\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - å®ç° Emojifier-V1\n",
    "\n",
    "å¦‚å›¾ï¼ˆ2ï¼‰æ‰€ç¤ºï¼Œç¬¬ä¸€æ­¥æ˜¯å°†è¾“å…¥çš„å¥å­è½¬æ¢ä¸ºè¯å‘é‡è¡¨ç¤ºï¼Œç„¶åå¯¹è¿™äº›è¯å‘é‡å–å¹³å‡å€¼ã€‚  \n",
    "ä¸ä¹‹å‰çš„ç»ƒä¹ ç±»ä¼¼ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨é¢„è®­ç»ƒçš„ **50 ç»´ GloVe è¯å‘é‡**ã€‚  \n",
    "è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒä»¥åŠ è½½åŒ…å«æ‰€æœ‰è¯å‘é‡è¡¨ç¤ºçš„ `word_to_vec_map`ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# è¯»å– GloVe è¯å‘é‡\n",
    "# ----------------------------\n",
    "\n",
    "# è°ƒç”¨ä¹‹å‰å®šä¹‰çš„ read_glove_vecs() å‡½æ•°ï¼Œè¯»å– GloVe æ–‡ä»¶\n",
    "# 'data/glove.6B.50d.txt' ï¼šGloVe é¢„è®­ç»ƒè¯å‘é‡æ–‡ä»¶è·¯å¾„ï¼Œ50ç»´åº¦è¯å‘é‡\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')\n",
    "\n",
    "# è¿”å›å€¼è¯´æ˜ï¼š\n",
    "# word_to_index : dictï¼Œå°†å•è¯æ˜ å°„ä¸ºå¯¹åº”çš„ç´¢å¼•\n",
    "#                 ä¾‹å¦‚: word_to_index['king'] = 1234\n",
    "# index_to_word : dictï¼Œå°†ç´¢å¼•æ˜ å°„å›å•è¯\n",
    "#                 ä¾‹å¦‚: index_to_word[1234] = 'king'\n",
    "# word_to_vec_map : dictï¼Œå°†å•è¯æ˜ å°„ä¸ºå¯¹åº”çš„è¯å‘é‡ï¼ˆnumpy.ndarrayï¼‰\n",
    "#                 ä¾‹å¦‚: word_to_vec_map['king'].shape = (50,) è¡¨ç¤º 50 ç»´å‘é‡\n",
    "\n",
    "# è¯»å–å®Œæˆåï¼Œå¯ç”¨äºï¼š\n",
    "# 1. å°†å•è¯è½¬æ¢ä¸ºå‘é‡è¿›è¡Œè¿ç®—\n",
    "# 2. åœ¨ç¥ç»ç½‘ç»œä¸­ä½œä¸ºè¾“å…¥çš„åµŒå…¥å‘é‡\n",
    "# 3. è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—ã€ç±»æ¯”ä»»åŠ¡ç­‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½ å·²ç»åŠ è½½äº†ä»¥ä¸‹å†…å®¹ï¼š\n",
    "\n",
    "- `word_to_index`ï¼šå°†å•è¯æ˜ å°„åˆ°è¯æ±‡è¡¨ç´¢å¼•çš„å­—å…¸ï¼ˆå…± 400,001 ä¸ªå•è¯ï¼Œæœ‰æ•ˆç´¢å¼•èŒƒå›´ 0 åˆ° 400,000ï¼‰  \n",
    "- `index_to_word`ï¼šå°†ç´¢å¼•æ˜ å°„å›è¯æ±‡è¡¨å¯¹åº”å•è¯çš„å­—å…¸  \n",
    "- `word_to_vec_map`ï¼šå°†å•è¯æ˜ å°„åˆ°å…¶ GloVe å‘é‡è¡¨ç¤ºçš„å­—å…¸  \n",
    "\n",
    "è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒä»¥æ£€æŸ¥åŠ è½½æ˜¯å¦æ­£å¸¸ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index of cucumber in the vocabulary is 113317\n",
      "the 289846th word in the vocabulary is potatos\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# æ¼”ç¤ºå•è¯ç´¢å¼•ä¸è¯å‘é‡æ˜ å°„\n",
    "# ----------------------------\n",
    "\n",
    "# å®šä¹‰è¦æŸ¥è¯¢çš„å•è¯\n",
    "word = \"cucumber\"\n",
    "\n",
    "# å®šä¹‰è¦æŸ¥è¯¢çš„ç´¢å¼•\n",
    "index = 289846\n",
    "\n",
    "# 1. æŸ¥è¯¢å•è¯å¯¹åº”çš„ç´¢å¼•\n",
    "# word_to_index[word] ä¼šè¿”å›å•è¯åœ¨è¯æ±‡è¡¨ä¸­çš„ç´¢å¼•\n",
    "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
    "# è¾“å‡ºç¤ºä¾‹: the index of cucumber in the vocabulary is 1234\n",
    "\n",
    "# 2. æŸ¥è¯¢ç´¢å¼•å¯¹åº”çš„å•è¯\n",
    "# index_to_word[index] ä¼šè¿”å›ç´¢å¼•å¯¹åº”çš„å•è¯\n",
    "print(\"the\", str(index) + \"th word in the vocabulary is\", index_to_word[index])\n",
    "# è¾“å‡ºç¤ºä¾‹: the 289846th word in the vocabulary is cucumber\n",
    "\n",
    "# è¯´æ˜ï¼š\n",
    "# - word_to_index ç”¨äºå°†å•è¯è½¬ä¸ºç´¢å¼•ï¼Œæ–¹ä¾¿åœ¨ç¥ç»ç½‘ç»œä¸­æŸ¥æ‰¾åµŒå…¥å‘é‡\n",
    "# - index_to_word ç”¨äºå°†ç´¢å¼•è½¬å›å•è¯ï¼Œä¾¿äºè§£é‡Šæ¨¡å‹è¾“å‡ºæˆ–è°ƒè¯•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ç»ƒä¹ **ï¼šå®ç° `sentence_to_avg()` å‡½æ•°ã€‚ä½ éœ€è¦å®Œæˆä»¥ä¸‹ä¸¤æ­¥ï¼š\n",
    "\n",
    "1. å°†æ¯ä¸ªå¥å­è½¬æ¢ä¸ºå°å†™å­—æ¯ï¼Œç„¶åå°†å¥å­æ‹†åˆ†ä¸ºå•è¯åˆ—è¡¨ã€‚å¯ä»¥ä½¿ç”¨ `X.lower()` å’Œ `X.split()`ã€‚  \n",
    "2. å¯¹å¥å­ä¸­çš„æ¯ä¸ªå•è¯ï¼Œè·å–å…¶å¯¹åº”çš„ GloVe å‘é‡è¡¨ç¤ºã€‚ç„¶åï¼Œå¯¹æ‰€æœ‰è¯å‘é‡å–å¹³å‡å€¼ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# å°†å¥å­è½¬æ¢ä¸ºå¹³å‡è¯å‘é‡\n",
    "# ----------------------------\n",
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    åŠŸèƒ½ï¼š\n",
    "        å°†ä¸€å¥è¯ï¼ˆsentenceï¼‰è½¬æ¢ä¸ºå•è¯åˆ—è¡¨ï¼Œæå–æ¯ä¸ªå•è¯çš„ GloVe è¯å‘é‡ï¼Œå¹¶è®¡ç®—å¹³å‡å‘é‡ã€‚\n",
    "        æœ€ç»ˆè¿”å›ä¸€ä¸ªè¡¨ç¤ºæ•´å¥è¯è¯­ä¹‰çš„å‘é‡ã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        sentence -- å­—ç¬¦ä¸²ç±»å‹ï¼Œä¸€æ¡è®­ç»ƒæ ·æœ¬ï¼ˆä¾‹å¦‚ X_train ä¸­çš„ä¸€æ¡å¥å­ï¼‰\n",
    "        word_to_vec_map -- å­—å…¸ç±»å‹ï¼Œå°†è¯æ±‡è¡¨ä¸­æ¯ä¸ªå•è¯æ˜ å°„ä¸º 50 ç»´è¯å‘é‡\n",
    "        \n",
    "    è¿”å›ï¼š\n",
    "        avg -- å¥å­çš„å¹³å‡è¯å‘é‡ï¼Œnumpy æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (50,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # ----------------------------\n",
    "    # 1. å°†å¥å­æ‹†åˆ†æˆå•è¯åˆ—è¡¨ï¼Œå¹¶å…¨éƒ¨è½¬æ¢ä¸ºå°å†™\n",
    "    # ä¾‹å¦‚ \"I love NLP\" -> [\"i\", \"love\", \"nlp\"]\n",
    "    # ----------------------------\n",
    "    words = sentence.lower().split()\n",
    "    \n",
    "    # ----------------------------\n",
    "    # 2. åˆå§‹åŒ–ä¸€ä¸ªå…¨é›¶çš„å‘é‡ï¼Œç”¨äºç´¯åŠ è¯å‘é‡\n",
    "    # ç»´åº¦ä¸ GloVe å‘é‡ç›¸åŒï¼Œè¿™é‡Œæ˜¯ 50 ç»´\n",
    "    # ----------------------------\n",
    "    avg = np.zeros(50,)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # 3. éå†å¥å­ä¸­çš„æ¯ä¸ªå•è¯ï¼Œå°†å¯¹åº”è¯å‘é‡ç´¯åŠ \n",
    "    # ----------------------------\n",
    "    for w in words:\n",
    "        avg += word_to_vec_map[w]   # ç´¯åŠ æ¯ä¸ªå•è¯çš„ 50 ç»´è¯å‘é‡\n",
    "    \n",
    "    # ----------------------------\n",
    "    # 4. å°†ç´¯åŠ çš„å‘é‡é™¤ä»¥å•è¯æ•°ï¼Œå¾—åˆ°å¹³å‡å‘é‡\n",
    "    # ----------------------------\n",
    "    avg = np.divide(avg, len(words))   # avg = avg / len(words)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # 5. è¿”å›å¥å­çš„å¹³å‡å‘é‡\n",
    "    # ----------------------------\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg =  [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
      " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
      "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
      "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
      "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
      "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
      " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
      " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
      "  0.1445417   0.09808667]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# ç¤ºä¾‹ï¼šå°†ä¸€å¥è¯è½¬æ¢ä¸ºå¹³å‡è¯å‘é‡\n",
    "# ----------------------------\n",
    "\n",
    "# å¥å­ç¤ºä¾‹\n",
    "sentence = \"Morrocan couscous is my favorite dish\"\n",
    "\n",
    "# è°ƒç”¨ sentence_to_avg å‡½æ•°ï¼Œå°†å¥å­è½¬æ¢ä¸º 50 ç»´å¹³å‡è¯å‘é‡\n",
    "avg = sentence_to_avg(sentence, word_to_vec_map)\n",
    "\n",
    "# æ‰“å°ç»“æœ\n",
    "print(\"avg = \", avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **avg= **\n",
    "        </td>\n",
    "        <td>\n",
    "           [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
    " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
    "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
    "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
    "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
    "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
    " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
    " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
    "  0.1445417   0.09808667]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#### æ¨¡å‹\n",
    "\n",
    "ç°åœ¨ï¼Œä½ å·²ç»å…·å¤‡å®Œæˆ `model()` å‡½æ•°å®ç°çš„æ‰€æœ‰ç»„ä»¶ã€‚  \n",
    "åœ¨ä½¿ç”¨ `sentence_to_avg()` åï¼Œä½ éœ€è¦å°†å¹³å‡å‘é‡è¾“å…¥åˆ°å‰å‘ä¼ æ’­ä¸­ï¼Œè®¡ç®—æŸå¤±ï¼Œç„¶åè¿›è¡Œåå‘ä¼ æ’­ä»¥æ›´æ–° softmax å‚æ•°ã€‚\n",
    "\n",
    "**ç»ƒä¹ **ï¼šå®ç°å›¾ï¼ˆ2ï¼‰ä¸­æè¿°çš„ `model()` å‡½æ•°ã€‚  \n",
    "å‡è®¾è¿™é‡Œçš„ $Yoh$ï¼ˆâ€œY one hotâ€ï¼‰æ˜¯è¾“å‡ºæ ‡ç­¾çš„ one-hot ç¼–ç ï¼Œå‰å‘ä¼ æ’­å’Œäº¤å‰ç†µæŸå¤±è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š\n",
    "\n",
    "$$ z^{(i)} = W . avg^{(i)} + b$$  \n",
    "$$ a^{(i)} = softmax(z^{(i)})$$  \n",
    "$$ \\mathcal{L}^{(i)} = - \\sum_{k = 0}^{n_y - 1} Yoh^{(i)}_k * log(a^{(i)}_k)$$\n",
    "\n",
    "å½“ç„¶å¯ä»¥å®ç°ä¸€ä¸ªæ›´é«˜æ•ˆçš„å‘é‡åŒ–å®ç°ã€‚ä½†ç”±äºæˆ‘ä»¬è¿™æ¬¡ä»ç„¶ä½¿ç”¨ for å¾ªç¯å°†å¥å­é€ä¸€è½¬æ¢ä¸º $avg^{(i)}$ è¡¨ç¤ºï¼Œè¿™é‡Œå°±ä¸å†ä¼˜åŒ–äº†ã€‚\n",
    "\n",
    "æˆ‘ä»¬å·²ç»ä¸ºä½ æä¾›äº†ä¸€ä¸ª `softmax()` å‡½æ•°ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# GRADED FUNCTION: model\n",
    "# ----------------------------\n",
    "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n",
    "    \"\"\"\n",
    "    åŸºäºå¹³å‡è¯å‘é‡çš„ç®€å•ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œç”¨äºè®­ç»ƒè¯å‘é‡è¡¨ç¤ºå’Œ emoji é¢„æµ‹\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "    X -- è¾“å…¥æ•°æ®ï¼Œnumpy æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå¥å­ï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼Œå½¢çŠ¶ (m, 1)\n",
    "    Y -- æ ‡ç­¾ï¼Œnumpy æ•°ç»„ï¼Œæ•´æ•°å½¢å¼ï¼ˆ0~4 å¯¹åº” emoji ç±»åˆ«ï¼‰ï¼Œå½¢çŠ¶ (m, 1)\n",
    "    word_to_vec_map -- å­—å…¸ï¼Œå°†è¯æ˜ å°„åˆ° 50 ç»´ GloVe å‘é‡\n",
    "    learning_rate -- å­¦ä¹ ç‡ï¼Œç”¨äºéšæœºæ¢¯åº¦ä¸‹é™\n",
    "    num_iterations -- è¿­ä»£æ¬¡æ•°\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "    pred -- æ¨¡å‹é¢„æµ‹ç»“æœï¼Œnumpy æ•°ç»„ï¼Œå½¢çŠ¶ (m, 1)\n",
    "    W -- softmax å±‚æƒé‡çŸ©é˜µï¼Œå½¢çŠ¶ (n_y, n_h)\n",
    "    b -- softmax å±‚åç½®ï¼Œå½¢çŠ¶ (n_y,)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)  # è®¾ç½®éšæœºç§å­ï¼Œä¿è¯ç»“æœå¯å¤ç°\n",
    "\n",
    "    # ----------------------------\n",
    "    # åˆå§‹åŒ–å‚æ•°\n",
    "    # ----------------------------\n",
    "    m = Y.shape[0]      # è®­ç»ƒæ ·æœ¬æ•°é‡\n",
    "    n_y = 5             # åˆ†ç±»ç±»åˆ«æ•°ï¼ˆemoji ç±»åˆ«ï¼‰\n",
    "    n_h = 50            # GloVe å‘é‡ç»´åº¦\n",
    "    \n",
    "    # Xavier åˆå§‹åŒ–æƒé‡çŸ©é˜µ Wï¼Œä½¿æƒé‡åˆ†å¸ƒæ›´å‡åŒ€\n",
    "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)  \n",
    "    b = np.zeros((n_y,))  # åç½®å‘é‡åˆå§‹åŒ–ä¸º 0\n",
    "\n",
    "    # å°†æ ‡ç­¾ Y è½¬æ¢ä¸º one-hot ç¼–ç ï¼Œä¾¿äº softmax è®¡ç®—\n",
    "    Y_oh = convert_to_one_hot(Y, C = n_y) \n",
    "    \n",
    "    # ----------------------------\n",
    "    # æ¢¯åº¦ä¸‹é™ä¼˜åŒ–å¾ªç¯\n",
    "    # ----------------------------\n",
    "    for t in range(num_iterations):            # éå†è¿­ä»£æ¬¡æ•°\n",
    "        for i in range(m):                     # éå†æ¯ä¸ªè®­ç»ƒæ ·æœ¬\n",
    "            \n",
    "            # ----------------------------\n",
    "            # ç¬¬ i ä¸ªè®­ç»ƒæ ·æœ¬ï¼šè®¡ç®—å¥å­å¹³å‡è¯å‘é‡\n",
    "            # ----------------------------\n",
    "            avg = sentence_to_avg(X[i], word_to_vec_map)  # avg å½¢çŠ¶ (50,)\n",
    "\n",
    "            # ----------------------------\n",
    "            # å‰å‘ä¼ æ’­\n",
    "            # z = WÂ·avg + b\n",
    "            # ----------------------------\n",
    "            z = np.dot(W, avg) + b                        # çº¿æ€§ç»„åˆï¼Œå½¢çŠ¶ (n_y,)\n",
    "            a = softmax(z)                                # softmax è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒ\n",
    "\n",
    "            # ----------------------------\n",
    "            # è®¡ç®—æŸå¤±ï¼ˆäº¤å‰ç†µæŸå¤±ï¼‰\n",
    "            # ----------------------------\n",
    "            cost = -np.sum(Y_oh[i]*np.log(a))             # ç¬¬ i ä¸ªæ ·æœ¬çš„æŸå¤±\n",
    "\n",
    "            # ----------------------------\n",
    "            # åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦\n",
    "            # ----------------------------\n",
    "            dz = a - Y_oh[i]                              # softmax è¯¯å·®\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))  # æƒé‡æ¢¯åº¦\n",
    "            db = dz                                       # åç½®æ¢¯åº¦\n",
    "\n",
    "            # ----------------------------\n",
    "            # å‚æ•°æ›´æ–°ï¼ˆéšæœºæ¢¯åº¦ä¸‹é™ï¼‰\n",
    "            # ----------------------------\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "        \n",
    "        # æ¯ 100 ä¸ª epoch è¾“å‡ºä¸€æ¬¡æŸå¤±å’Œå‡†ç¡®ç‡ï¼Œä¾¿äºè§‚å¯Ÿè®­ç»ƒæ•ˆæœ\n",
    "        if t % 100 == 0:\n",
    "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
    "            pred = predict(X, Y, W, b, word_to_vec_map)  # è¾“å‡ºå½“å‰é¢„æµ‹å‡†ç¡®ç‡\n",
    "\n",
    "    # è¿”å›æœ€ç»ˆé¢„æµ‹ã€æƒé‡å’Œåç½®\n",
    "    return pred, W, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,)\n",
      "(132,)\n",
      "(132, 5)\n",
      "never talk to me again\n",
      "<class 'numpy.ndarray'>\n",
      "(20,)\n",
      "(20,)\n",
      "(132, 5)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# è¾“å‡ºè®­ç»ƒé›† X_train çš„å½¢çŠ¶\n",
    "print(X_train.shape)\n",
    "# X_train æ˜¯å¥å­åˆ—è¡¨ï¼Œé€šå¸¸å½¢çŠ¶ä¸º (m, ) æˆ– (m,1)ï¼Œm = æ ·æœ¬æ•°\n",
    "\n",
    "# è¾“å‡ºè®­ç»ƒæ ‡ç­¾ Y_train çš„å½¢çŠ¶\n",
    "print(Y_train.shape)\n",
    "# Y_train æ˜¯æ•´æ•°æ ‡ç­¾æ•°ç»„ï¼Œå½¢çŠ¶ (m, 1)\n",
    "\n",
    "# å°† Y_train è½¬ä¸º one-hot ç¼–ç å¹¶æŸ¥çœ‹å½¢çŠ¶\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "# np.eye(5) ç”Ÿæˆ 5x5 å•ä½çŸ©é˜µ\n",
    "# Y_train.reshape(-1) å°† Y_train æ‹‰æˆä¸€ç»´\n",
    "# np.eye(5)[Y_train.reshape(-1)] å¾—åˆ°æ¯ä¸ªæ ‡ç­¾å¯¹åº”çš„ one-hot ç¼–ç \n",
    "# ç»“æœå½¢çŠ¶ (m, 5)\n",
    "\n",
    "# æ‰“å°è®­ç»ƒé›†ç¬¬ä¸€ä¸ªæ ·æœ¬\n",
    "print(X_train[0])\n",
    "# è¾“å‡ºç¤ºä¾‹å¥å­å­—ç¬¦ä¸²\n",
    "\n",
    "# æŸ¥çœ‹ X_train çš„æ•°æ®ç±»å‹\n",
    "print(type(X_train))\n",
    "# é€šå¸¸æ˜¯ numpy.ndarray æˆ– list\n",
    "\n",
    "# æ„å»ºä¸€ä¸ªå°å‹æ ‡ç­¾æ•°ç»„ Yï¼ˆ16 ä¸ªæ ·æœ¬ï¼‰\n",
    "Y = np.asarray([5,0,0,5, 4, 4, 4, 6, 6, 4, 1, 1, 5, 6, 6, 3, 6, 3, 4, 4])\n",
    "print(Y.shape)\n",
    "# è¾“å‡º Y çš„å½¢çŠ¶ (20,)\n",
    "\n",
    "# æ„å»ºä¸€ä¸ªå°å‹å¥å­æ•°ç»„ Xï¼Œå¯¹åº”ä¸Šé¢çš„æ ‡ç­¾ Y\n",
    "X = np.asarray([\n",
    "    'I am going to the bar tonight', \n",
    "    'I love you', \n",
    "    'miss you my dear',\n",
    "    'Lets go party and drinks',\n",
    "    'Congrats on the new job',\n",
    "    'Congratulations',\n",
    "    'I am so happy for you',\n",
    "    'Why are you feeling bad',\n",
    "    'What is wrong with you',\n",
    "    'You totally deserve this prize',\n",
    "    'Let us go play football',\n",
    "    'Are you down for football this afternoon',\n",
    "    'Work hard play harder',\n",
    "    'It is suprising how people can be dumb sometimes',\n",
    "    'I am very disappointed',\n",
    "    'It is the best day in my life',\n",
    "    'I think I will end up alone',\n",
    "    'My life is so boring',\n",
    "    'Good job',\n",
    "    'Great so awesome'\n",
    "])\n",
    "print(X.shape)\n",
    "# è¾“å‡º X çš„å½¢çŠ¶ (20,)\n",
    "\n",
    "# å†æ¬¡æ‰“å° Y_train çš„ one-hot ç¼–ç å½¢çŠ¶\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "\n",
    "# å†æ¬¡æ‰“å° X_train çš„ç±»å‹\n",
    "print(type(X_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿è¡Œä¸‹ä¸€ä¸ªä»£ç å•å…ƒä»¥è®­ç»ƒä½ çš„æ¨¡å‹ï¼Œå¹¶å­¦ä¹  softmax å‚æ•° **(W, b)**ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = 1.9520498812810072\n",
      "Accuracy: 0.3484848484848485\n",
      "Epoch: 100 --- cost = 0.07971818726014807\n",
      "Accuracy: 0.9318181818181818\n",
      "Epoch: 200 --- cost = 0.04456369243681402\n",
      "Accuracy: 0.9545454545454546\n",
      "Epoch: 300 --- cost = 0.03432267378786059\n",
      "Accuracy: 0.9696969696969697\n",
      "[[3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "# è®­ç»ƒæ¨¡å‹\n",
    "pred, W, b = model(X_train, Y_train, word_to_vec_map)\n",
    "# model(...) è¿”å›ä¸‰ä¸ªå€¼ï¼š\n",
    "# pred -- numpy æ•°ç»„ï¼Œæ¨¡å‹å¯¹è®­ç»ƒé›† X_train çš„é¢„æµ‹æ ‡ç­¾ï¼Œå½¢çŠ¶ (m, 1)\n",
    "# W    -- softmax å±‚çš„æƒé‡çŸ©é˜µï¼Œå½¢çŠ¶ (n_y, n_h)ï¼Œè¿™é‡Œ n_y=5ï¼ˆç±»åˆ«æ•°ï¼‰ï¼Œn_h=50ï¼ˆGloVe å‘é‡ç»´åº¦ï¼‰\n",
    "# b    -- softmax å±‚çš„åç½®å‘é‡ï¼Œå½¢çŠ¶ (n_y,)\n",
    "\n",
    "# è¾“å‡ºè®­ç»ƒåçš„é¢„æµ‹ç»“æœ\n",
    "print(pred)\n",
    "# pred çš„æ¯ä¸ªå…ƒç´ æ˜¯è®­ç»ƒé›†ä¸­æ¯ä¸ªå¥å­çš„é¢„æµ‹ emoji ç±»åˆ«ï¼ˆæ•´æ•°ç´¢å¼•ï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output** (on a subset of iterations):\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Epoch: 0**\n",
    "        </td>\n",
    "        <td>\n",
    "           cost = 1.95204988128\n",
    "        </td>\n",
    "        <td>\n",
    "           Accuracy: 0.348484848485\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "        <td>\n",
    "            **Epoch: 100**\n",
    "        </td>\n",
    "        <td>\n",
    "           cost = 0.0797181872601\n",
    "        </td>\n",
    "        <td>\n",
    "           Accuracy: 0.931818181818\n",
    "        </td>\n",
    "    </tr>\n",
    "    \n",
    "<tr>\n",
    "        <td>\n",
    "            **Epoch: 200**\n",
    "        </td>\n",
    "        <td>\n",
    "           cost = 0.0445636924368\n",
    "        </td>\n",
    "        <td>\n",
    "           Accuracy: 0.954545454545\n",
    "        </td>\n",
    "    </tr>\n",
    "    \n",
    "    <tr>\n",
    "        <td>\n",
    "            **Epoch: 300**\n",
    "        </td>\n",
    "        <td>\n",
    "           cost = 0.0343226737879\n",
    "        </td>\n",
    "        <td>\n",
    "           Accuracy: 0.969696969697\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¤ªæ£’äº†ï¼ä½ çš„æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„å‡†ç¡®ç‡ç›¸å½“é«˜ã€‚  \n",
    "ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å®ƒåœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°å¦‚ä½•ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### 1.4 - æµ‹è¯•é›†æ€§èƒ½è¯„ä¼°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.9772727272727273\n",
      "Test set:\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# å¯¹è®­ç»ƒé›†è¿›è¡Œé¢„æµ‹\n",
    "# ----------------------------\n",
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "# è°ƒç”¨ predict å‡½æ•°ï¼š\n",
    "# X_train -- è¾“å…¥å¥å­åˆ—è¡¨\n",
    "# Y_train -- çœŸå®æ ‡ç­¾\n",
    "# W, b -- æ¨¡å‹è®­ç»ƒå¾—åˆ°çš„ softmax å‚æ•°\n",
    "# word_to_vec_map -- GloVe è¯å‘é‡å­—å…¸\n",
    "# è¿”å› pred_trainï¼šè®­ç»ƒé›†çš„é¢„æµ‹ç»“æœï¼Œå½¢çŠ¶ (m, 1)\n",
    "# å‡½æ•°å†…éƒ¨ä¼šï¼š\n",
    "#   1. å°†æ¯ä¸ªå¥å­æ‹†åˆ†æˆå•è¯\n",
    "#   2. å–æ¯ä¸ªå•è¯çš„ GloVe å‘é‡å¹¶æ±‚å¹³å‡å¾—åˆ°å¥å­å‘é‡\n",
    "#   3. è®¡ç®— Z = WÂ·avg + b\n",
    "#   4. é€šè¿‡ softmax å¾—åˆ°æ¦‚ç‡å‘é‡\n",
    "#   5. å–æœ€å¤§æ¦‚ç‡ç´¢å¼•ä½œä¸ºé¢„æµ‹\n",
    "#   6. è®¡ç®—é¢„æµ‹å‡†ç¡®ç‡å¹¶æ‰“å°\n",
    "\n",
    "# ----------------------------\n",
    "# å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹\n",
    "# ----------------------------\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)\n",
    "# ç”¨è®­ç»ƒå¥½çš„ W å’Œ b å¯¹æµ‹è¯•é›† X_test è¿›è¡Œé¢„æµ‹\n",
    "# è¿”å› pred_testï¼šæµ‹è¯•é›†çš„é¢„æµ‹ç»“æœï¼Œå½¢çŠ¶ (m_test, 1)\n",
    "# åŒæ ·å†…éƒ¨ä¼šæ‰“å°æµ‹è¯•é›†çš„å‡†ç¡®ç‡\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Train set accuracy**\n",
    "        </td>\n",
    "        <td>\n",
    "           97.7\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Test set accuracy**\n",
    "        </td>\n",
    "        <td>\n",
    "           85.7\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨æœ‰ 5 ä¸ªç±»åˆ«çš„æƒ…å†µä¸‹ï¼ŒéšæœºçŒœæµ‹çš„å‡†ç¡®ç‡åªæœ‰ 20%ã€‚  \n",
    "è€Œåœ¨ä»…ç”¨ 127 ä¸ªæ ·æœ¬è®­ç»ƒåï¼Œä½ çš„æ¨¡å‹å°±èƒ½è¾¾åˆ°è¿™æ ·çš„æ€§èƒ½ï¼Œå·²ç»ç›¸å½“ä¸é”™äº†ã€‚\n",
    "\n",
    "åœ¨è®­ç»ƒé›†ä¸­ï¼Œç®—æ³•è§è¿‡å¥å­ \"*I love you*\"ï¼Œå¯¹åº”æ ‡ç­¾ä¸º â¤ï¸ã€‚  \n",
    "ç„¶è€Œï¼Œä½ å¯ä»¥æ³¨æ„åˆ°å•è¯ \"adore\" å¹¶æœªå‡ºç°åœ¨è®­ç»ƒé›†ä¸­ã€‚  \n",
    "å°½ç®¡å¦‚æ­¤ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹è¾“å…¥ \"*I adore you*\" æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n",
      "\n",
      "i adore you â¤ï¸\n",
      "i love you â¤ï¸\n",
      "funny lol :smile:\n",
      "lets play with a ball âš¾\n",
      "food is ready ğŸ´\n",
      "not feeling happy :smile:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luxia\\AppData\\Local\\Temp\\ipykernel_33892\\3157549296.py:129: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(X[i], label_to_emoji(int(pred[i])))\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# è‡ªå®šä¹‰å¥å­åŠå¯¹åº”æ ‡ç­¾\n",
    "# ----------------------------\n",
    "X_my_sentences = np.array([\n",
    "    \"i adore you\",             # å¥å­1\n",
    "    \"i love you\",              # å¥å­2\n",
    "    \"funny lol\",               # å¥å­3\n",
    "    \"lets play with a ball\",   # å¥å­4\n",
    "    \"food is ready\",           # å¥å­5\n",
    "    \"not feeling happy\"        # å¥å­6\n",
    "])\n",
    "\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "# æ¯ä¸ªå¥å­çš„çœŸå®æ ‡ç­¾\n",
    "# 0: â¤ï¸ (heart)\n",
    "# 1: âš¾ (baseball)\n",
    "# 2: ğŸ˜„ (smile)\n",
    "# 3: ğŸ˜ (disappointed)\n",
    "# 4: ğŸ´ (fork_and_knife)\n",
    "\n",
    "# ----------------------------\n",
    "# å¯¹è‡ªå®šä¹‰å¥å­è¿›è¡Œé¢„æµ‹\n",
    "# ----------------------------\n",
    "pred = predict(X_my_sentences, Y_my_labels, W, b, word_to_vec_map)\n",
    "# predict å‡½æ•°å†…éƒ¨æ­¥éª¤ï¼š\n",
    "# 1. éå†æ¯ä¸ªå¥å­ï¼Œå°†å¥å­æ‹†æˆå•è¯\n",
    "# 2. å¯¹æ¯ä¸ªå•è¯å– GloVe è¯å‘é‡\n",
    "# 3. æ±‚å¥å­æ‰€æœ‰è¯å‘é‡çš„å¹³å‡ï¼Œå¾—åˆ°å¥å­å‘é‡ avg\n",
    "# 4. å‰å‘ä¼ æ’­è®¡ç®— Z = W Â· avg + b\n",
    "# 5. é€šè¿‡ softmax å¾—åˆ°æ¦‚ç‡åˆ†å¸ƒ\n",
    "# 6. å–æ¦‚ç‡æœ€å¤§å€¼å¯¹åº”ç´¢å¼•ä½œä¸ºé¢„æµ‹ç»“æœ\n",
    "# 7. æ‰“å°é¢„æµ‹çš„å‡†ç¡®ç‡\n",
    "\n",
    "# ----------------------------\n",
    "# æ‰“å°é¢„æµ‹ç»“æœ\n",
    "# ----------------------------\n",
    "print_predictions(X_my_sentences, pred)\n",
    "# print_predictions å‡½æ•°ï¼š\n",
    "# éå†æ¯ä¸ªå¥å­\n",
    "# è°ƒç”¨ label_to_emoji(pred[i]) å°†é¢„æµ‹çš„æ ‡ç­¾ç´¢å¼•è½¬æ¢ä¸º emoji\n",
    "# æ‰“å° \"å¥å­ â†’ emoji\"\n",
    "# ä¾‹å¦‚è¾“å‡ºï¼š\n",
    "# i adore you â¤ï¸\n",
    "# funny lol ğŸ˜„\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¤ªæ£’äº†ï¼ç”±äº *adore* ä¸ *love* çš„è¯å‘é‡ç›¸ä¼¼ï¼Œç®—æ³•èƒ½å¤Ÿæ­£ç¡®æ³›åŒ–ï¼Œå³ä½¿æ˜¯ä¸€ä¸ªä»æœªè§è¿‡çš„å•è¯ä¹Ÿèƒ½å¤„ç†æ­£ç¡®ã€‚  \n",
    "åƒ *heart*ã€*dear*ã€*beloved* æˆ– *adore* è¿™æ ·çš„è¯ï¼Œå…¶è¯å‘é‡éƒ½ä¸ *love* ç±»ä¼¼ï¼Œå› æ­¤ä¹Ÿå¯èƒ½åŒæ ·æœ‰æ•ˆâ€”â€”ä½ å¯ä»¥è‡ªç”±ä¿®æ”¹ä¸Šè¿°è¾“å…¥ï¼Œå°è¯•å„ç§å¥å­ï¼Œçœ‹çœ‹æ•ˆæœå¦‚ä½•ã€‚\n",
    "\n",
    "éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç®—æ³•æ— æ³•æ­£ç¡®å¤„ç† \"*not feeling happy*\" è¿™ç§æƒ…å†µã€‚  \n",
    "è¿™æ˜¯å› ä¸ºè¯¥ç®—æ³•å¿½ç•¥äº†**å•è¯é¡ºåº**ï¼Œå› æ­¤ä¸æ“…é•¿ç†è§£è¯¸å¦‚ \"*not happy*\" è¿™æ ·çš„çŸ­è¯­ã€‚\n",
    "\n",
    "æ‰“å° **æ··æ·†çŸ©é˜µï¼ˆconfusion matrixï¼‰** ä¹Ÿèƒ½å¸®åŠ©ç†è§£å“ªäº›ç±»åˆ«å¯¹ä½ çš„æ¨¡å‹æ¥è¯´æ›´éš¾ã€‚  \n",
    "æ··æ·†çŸ©é˜µæ˜¾ç¤ºäº†æŸä¸ªå®é™…æ ‡ç­¾ä¸ºæŸç±»åˆ«ï¼ˆ\"actual\" classï¼‰çš„æ ·æœ¬ï¼Œè¢«ç®—æ³•è¯¯æ ‡ä¸ºå…¶ä»–ç±»åˆ«ï¼ˆ\"predicted\" class\"ï¼‰çš„é¢‘ç‡ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n",
      "           â¤ï¸    âš¾    :smile:    :disappointed:   ğŸ´\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# æŸ¥çœ‹æµ‹è¯•é›†æ ‡ç­¾çš„å½¢çŠ¶\n",
    "# ----------------------------\n",
    "print(Y_test.shape)\n",
    "# è¾“å‡º (56,) â†’ æµ‹è¯•é›†æœ‰ 56 ä¸ªå¥å­\n",
    "\n",
    "# ----------------------------\n",
    "# æ‰“å°åˆ—æ ‡é¢˜ï¼ˆemoji è¡¨ç¤ºæ¯ä¸ªç±»åˆ«ï¼‰\n",
    "# ----------------------------\n",
    "print('           ' + label_to_emoji(0) + '    ' + label_to_emoji(1) + '    ' + label_to_emoji(2) + '    ' + label_to_emoji(3) + '   ' + label_to_emoji(4))\n",
    "# label_to_emoji å‡½æ•°å°†ç±»åˆ«ç´¢å¼•è½¬æ¢ä¸º emoji\n",
    "# è¾“å‡ºç¤ºä¾‹ï¼š           â¤ï¸    âš¾    ğŸ˜„    ğŸ˜   ğŸ´\n",
    "\n",
    "# ----------------------------\n",
    "# ç”Ÿæˆæµ‹è¯•é›†æ··æ·†çŸ©é˜µ\n",
    "# ----------------------------\n",
    "pd.crosstab(\n",
    "    Y_test,                        # è¡Œï¼šçœŸå®æ ‡ç­¾\n",
    "    pred_test.reshape(56,),        # åˆ—ï¼šé¢„æµ‹æ ‡ç­¾\n",
    "    rownames=['Actual'],           # è¡Œå\n",
    "    colnames=['Predicted'],        # åˆ—å\n",
    "    margins=True                   # æ·»åŠ è¡Œ/åˆ—æ€»è®¡\n",
    ")\n",
    "# è¾“å‡ºä¸€ä¸ª DataFrameï¼Œæ˜¾ç¤ºæ¯ä¸ªçœŸå®ç±»åˆ«è¢«é¢„æµ‹ä¸ºå„ç±»åˆ«çš„æ¬¡æ•°\n",
    "# margins=True ä¼šåœ¨æœ€åä¸€è¡Œ/åˆ—æ˜¾ç¤ºæ€»å’Œ\n",
    "\n",
    "# ----------------------------\n",
    "# å¯è§†åŒ–æ··æ·†çŸ©é˜µ\n",
    "# ----------------------------\n",
    "plot_confusion_matrix(Y_test, pred_test)\n",
    "# plot_confusion_matrix å‡½æ•°æ­¥éª¤ï¼š\n",
    "# 1. ç”¨ pd.crosstab æ„å»ºæ··æ·†çŸ©é˜µ\n",
    "# 2. å½’ä¸€åŒ–ï¼ˆé™¤ä»¥æ¯è¡Œæ€»å’Œï¼‰å¾—åˆ°æ¯ä¸ªç±»åˆ«é¢„æµ‹æ¯”ä¾‹\n",
    "# 3. plt.matshow æ˜¾ç¤ºçŸ©é˜µï¼Œé¢œè‰²è¡¨ç¤ºé¢„æµ‹æ•°é‡\n",
    "# 4. è®¾ç½®åæ ‡è½´æ ‡ç­¾ã€æ ‡é¢˜ã€é¢œè‰²æ¡\n",
    "# 5. è¾“å‡ºå›¾åƒæ–¹ä¾¿ç›´è§‚åˆ†ææ¨¡å‹é¢„æµ‹æƒ…å†µ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**æœ¬éƒ¨åˆ†éœ€è¦è®°ä½çš„å†…å®¹**ï¼š\n",
    "- å³ä½¿åªæœ‰ 127 ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œä½ ä¹Ÿå¯ä»¥å¾—åˆ°ä¸€ä¸ªç›¸å½“ä¸é”™çš„è¡¨æƒ…ç¬¦å·ç”Ÿæˆæ¨¡å‹ã€‚è¿™è¦å½’åŠŸäºè¯å‘é‡æä¾›çš„æ³›åŒ–èƒ½åŠ›ã€‚  \n",
    "- Emojify-V1 åœ¨å¤„ç†åƒ *\"This movie is not good and not enjoyable\"* è¿™æ ·çš„å¥å­æ—¶è¡¨ç°ä¸ä½³ï¼Œå› ä¸ºå®ƒæ— æ³•ç†è§£å•è¯ç»„åˆâ€”â€”å®ƒåªæ˜¯å°†æ‰€æœ‰å•è¯çš„è¯å‘é‡å¹³å‡ï¼Œè€Œä¸å…³æ³¨å•è¯çš„é¡ºåºã€‚ä½ å°†åœ¨ä¸‹ä¸€éƒ¨åˆ†æ„å»ºä¸€ä¸ªæ›´å¥½çš„ç®—æ³•ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Emojifier-V2ï¼šåœ¨Pytorchä¸­ä½¿ç”¨ LSTM\n",
    "\n",
    "è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ª **LSTM æ¨¡å‹**ï¼Œè¾“å…¥ä¸ºå•è¯åºåˆ—ã€‚  \n",
    "è¯¥æ¨¡å‹èƒ½å¤Ÿè€ƒè™‘å•è¯çš„é¡ºåºã€‚Emojifier-V2 å°†ç»§ç»­ä½¿ç”¨**é¢„è®­ç»ƒè¯å‘é‡**æ¥è¡¨ç¤ºå•è¯ï¼Œä½†ä¼šå°†è¿™äº›è¯å‘é‡è¾“å…¥åˆ° LSTM ä¸­ï¼Œç”± LSTM é¢„æµ‹æœ€åˆé€‚çš„è¡¨æƒ…ç¬¦å·ã€‚\n",
    "\n",
    "è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒä»¥åŠ è½½Pytorchæ‰€éœ€çš„åŒ…ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# å¯¼å…¥å¸¸ç”¨åº“\n",
    "# ----------------------------\n",
    "import numpy as np  \n",
    "# å¯¼å…¥ NumPy åº“ï¼Œç”¨äºé«˜æ•ˆçš„æ•°å€¼è®¡ç®—ã€æ•°ç»„æ“ä½œå’Œçº¿æ€§ä»£æ•°è¿ç®—\n",
    "\n",
    "import torch  \n",
    "# å¯¼å…¥ PyTorch ä¸»åº“ï¼Œç”¨äºå¼ é‡æ“ä½œã€è‡ªåŠ¨æ±‚å¯¼å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹æ„å»º\n",
    "\n",
    "import torch.nn as nn  \n",
    "# å¯¼å…¥ torch.nn æ¨¡å—ï¼Œå…¶ä¸­åŒ…å«æ„å»ºç¥ç»ç½‘ç»œçš„å„ç±»å±‚ï¼ˆå¦‚ Linear, Conv2d, LSTM ç­‰ï¼‰\n",
    "# nn æ˜¯æ„å»ºæ¨¡å‹çš„åŸºç¡€æ¨¡å—\n",
    "\n",
    "import torch.nn.functional as F  \n",
    "# å¯¼å…¥ torch.nn.functional æ¨¡å—ï¼Œæä¾›äº†å¤§é‡å‡½æ•°åŒ–çš„æ“ä½œï¼Œå¦‚æ¿€æ´»å‡½æ•°ï¼ˆrelu, softmax ç­‰ï¼‰ã€æŸå¤±å‡½æ•°ç­‰\n",
    "# ä¸ nn.Module ä¸­çš„å±‚ä¸åŒï¼Œfunctional æä¾›çš„æ˜¯â€œå‡½æ•°å¼â€æ“ä½œï¼Œä¸åŒ…å«å¯å­¦ä¹ å‚æ•°\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "# Datasetï¼šç”¨äºå°è£…è‡ªå®šä¹‰æ•°æ®é›†ï¼Œå¿…é¡»å®ç° __len__() å’Œ __getitem__() æ–¹æ³•\n",
    "# DataLoaderï¼šæä¾›æ‰¹é‡è¯»å–æ•°æ®ã€æ‰“ä¹±é¡ºåºå’Œå¤šçº¿ç¨‹åŠ è½½çš„åŠŸèƒ½\n",
    "# å¸¸ç”¨äºè®­ç»ƒå¾ªç¯ä¸­æŒ‰ batch è·å–æ•°æ®\n",
    "\n",
    "import random  \n",
    "# Python æ ‡å‡†åº“çš„ random æ¨¡å—ï¼Œç”¨äºç”Ÿæˆéšæœºæ•°ã€éšæœºé€‰æ‹©æˆ–æ‰“ä¹±æ•°æ®\n",
    "# åœ¨è®­ç»ƒæˆ–åˆå§‹åŒ–æƒé‡æ—¶å¸¸ç”¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# è®¾å¤‡é€‰æ‹©ï¼ˆCPU / GPUï¼‰\n",
    "# ----------------------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "# torch.device()ï¼šPyTorch ä¸­è¡¨ç¤ºå­˜æ”¾å¼ é‡å’Œæ¨¡å‹çš„è®¾å¤‡å¯¹è±¡\n",
    "# \"cuda\"ï¼šè¡¨ç¤º GPUï¼Œå¦‚æœæœ‰å¯ç”¨çš„ NVIDIA GPUï¼Œå¯ç”¨äºåŠ é€Ÿè®¡ç®—\n",
    "# \"cpu\"ï¼šè¡¨ç¤ºä½¿ç”¨ CPU è¿›è¡Œè®¡ç®—\n",
    "# torch.cuda.is_available()ï¼šæ£€æŸ¥å½“å‰ç³»ç»Ÿæ˜¯å¦æœ‰å¯ç”¨çš„ GPU\n",
    "# è¯­å¥å«ä¹‰ï¼šå¦‚æœæœ‰å¯ç”¨ GPUï¼Œåˆ™ä½¿ç”¨ GPUï¼›å¦åˆ™é€€å›åˆ° CPU\n",
    "# å°† device å¯¹è±¡ä¼ ç»™å¼ é‡æˆ–æ¨¡å‹ï¼Œå¯ä»¥å®ç°å¼ é‡/æ¨¡å‹åœ¨ GPU ä¸Šè¿ç®—\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - æ¨¡å‹æ¦‚è§ˆï¼ˆPyTorch ç‰ˆæœ¬ï¼‰\n",
    "\n",
    "ä¸‹é¢æ˜¯ä½ å°†è¦å®ç°çš„ **Emojifier-V2** PyTorch ç‰ˆæœ¬ï¼š\n",
    "\n",
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center> **å›¾ 3**ï¼šEmojifier-V2ã€‚ä¸€ä¸ªä¸¤å±‚ LSTM åºåˆ—åˆ†ç±»å™¨ã€‚</center></caption>\n",
    "\n",
    "åœ¨ PyTorch ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ `nn.Embedding`ã€`nn.LSTM` å’Œ `nn.Linear` æ¥å®ç°è¿™ä¸ªæ¨¡å‹ã€‚  \n",
    "è®­ç»ƒæ–¹å¼ä¹Ÿå°†ä½¿ç”¨ mini-batchï¼ŒPyTorch ä¸­è¦æ±‚åŒä¸€ mini-batch çš„æ‰€æœ‰åºåˆ—é•¿åº¦ç›¸åŒï¼Œè¿™ä¸ Keras ç›¸åŒã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Mini-batch ä¸å¡«å……ï¼ˆPaddingï¼‰\n",
    "\n",
    "åœ¨ PyTorch ä¸­å¤„ç†ä¸åŒé•¿åº¦çš„åºåˆ—æ—¶ä¹Ÿå¿…é¡»è¿›è¡Œ **å¡«å……ï¼ˆpaddingï¼‰**ã€‚  \n",
    "å…·ä½“æ–¹æ³•ä¸ Keras ç›¸åŒï¼šè®¾å®šæœ€å¤§å¥å­é•¿åº¦ `max_len`ï¼Œå°†æ‰€æœ‰åºåˆ—å¡«å……æˆ–æˆªæ–­åˆ°ç›¸åŒé•¿åº¦ã€‚ä¾‹å¦‚ï¼š\n",
    "å› æ­¤ï¼Œå¥å­ \"i love you\" å°†è¡¨ç¤ºä¸ºï¼š\n",
    "$$(e_{i}, e_{love}, e_{you}, \\vec{0}, \\vec{0}, \\ldots, \\vec{0})$$\n",
    "\n",
    "å…¶ä¸­ 0 è¡¨ç¤ºå¡«å……å€¼ï¼Œé•¿åº¦ç»Ÿä¸€ä¸º `max_len`ã€‚  \n",
    "è¿™ä½¿å¾—åºåˆ—å¯ä»¥åŒæ—¶è¢«é€å…¥ LSTMï¼Œä¾¿äºæ‰¹é‡è®¡ç®—ã€‚\n",
    "\n",
    "åœ¨ PyTorch ä¸­ï¼Œå¯ä»¥é€šè¿‡è‡ªå®šä¹‰å‡½æ•° `sentences_to_indices()` å°†å¥å­è½¬æ¢ä¸ºç´¢å¼•çŸ©é˜µã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - åµŒå…¥å±‚ï¼ˆEmbedding layerï¼‰\n",
    "\n",
    "åœ¨ PyTorch ä¸­ï¼ŒåµŒå…¥çŸ©é˜µç”± `nn.Embedding` è¡¨ç¤ºï¼Œå®ƒå°†æ­£æ•´æ•°ï¼ˆå•è¯ç´¢å¼•ï¼‰æ˜ å°„åˆ°å›ºå®šå¤§å°çš„ç¨ å¯†å‘é‡ï¼ˆembedding å‘é‡ï¼‰ã€‚  \n",
    "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒçš„ GloVe è¯å‘é‡åˆå§‹åŒ–è¯¥å±‚ï¼Œå¹¶å°†å…¶è®¾ç½®ä¸º **ä¸å¯è®­ç»ƒï¼ˆfreeze=Trueï¼‰**ï¼Œä¿æŒè¯å‘é‡å›ºå®šã€‚\n",
    "\n",
    "`Embedding()` å±‚çš„è¾“å…¥æ˜¯ä¸€ä¸ªæ•´æ•°çŸ©é˜µï¼Œå½¢çŠ¶ä¸º **(batch size, max input length)**ã€‚  \n",
    "è¿™å¯¹åº”äºå°†å¥å­è½¬æ¢ä¸ºç´¢å¼•åˆ—è¡¨ï¼ˆæ•´æ•°ï¼‰ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\n",
    "\n",
    "<img src=\"images/embedding1.png\" style=\"width:700px;height:250px;\">\n",
    "<caption><center> **å›¾ 4**ï¼šåµŒå…¥å±‚ç¤ºæ„å›¾ã€‚è¯¥ç¤ºä¾‹å±•ç¤ºäº†ä¸¤ä¸ªæ ·æœ¬é€šè¿‡åµŒå…¥å±‚çš„ä¼ æ’­è¿‡ç¨‹ã€‚  \n",
    "ä¸¤ä¸ªæ ·æœ¬éƒ½è¢«ç”¨ 0 å¡«å……è‡³é•¿åº¦ `max_len=5`ã€‚æœ€ç»ˆè¡¨ç¤ºçš„ç»´åº¦ä¸º `(2, max_len, 50)`ï¼Œå› ä¸ºä½¿ç”¨çš„è¯å‘é‡ä¸º 50 ç»´ã€‚</center></caption>\n",
    "\n",
    "è¾“å…¥ä¸­çš„æœ€å¤§æ•´æ•°ï¼ˆå³å•è¯ç´¢å¼•ï¼‰ä¸åº”å¤§äºè¯æ±‡è¡¨å¤§å°ã€‚  \n",
    "è¯¥å±‚è¾“å‡ºå½¢çŠ¶ä¸º **(batch size, max input length, è¯å‘é‡ç»´åº¦)**ã€‚\n",
    "\n",
    "ç¬¬ä¸€æ­¥æ˜¯å°†æ‰€æœ‰è®­ç»ƒå¥å­è½¬æ¢ä¸ºç´¢å¼•åˆ—è¡¨ï¼Œç„¶åå¯¹è¿™äº›åˆ—è¡¨è¿›è¡Œ **é›¶å¡«å……ï¼ˆzero-paddingï¼‰**ï¼Œä½¿å…¶é•¿åº¦ç­‰äºæœ€é•¿å¥å­çš„é•¿åº¦ã€‚\n",
    "\n",
    "å®ç°ä¸‹åˆ—å‡½æ•°ï¼Œå°† **X**ï¼ˆå¥å­æ•°ç»„ï¼Œå­—ç¬¦ä¸²å½¢å¼ï¼‰è½¬æ¢ä¸ºå¯¹åº”å•è¯ç´¢å¼•çš„æ•°ç»„ã€‚  \n",
    "è¾“å‡ºå½¢çŠ¶åº”é€‚ç”¨äº `Embedding()` å±‚ï¼ˆå¦‚å›¾ 4 æ‰€ç¤ºï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# å‡½æ•°ï¼šsentences_to_indices\n",
    "# ----------------------------\n",
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    åŠŸèƒ½ï¼š\n",
    "        å°†æ–‡æœ¬å¥å­è½¬æ¢ä¸ºç´¢å¼•çŸ©é˜µï¼Œæ¯ä¸ªå•è¯ç”¨è¯è¡¨ä¸­çš„ç´¢å¼•è¡¨ç¤ºã€‚\n",
    "        ç”¨äºå°†æ–‡æœ¬æ•°æ®è¾“å…¥åˆ°ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ˆå¦‚ Embedding å±‚ï¼‰ä¸­ã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        X           -- è¾“å…¥å¥å­åˆ—è¡¨ï¼Œé•¿åº¦ä¸º mï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ˆå¥å­ï¼‰\n",
    "        word_to_index -- å­—å…¸ï¼Œå°†å•è¯æ˜ å°„ä¸ºç´¢å¼•ã€‚ä¾‹å¦‚ {'i':1, 'love':2, ...}\n",
    "        max_len     -- æ¯ä¸ªå¥å­çš„æœ€å¤§é•¿åº¦ï¼Œè¶…è¿‡çš„å•è¯æˆªæ–­ï¼Œä¸è¶³çš„å¥å­è¡¥ 0\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "        X_indices   -- numpy æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (m, max_len)ï¼Œæ¯è¡Œæ˜¯å¥å­å¯¹åº”çš„å•è¯ç´¢å¼•\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1. è·å–å¥å­æ•°é‡ m\n",
    "    # ----------------------------\n",
    "    m = len(X)  # len(X) è¿”å›å¥å­æ€»æ•°\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2. åˆå§‹åŒ–ç´¢å¼•çŸ©é˜µ X_indices\n",
    "    # ----------------------------\n",
    "    X_indices = np.zeros((m, max_len))  \n",
    "    # ä½¿ç”¨å…¨ 0 åˆå§‹åŒ–\n",
    "    # shape: (å¥å­æ•°é‡ m, æ¯å¥æœ€å¤§é•¿åº¦ max_len)\n",
    "    # å¦‚æœå¥å­é•¿åº¦ä¸è¶³ max_lenï¼Œè‡ªåŠ¨è¡¥ 0\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3. éå†æ¯ä¸ªå¥å­\n",
    "    # ----------------------------\n",
    "    for i, sentence in enumerate(X):  # enumerate è¿”å›ç´¢å¼• i å’Œå¥å­å†…å®¹ sentence\n",
    "        words = sentence.lower().split()  # å°†å¥å­å°å†™å¹¶æ‹†åˆ†ä¸ºå•è¯åˆ—è¡¨\n",
    "\n",
    "        # ----------------------------\n",
    "        # 4. éå†å¥å­ä¸­çš„å•è¯\n",
    "        # ----------------------------\n",
    "        for j, w in enumerate(words):  # j: å•è¯ä½ç½®, w: å•è¯\n",
    "            if j >= max_len:  # å¦‚æœå¥å­é•¿åº¦è¶…è¿‡ max_lenï¼Œåˆ™æˆªæ–­\n",
    "                break\n",
    "\n",
    "            # ä½¿ç”¨ word_to_index.get() è·å–å•è¯ç´¢å¼•\n",
    "            # å¦‚æœå•è¯ä¸åœ¨è¯è¡¨ä¸­ï¼Œè¿”å› 0\n",
    "            X_indices[i, j] = word_to_index.get(w, 0)\n",
    "\n",
    "    # ----------------------------\n",
    "    # 5. è¿”å›ç´¢å¼•çŸ©é˜µ\n",
    "    # ----------------------------\n",
    "    return X_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒï¼Œä»¥æŸ¥çœ‹ `sentences_to_indices()` çš„ä½œç”¨ï¼Œå¹¶æ£€æŸ¥ä½ çš„ç»“æœã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
      "X1_indices = [[155345. 225122.      0.      0.      0.]\n",
      " [220930. 286375.  69714.      0.      0.]\n",
      " [151204. 192973. 302254. 151349. 394475.]]\n"
     ]
    }
   ],
   "source": [
    "# è¾“å…¥å¥å­åˆ—è¡¨\n",
    "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
    "\n",
    "# è°ƒç”¨ sentences_to_indices å‡½æ•°ï¼Œå°†å¥å­è½¬æˆç´¢å¼•çŸ©é˜µ\n",
    "X1_indices = sentences_to_indices(X1, word_to_index, max_len=5)\n",
    "\n",
    "# è¾“å‡ºå¥å­å’Œå¯¹åº”çš„ç´¢å¼•çŸ©é˜µ\n",
    "print(\"X1 =\", X1)\n",
    "print(\"X1_indices =\", X1_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **X1 =**\n",
    "        </td>\n",
    "        <td>\n",
    "           ['funny lol' 'lets play football' 'food is ready for you']\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **X1_indices =**\n",
    "        </td>\n",
    "        <td>\n",
    "           [[ 155345.  225122.       0.       0.       0.] <br>\n",
    "            [ 220930.  286375.  151266.       0.       0.] <br>\n",
    "            [ 151204.  192973.  302254.  151349.  394475.]]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬åœ¨ **PyTorch** ä¸­æ„å»º `nn.Embedding` å±‚ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„è¯å‘é‡ã€‚  \n",
    "åœ¨æ„å»ºå¥½è¯¥å±‚åï¼Œä½ å°†æŠŠ `sentences_to_indices()` çš„è¾“å‡ºä½œä¸ºè¾“å…¥ä¼ å…¥ï¼ŒEmbedding å±‚å°†è¿”å›å¥å­çš„è¯å‘é‡è¡¨ç¤ºã€‚\n",
    "\n",
    "å®ç° `pretrained_embedding_layer()` çš„æ­¥éª¤å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. åˆå§‹åŒ–åµŒå…¥çŸ©é˜µä¸ºå…¨é›¶çš„ numpy æ•°ç»„ï¼Œå½¢çŠ¶ä¸º `(vocab_len, embedding_dim)`ã€‚  \n",
    "2. éå† `word_to_vec_map`ï¼Œå°†æ¯ä¸ªè¯å¯¹åº”çš„ GloVe å‘é‡å¡«å…¥åµŒå…¥çŸ©é˜µçš„æ­£ç¡®è¡Œã€‚  \n",
    "3. å®šä¹‰ PyTorch çš„ `nn.Embedding` å±‚ï¼Œå¹¶ä½¿ç”¨ `nn.Embedding.from_pretrained()` å°†åµŒå…¥çŸ©é˜µåŠ è½½è¿›å»ï¼š  \n",
    "   - è®¾ç½® `freeze=True`ï¼Œä¿è¯è¯å‘é‡åœ¨è®­ç»ƒä¸­ä¿æŒå›ºå®šã€‚  \n",
    "   - è‹¥è®¾ç½® `freeze=False`ï¼Œè®­ç»ƒæ—¶åµŒå…¥å‘é‡ä¼šè¢«æ›´æ–°ã€‚  \n",
    "4. è¿”å›æ„å»ºå¥½çš„ Embedding å±‚ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    åŠŸèƒ½ï¼š\n",
    "        åˆ›å»ºä¸€ä¸ª PyTorch çš„ Embedding å±‚ï¼Œå¹¶ç”¨é¢„è®­ç»ƒçš„è¯å‘é‡ï¼ˆå¦‚ GloVeï¼‰åˆå§‹åŒ–ã€‚\n",
    "        è¯¥å±‚å¯ä»¥ç›´æ¥ç”¨äºç¥ç»ç½‘ç»œè¾“å…¥ï¼Œå°†å•è¯ç´¢å¼•æ˜ å°„ä¸ºè¯å‘é‡ã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        word_to_vec_map (dict): å­—å…¸ï¼Œå°†æ¯ä¸ªå•è¯æ˜ å°„åˆ°å…¶é¢„è®­ç»ƒè¯å‘é‡ï¼Œä¾‹å¦‚ GloVe\n",
    "                                 æ ¼å¼: {'word': np.array([50ç»´å‘é‡])}\n",
    "        word_to_index (dict): å­—å…¸ï¼Œå°†æ¯ä¸ªå•è¯æ˜ å°„åˆ°å”¯ä¸€ç´¢å¼•\n",
    "                              æ ¼å¼: {'word': index}\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "        embedding_layer (nn.Embedding): PyTorch Embedding å±‚ï¼Œæƒé‡å·²ç»ç”¨é¢„è®­ç»ƒè¯å‘é‡åˆå§‹åŒ–\n",
    "                                        å¹¶ä¸”å‚æ•°å†»ç»“ (freeze=True)ï¼Œä¸å¯è®­ç»ƒ\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1. è·å–è¯æ±‡è¡¨é•¿åº¦ + 1\n",
    "    # ----------------------------\n",
    "    # vocab_len: è¯æ±‡è¡¨å¤§å° + 1ï¼Œå› ä¸ºç´¢å¼•é€šå¸¸ä»1å¼€å§‹ï¼Œ0ä¿ç•™ç»™padding\n",
    "    vocab_len = len(word_to_index) + 1\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2. è·å–è¯å‘é‡ç»´åº¦\n",
    "    # ----------------------------\n",
    "    # emb_dim: è¯å‘é‡çš„ç»´åº¦ï¼Œä¾‹å¦‚ GloVe 50ç»´ã€100ç»´ç­‰\n",
    "    emb_dim = list(word_to_vec_map.values())[0].shape[0]\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3. åˆå§‹åŒ–è¯å‘é‡çŸ©é˜µ\n",
    "    # ----------------------------\n",
    "    # emb_matrix: å½¢çŠ¶ä¸º (vocab_len, emb_dim)\n",
    "    # ç¬¬ i è¡Œå­˜å‚¨ç´¢å¼• i å¯¹åº”çš„è¯å‘é‡\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "\n",
    "    # ----------------------------\n",
    "    # 4. å°†é¢„è®­ç»ƒè¯å‘é‡å¡«å…¥çŸ©é˜µ\n",
    "    # ----------------------------\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]  # ç¬¬ idx è¡Œå°±æ˜¯ word çš„è¯å‘é‡\n",
    "\n",
    "    # ----------------------------\n",
    "    # 5. è½¬ä¸º PyTorch å¼ é‡\n",
    "    # ----------------------------\n",
    "    emb_matrix = torch.tensor(emb_matrix, dtype=torch.float32)\n",
    "\n",
    "    # ----------------------------\n",
    "    # 6. åˆ›å»º PyTorch Embedding å±‚\n",
    "    # ----------------------------\n",
    "    # from_pretrained: ç”¨ç»™å®šæƒé‡åˆå§‹åŒ– Embedding\n",
    "    # freeze=True: å†»ç»“æƒé‡ï¼Œä¸åœ¨è®­ç»ƒä¸­æ›´æ–°\n",
    "    embedding_layer = nn.Embedding.from_pretrained(emb_matrix, freeze=True)\n",
    "\n",
    "    return embedding_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights[0][1][3] = -0.3403\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 1. åˆ›å»ºé¢„è®­ç»ƒåµŒå…¥å±‚\n",
    "# ----------------------------\n",
    "# è°ƒç”¨ä¹‹å‰å®šä¹‰çš„å‡½æ•°ï¼Œç”¨ GloVe è¯å‘é‡åˆå§‹åŒ– Embedding å±‚\n",
    "# embedding_layer: nn.Embedding ç±»å‹ï¼Œæƒé‡å·²å†»ç»“\n",
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. è®¿é—®åµŒå…¥çŸ©é˜µæƒé‡\n",
    "# ----------------------------\n",
    "# embedding_layer.weight è¿”å› Embedding å±‚çš„æƒé‡å¼ é‡\n",
    "# detach(): å°†å¼ é‡ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»ï¼Œä¸è¿½è¸ªæ¢¯åº¦\n",
    "# numpy(): è½¬ä¸º NumPy æ•°ç»„ï¼Œæ–¹ä¾¿ç´¢å¼•æˆ–æ‰“å°\n",
    "weights = embedding_layer.weight.detach().numpy()  # å½¢çŠ¶: (vocab_len, emb_dim)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. æ‰“å°æŒ‡å®šç´¢å¼•çš„è¯å‘é‡å…ƒç´ \n",
    "# ----------------------------\n",
    "# ä¾‹å¦‚ï¼šweights[1][3]\n",
    "# - weights[1] è¡¨ç¤ºè¯æ±‡è¡¨ç´¢å¼•ä¸º 1 çš„å•è¯çš„è¯å‘é‡\n",
    "# - weights[1][3] è¡¨ç¤ºè¯¥è¯å‘é‡çš„ç¬¬ 4 ä¸ªç»´åº¦çš„å€¼\n",
    "print(\"weights[0][1][3] =\", weights[1][3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **weights[0][1][3] =**\n",
    "        </td>\n",
    "        <td>\n",
    "           -0.3403\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 æ„å»º Emojifier-V2\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬æ„å»º **Emojifier-V2** æ¨¡å‹ã€‚  \n",
    "ä½ å°†ä½¿ç”¨ä¹‹å‰æ„å»ºçš„åµŒå…¥å±‚ï¼Œå¹¶å°†å…¶è¾“å‡ºä¼ å…¥ä¸¤å±‚ LSTM ç½‘ç»œï¼Œæœ€åé€šè¿‡å…¨è¿æ¥å±‚è¾“å‡º softmax æ¦‚ç‡ã€‚\n",
    "\n",
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center> **å›¾ 3**ï¼šEmojifier-V2ã€‚ä¸€ä¸ªä¸¤å±‚ LSTM åºåˆ—åˆ†ç±»å™¨ã€‚</center></caption>\n",
    "\n",
    "---\n",
    "\n",
    "åœ¨ PyTorch ä¸­ï¼Œæˆ‘ä»¬ç”¨ `nn.Module` æ„å»ºè¯¥æ¨¡å‹ï¼Œä¸»è¦ç»“æ„å¦‚ä¸‹ï¼š\n",
    "\n",
    "- **è¾“å…¥**ï¼šå¥å­ç´¢å¼•çŸ©é˜µï¼Œå½¢çŠ¶ä¸º `(batch_size, max_len)`  \n",
    "- **Embedding å±‚**ï¼šå°†æ¯ä¸ªå•è¯ç´¢å¼•æ˜ å°„ä¸ºå…¶ GloVe è¯å‘é‡ `(batch_size, max_len, emb_dim)`  \n",
    "- **LSTM å±‚ 1**ï¼šéšè—çŠ¶æ€å¤§å° 128ï¼Œè¿”å›æ•´åºåˆ— `(batch_size, max_len, 128)`  \n",
    "- **Dropout 1**ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæ¦‚ç‡ 0.5  \n",
    "- **LSTM å±‚ 2**ï¼šéšè—çŠ¶æ€å¤§å° 128ï¼Œåªè¿”å›æœ€åä¸€ä¸ªéšè—çŠ¶æ€ `(batch_size, 128)`  \n",
    "- **Dropout 2**ï¼šæ¦‚ç‡ 0.5  \n",
    "- **å…¨è¿æ¥å±‚**ï¼šè¾“å‡ºå¤§å°ä¸º `C=5`  \n",
    "- **Softmax æ¿€æ´»**ï¼šè¾“å‡ºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- Emojify-V2 æ¨¡å‹ ---------------------------- #\n",
    "class EmojifyV2(nn.Module):  \n",
    "    \"\"\"\n",
    "    åŒå±‚ LSTM æ¨¡å‹ï¼Œç”¨äºæ ¹æ®è¾“å…¥å¥å­é¢„æµ‹å¯¹åº”çš„ Emoji è¡¨æƒ…ç±»åˆ«ã€‚\n",
    "    æ¨¡å‹ç»“æ„ï¼š\n",
    "    1. é¢„è®­ç»ƒåµŒå…¥å±‚ï¼ˆä½¿ç”¨ GloVe å‘é‡ï¼‰\n",
    "    2. åŒå±‚ LSTMï¼ˆ128 å•å…ƒï¼‰\n",
    "    3. Dropout æ­£åˆ™åŒ–\n",
    "    4. å…¨è¿æ¥å±‚ + Softmax è¾“å‡ºåˆ†ç±»\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_len, word_to_vec_map, word_to_index, C=5):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–æ¨¡å‹ç»“æ„ã€‚\n",
    "        \n",
    "        å‚æ•°ï¼š\n",
    "        max_len -- intï¼Œè¾“å…¥å¥å­çš„æœ€å¤§é•¿åº¦ï¼ˆç”¨äº Paddingï¼‰\n",
    "        word_to_vec_map -- dictï¼Œè¯åˆ°è¯å‘é‡çš„æ˜ å°„ï¼ˆGloVeï¼‰\n",
    "        word_to_index -- dictï¼Œè¯åˆ°ç´¢å¼•çš„æ˜ å°„\n",
    "        C -- intï¼Œåˆ†ç±»æ•°ï¼ˆä¾‹å¦‚ï¼š5 ç±»è¡¨æƒ…ï¼‰\n",
    "        \"\"\"\n",
    "        # ç»§æ‰¿çˆ¶ç±»æ„é€ å‡½æ•°\n",
    "        super(EmojifyV2, self).__init__()\n",
    "        \n",
    "        # ä¿å­˜æœ€å¤§åºåˆ—é•¿åº¦\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        # ---------------------------- 1ï¸ é¢„è®­ç»ƒåµŒå…¥å±‚ ----------------------------\n",
    "        # ä½¿ç”¨é¢„è®­ç»ƒçš„ GloVe è¯å‘é‡ï¼Œå›ºå®šä¸è®­ç»ƒï¼ˆfreeze=Trueï¼‰\n",
    "        # æ¯ä¸ªè¯è¢«æ˜ å°„ä¸ºä¸€ä¸ª embedding å‘é‡ï¼ˆä¾‹å¦‚ 50 ç»´ï¼‰\n",
    "        self.embedding = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "        \n",
    "        # ---------------------------- 2ï¸ ç¬¬ä¸€å±‚ LSTM ----------------------------\n",
    "        # input_sizeï¼šæ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥å‘é‡çš„ç»´åº¦ï¼ˆå³ embedding_dimï¼‰\n",
    "        # hidden_sizeï¼šLSTM éšè—çŠ¶æ€çš„ç»´åº¦ï¼ˆæ­¤å¤„ä¸º 128ï¼‰\n",
    "        # batch_first=Trueï¼šè¾“å…¥è¾“å‡ºçš„ç¬¬ä¸€ä¸ªç»´åº¦ä¸º batch\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            input_size=self.embedding.embedding_dim,  \n",
    "            hidden_size=128,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Dropout ç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        # ---------------------------- 3ï¸ ç¬¬äºŒå±‚ LSTM ----------------------------\n",
    "        # æ¥æ”¶å‰ä¸€å±‚çš„è¾“å‡ºï¼Œç»§ç»­æå–æ—¶åºç‰¹å¾\n",
    "        self.lstm2 = nn.LSTM(\n",
    "            input_size=128,  \n",
    "            hidden_size=128,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        # ---------------------------- 4ï¸ å…¨è¿æ¥è¾“å‡ºå±‚ ----------------------------\n",
    "        # è¾“å…¥ç»´åº¦ 128ï¼ˆLSTM éšå±‚è¾“å‡ºï¼‰ï¼Œè¾“å‡ºç»´åº¦ä¸ºç±»åˆ«æ•° C\n",
    "        self.fc = nn.Linear(128, C)\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        å‰å‘ä¼ æ’­é€»è¾‘ï¼šå°†è¾“å…¥å¥å­ç´¢å¼•åºåˆ—æ˜ å°„ä¸ºç±»åˆ«æ¦‚ç‡ã€‚\n",
    "        \n",
    "        å‚æ•°ï¼š\n",
    "        X -- å¼ é‡ï¼Œå½¢çŠ¶ (batch_size, max_len)ï¼ŒåŒ…å«è¯ç´¢å¼•åºåˆ—\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "        æ¯ä¸ªæ ·æœ¬çš„åˆ†ç±»æ¦‚ç‡ï¼Œå½¢çŠ¶ (batch_size, C)\n",
    "        \"\"\"\n",
    "        # Step 1: è¯åµŒå…¥\n",
    "        emb = self.embedding(X.long())  \n",
    "        # emb å½¢çŠ¶: (batch_size, max_len, emb_dim)\n",
    "        \n",
    "        # Step 2: ç¬¬ä¸€å±‚ LSTM\n",
    "        lstm_out1, _ = self.lstm1(emb)  \n",
    "        # è¾“å‡º lstm_out1 å½¢çŠ¶: (batch_size, max_len, 128)\n",
    "        \n",
    "        lstm_out1 = self.dropout1(lstm_out1)\n",
    "        \n",
    "        # Step 3: ç¬¬äºŒå±‚ LSTM\n",
    "        lstm_out2, (h_n, _) = self.lstm2(lstm_out1)\n",
    "        # h_n å½¢çŠ¶: (num_layers=1, batch_size, hidden_size=128)\n",
    "        \n",
    "        # Step 4: å–æœ€åä¸€å±‚ LSTM çš„æœ€åä¸€ä¸ªéšè—çŠ¶æ€\n",
    "        lstm_out2 = self.dropout2(h_n[-1])  \n",
    "        # lstm_out2 å½¢çŠ¶: (batch_size, 128)\n",
    "        \n",
    "        # Step 5: å…¨è¿æ¥å±‚ + Softmax\n",
    "        out = self.fc(lstm_out2)  \n",
    "        # out å½¢çŠ¶: (batch_size, C)\n",
    "        \n",
    "        return F.softmax(out, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- è®­ç»ƒå‡½æ•°ï¼ˆå¸¦è¿›åº¦æ˜¾ç¤ºï¼‰ ---------------------------- #\n",
    "from tqdm import tqdm   # tqdm ç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¾ç¤ºåŠ¨æ€è¿›åº¦æ¡\n",
    "\n",
    "def train(model, X_train_indices, Y_train_oh, num_epochs=50, batch_size=32, lr=0.001):\n",
    "    \"\"\"\n",
    "    æ¨¡å‹è®­ç»ƒå‡½æ•°ï¼ˆå¸¦è¿›åº¦æ˜¾ç¤ºä¸æ€§èƒ½è¯„ä¼°ï¼‰\n",
    "\n",
    "    å‚æ•°è¯´æ˜ï¼š\n",
    "    model           -- PyTorch æ¨¡å‹å¯¹è±¡ï¼ˆå¦‚ EmojifyV2 å®ä¾‹ï¼‰\n",
    "    X_train_indices -- è®­ç»ƒé›†è¾“å…¥ï¼ˆå·²è½¬ä¸ºè¯ç´¢å¼•çš„ numpy æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (m, maxLen)ï¼‰\n",
    "    Y_train_oh      -- è®­ç»ƒé›†æ ‡ç­¾çš„ one-hot ç¼–ç ï¼ˆå½¢çŠ¶ä¸º (m, C)ï¼‰\n",
    "    num_epochs      -- è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤ 50ï¼‰\n",
    "    batch_size      -- æ¯æ‰¹æ¬¡æ ·æœ¬æ•°ï¼ˆé»˜è®¤ 32ï¼‰\n",
    "    lr              -- å­¦ä¹ ç‡ï¼ˆé»˜è®¤ 0.001ï¼‰\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------------------------- 1ï¸âƒ£ ä¼˜åŒ–å™¨ä¸æŸå¤±å‡½æ•° ----------------------------\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  \n",
    "    # ä½¿ç”¨ Adam ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°ï¼Œèƒ½è‡ªåŠ¨è°ƒèŠ‚å­¦ä¹ ç‡\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    # äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼šç”¨äºå¤šåˆ†ç±»é—®é¢˜ï¼ˆå†…éƒ¨è‡ªåŠ¨åš softmaxï¼‰\n",
    "\n",
    "    # ---------------------------- 2ï¸âƒ£ æ„å»ºæ•°æ®åŠ è½½å™¨ ----------------------------\n",
    "    dataset = torch.utils.data.TensorDataset(\n",
    "        torch.tensor(X_train_indices, dtype=torch.long),                   # è¾“å…¥ç´¢å¼•å¼ é‡\n",
    "        torch.tensor(np.argmax(Y_train_oh, axis=1), dtype=torch.long)      # æ ‡ç­¾è½¬ä¸ºç±»åˆ«ç´¢å¼•\n",
    "    )\n",
    "\n",
    "    # DataLoader ä¼šè‡ªåŠ¨æ‰“ä¹±ï¼ˆshuffle=Trueï¼‰å¹¶æŒ‰æ‰¹ï¼ˆbatch_sizeï¼‰åŠ è½½æ•°æ®\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # å°†æ¨¡å‹æ”¾åˆ°è®¾å¤‡ä¸Šï¼ˆGPU æˆ– CPUï¼‰\n",
    "    model.to(device)\n",
    "\n",
    "    # ---------------------------- 3ï¸âƒ£ è®­ç»ƒå¾ªç¯ ----------------------------\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()      # å¯ç”¨è®­ç»ƒæ¨¡å¼ï¼ˆDropout ç”Ÿæ•ˆï¼‰\n",
    "        total_loss = 0.0   # ç´¯è®¡æŸå¤±\n",
    "        correct = 0        # é¢„æµ‹æ­£ç¡®æ ·æœ¬æ•°\n",
    "        total = 0          # æ€»æ ·æœ¬æ•°\n",
    "\n",
    "        # tqdm ç”¨äºæ˜¾ç¤ºå½“å‰ epoch çš„è®­ç»ƒè¿›åº¦æ¡\n",
    "        pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "        for X_batch, Y_batch in pbar:\n",
    "            # å°†å½“å‰æ‰¹æ•°æ®åŠ è½½åˆ° GPU æˆ– CPU\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "\n",
    "            # ------------------ å‰å‘ä¼ æ’­ ------------------\n",
    "            out = model(X_batch)          # æ¨¡å‹é¢„æµ‹è¾“å‡º (batch_size, C)\n",
    "            loss = criterion(out, Y_batch)  # è®¡ç®—äº¤å‰ç†µæŸå¤±\n",
    "\n",
    "            # ------------------ åå‘ä¼ æ’­ ------------------\n",
    "            optimizer.zero_grad()   # æ¸…ç©ºä¸Šä¸€æ­¥çš„æ¢¯åº¦\n",
    "            loss.backward()         # åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦\n",
    "            optimizer.step()        # æ›´æ–°å‚æ•°ï¼ˆæ ¹æ®æ¢¯åº¦ä¸‹é™ï¼‰\n",
    "\n",
    "            # ------------------ ç»Ÿè®¡æ€§èƒ½æŒ‡æ ‡ ------------------\n",
    "            total_loss += loss.item()                         # ç´¯åŠ æœ¬æ‰¹æ¬¡çš„æŸå¤±\n",
    "            preds = torch.argmax(out, dim=1)                  # è·å–é¢„æµ‹ç±»åˆ«\n",
    "            correct += (preds == Y_batch).sum().item()        # ç´¯åŠ æ­£ç¡®é¢„æµ‹æ•°\n",
    "            total += Y_batch.size(0)                          # ç´¯åŠ æ ·æœ¬æ€»æ•°\n",
    "\n",
    "            # tqdm å®æ—¶æ˜¾ç¤ºå½“å‰æ‰¹æ¬¡çš„ loss ä¸å‡†ç¡®ç‡\n",
    "            pbar.set_postfix({\n",
    "                \"loss\": f\"{loss.item():.4f}\",\n",
    "                \"acc\": f\"{(correct / total):.4f}\"\n",
    "            })\n",
    "\n",
    "        # ---------------------------- 4ï¸âƒ£ æ¯ä¸ª epoch æ‰“å°æ±‡æ€» ----------------------------\n",
    "        avg_loss = total_loss / len(loader)  # å¹³å‡æŸå¤±\n",
    "        acc = correct / total                # å¹³å‡å‡†ç¡®ç‡\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"{len(loader)}/{len(loader)} [==============================] \"\n",
    "              f\"- loss: {avg_loss:.4f} - acc: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- æµ‹è¯•è¯„ä¼°å‡½æ•° ---------------------------- #\n",
    "def evaluate(model, X_test_indices, Y_test_oh):\n",
    "    \"\"\"\n",
    "    æ¨¡å‹è¯„ä¼°å‡½æ•°ï¼ˆevaluation functionï¼‰\n",
    "    ä½œç”¨ï¼šåœ¨æµ‹è¯•é›†ä¸Šè®¡ç®—æ¨¡å‹é¢„æµ‹å‡†ç¡®ç‡\n",
    "    \n",
    "    å‚æ•°è¯´æ˜ï¼š\n",
    "    - model: è®­ç»ƒå¥½çš„ PyTorch æ¨¡å‹\n",
    "    - X_test_indices: æµ‹è¯•é›†è¾“å…¥ç´¢å¼•ï¼ˆnumpy æ•°ç»„ï¼‰\n",
    "    - Y_test_oh: æµ‹è¯•é›†æ ‡ç­¾çš„ one-hot ç¼–ç \n",
    "    \"\"\"\n",
    "    \n",
    "    # å°†æ¨¡å‹åˆ‡æ¢ä¸ºâ€œè¯„ä¼°æ¨¡å¼â€ï¼ˆevaluation modeï¼‰\n",
    "    # ä½œç”¨ï¼šå…³é—­ Dropoutã€BatchNorm ç­‰è®­ç»ƒæ—¶çš„éšæœºè¡Œä¸º\n",
    "    model.eval()\n",
    "    \n",
    "    # å°† numpy æ•°ç»„è½¬æ¢ä¸º LongTensor å¹¶æ”¾åˆ°è®¾å¤‡ä¸Šï¼ˆCPU æˆ– GPUï¼‰\n",
    "    X_test_tensor = torch.tensor(X_test_indices, dtype=torch.long).to(device)\n",
    "    \n",
    "    # å°† one-hot æ ‡ç­¾è½¬æ¢ä¸ºç±»åˆ«ç´¢å¼•ï¼ˆä½¿ç”¨ argmax å–æœ€å¤§æ¦‚ç‡å¯¹åº”çš„ç±»ï¼‰\n",
    "    Y_test_tensor = torch.tensor(np.argmax(Y_test_oh, axis=1), dtype=torch.long).to(device)\n",
    "    \n",
    "    # å…³é—­æ¢¯åº¦è®¡ç®—ï¼ŒåŠ å¿«æ¨ç†é€Ÿåº¦ã€å‡å°‘æ˜¾å­˜å ç”¨\n",
    "    with torch.no_grad():\n",
    "        # å‰å‘ä¼ æ’­ï¼Œå¾—åˆ°æ¨¡å‹è¾“å‡ºï¼ˆæ¯ä¸ªæ ·æœ¬åœ¨å„ç±»åˆ«ä¸Šçš„åˆ†æ•°ï¼‰\n",
    "        pred = model(X_test_tensor)\n",
    "        \n",
    "        # ä»æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹åˆ†æ•°ä¸­ï¼Œå–æœ€å¤§å€¼å¯¹åº”çš„ç±»åˆ«ä½œä¸ºé¢„æµ‹ç»“æœ\n",
    "        pred_labels = torch.argmax(pred, dim=1)\n",
    "        \n",
    "        # è®¡ç®—é¢„æµ‹å‡†ç¡®ç‡ï¼šé¢„æµ‹æ ‡ç­¾ä¸çœŸå®æ ‡ç­¾ç›¸ç­‰çš„æ¯”ä¾‹\n",
    "        acc = (pred_labels == Y_test_tensor).float().mean().item()\n",
    "    \n",
    "    # æ‰“å°å‡†ç¡®ç‡ç»“æœ\n",
    "    print(\"Test accuracy =\", acc)\n",
    "    \n",
    "    # å°†é¢„æµ‹ç»“æœä» GPU ç§»åˆ° CPU å¹¶è½¬ä¸º numpy æ•°ç»„è¿”å›ï¼Œæ–¹ä¾¿åç»­åˆ†ææˆ–å±•ç¤º\n",
    "    return pred_labels.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- æ‰“å°é¢„æµ‹å‡½æ•° ---------------------------- #\n",
    "def print_predictions(model, X_test, X_test_indices, Y_test, label_to_emoji):\n",
    "    \"\"\"\n",
    "    æ‰“å°é¢„æµ‹é”™è¯¯æ ·æœ¬çš„å‡½æ•°\n",
    "    \n",
    "    åŠŸèƒ½ï¼š\n",
    "    åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œæ¨¡å‹é¢„æµ‹ï¼Œå¹¶è¾“å‡ºé¢„æµ‹é”™è¯¯çš„æ ·æœ¬ï¼Œ\n",
    "    åŒ…å«åŸæ–‡æœ¬ã€çœŸå®è¡¨æƒ…ä¸é¢„æµ‹è¡¨æƒ…ï¼Œç”¨äºäººå·¥æ£€æŸ¥æ¨¡å‹æ•ˆæœã€‚\n",
    "    \n",
    "    å‚æ•°è¯´æ˜ï¼š\n",
    "    - model: è®­ç»ƒå¥½çš„ PyTorch æ¨¡å‹\n",
    "    - X_test: åŸå§‹æµ‹è¯•é›†æ ·æœ¬ï¼ˆé€šå¸¸æ˜¯å¥å­æ–‡æœ¬åˆ—è¡¨ï¼‰\n",
    "    - X_test_indices: æµ‹è¯•é›†ç´¢å¼•å½¢å¼è¾“å…¥ï¼ˆæ¨¡å‹è¾“å…¥æ ¼å¼ï¼‰\n",
    "    - Y_test: æµ‹è¯•é›†çœŸå®æ ‡ç­¾ï¼ˆé one-hot å½¢å¼ï¼‰\n",
    "    - label_to_emoji: å°†æ ‡ç­¾ç¼–å·è½¬æ¢ä¸ºè¡¨æƒ…ç¬¦å·çš„å‡½æ•°\n",
    "    \"\"\"\n",
    "\n",
    "    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­ Dropout / BatchNorm çš„éšæœºè¡Œä¸ºï¼‰\n",
    "    model.eval()\n",
    "    \n",
    "    # å°†æµ‹è¯•é›†ç´¢å¼•æ•°æ®è½¬ä¸º Tensorï¼Œå¹¶ç§»åŠ¨åˆ°å¯¹åº”è®¾å¤‡ä¸Šï¼ˆCPU æˆ– GPUï¼‰\n",
    "    X_test_tensor = torch.tensor(X_test_indices, dtype=torch.long).to(device)\n",
    "\n",
    "    # å…³é—­æ¢¯åº¦è®¡ç®—ï¼ŒåŠ å¿«é¢„æµ‹é€Ÿåº¦\n",
    "    with torch.no_grad():\n",
    "        # å‰å‘ä¼ æ’­å¾—åˆ°é¢„æµ‹ç»“æœï¼ˆæ¯ä¸ªæ ·æœ¬çš„ç±»åˆ«å¾—åˆ†ï¼‰\n",
    "        pred = model(X_test_tensor)\n",
    "        \n",
    "        # å–æ¯ä¸ªæ ·æœ¬çš„æœ€å¤§å¾—åˆ†ç±»åˆ«ï¼ˆå³é¢„æµ‹ç»“æœï¼‰\n",
    "        pred_labels = torch.argmax(pred, dim=1).cpu().numpy()\n",
    "\n",
    "    # æ‰“å°æç¤ºä¿¡æ¯\n",
    "    print(f\"é”™è¯¯ä¿¡æ¯å¦‚ä¸‹ï¼ˆä»…å±•ç¤ºé¢„æµ‹é”™è¯¯çš„æ ·æœ¬ï¼‰:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # éå†æµ‹è¯•æ ·æœ¬\n",
    "    for i in range(len(X_test)):\n",
    "        # åˆ¤æ–­é¢„æµ‹æ˜¯å¦é”™è¯¯\n",
    "        if pred_labels[i] != Y_test[i]:\n",
    "            # æ‰“å°çœŸå®è¡¨æƒ… + åŸå§‹æ–‡æœ¬ + é¢„æµ‹è¡¨æƒ…\n",
    "            print(f\"âœ… æ­£ç¡®è¡¨æƒ…ï¼š{label_to_emoji(Y_test[i])}   \"\n",
    "                  f\"âŒ é¢„æµ‹ç»“æœï¼š{X_test[i]} {label_to_emoji(pred_labels[i]).strip()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½ çš„ Emojifier-V2 **æ¨¡å‹**è¾“å…¥ä¸ºå½¢çŠ¶ (`m`, `max_len`) çš„æ•°ç»„ï¼Œè¾“å‡ºä¸ºå½¢çŠ¶ (`m`, ç±»åˆ«æ•°) çš„æ¦‚ç‡å‘é‡ã€‚  \n",
    "\n",
    "å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦åšä¸¤ä»¶äº‹ï¼š\n",
    "\n",
    "1. å°†è®­ç»ƒé›†å¥å­ä»å­—ç¬¦ä¸²å½¢å¼è½¬æ¢ä¸ºç´¢å¼•å½¢å¼ï¼Œæ–¹ä¾¿åµŒå…¥å±‚å¤„ç†ï¼š\n",
    "\n",
    "```python\n",
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "```\n",
    "\n",
    "2. å°†æ ‡ç­¾ä»æ•´æ•°ç´¢å¼•è½¬æ¢ä¸º one-hot ç¼–ç ï¼Œä»¥ä¾¿ç”¨äºäº¤å‰ç†µæŸå¤±ï¼š\n",
    "```python\n",
    "Y_train_oh = np.eye(C)[Y_train.reshape(-1)]\n",
    "Y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
    "```\n",
    "\n",
    "è¿™æ ·å¤„ç†åï¼š\n",
    "\n",
    "- X_train_indices å’Œ X_test_indices çš„å½¢çŠ¶ä¸º (æ ·æœ¬æ•°, max_len)ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯å¯¹åº”å•è¯çš„ç´¢å¼•\n",
    "\n",
    "- Y_train_oh å’Œ Y_test_oh çš„å½¢çŠ¶ä¸º (æ ·æœ¬æ•°, C)ï¼Œæ¯è¡Œæ˜¯æ ‡ç­¾çš„ one-hot ç¼–ç \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# æ•°æ®é¢„å¤„ç†ï¼šå¥å­ç´¢å¼•åŒ–ä¸æ ‡ç­¾ One-hot ç¼–ç \n",
    "# ========================================\n",
    "\n",
    "# å‡è®¾ä»¥ä¸‹å˜é‡å·²åœ¨å‰é¢å®šä¹‰å¥½ï¼š\n",
    "# X_train, Y_train, X_test, Y_test               â€”â€” è®­ç»ƒé›†ä¸æµ‹è¯•é›†ï¼ˆè¾“å…¥å¥å­ä¸æ ‡ç­¾ï¼‰\n",
    "# word_to_index                                  â€”â€” å•è¯åˆ°ç´¢å¼•çš„æ˜ å°„å­—å…¸\n",
    "# word_to_vec_map                                â€”â€” å•è¯åˆ°è¯å‘é‡çš„æ˜ å°„å­—å…¸\n",
    "# maxLen                                         â€”â€” æ¯ä¸ªå¥å­çš„æœ€å¤§é•¿åº¦ï¼ˆä¾‹å¦‚ 10ï¼‰\n",
    "# è¿™äº›æ•°æ®é€šå¸¸æ¥è‡ªå‰é¢çš„æ–‡æœ¬å¤„ç†ä¸ GloVe å‘é‡åŠ è½½æ­¥éª¤ã€‚\n",
    "\n",
    "# -------------------------------------------------\n",
    "# C = 5 è¡¨ç¤ºåˆ†ç±»ä»»åŠ¡ä¸­ç±»åˆ«çš„æ€»æ•°ï¼ˆå³è¡¨æƒ…ç±»åˆ«æ•°ï¼‰\n",
    "# åœ¨è¡¨æƒ…ä»»åŠ¡ä¸­å…±æœ‰ 5 ç§ç±»åˆ«ï¼Œå¯¹åº” 5 ç§ emoji è¡¨æƒ…ã€‚\n",
    "# -------------------------------------------------\n",
    "C = 5\n",
    "\n",
    "\n",
    "# =================================================\n",
    "# 1. å°†è®­ç»ƒé›†ä¸­çš„æ¯ä¸ªå¥å­è½¬æ¢ä¸ºè¯ç´¢å¼•çŸ©é˜µ\n",
    "# =================================================\n",
    "# sentences_to_indices() å‡½æ•°ä½œç”¨ï¼š\n",
    "#   - è¾“å…¥ï¼šä¸€ç»„å¥å­ + å•è¯ç´¢å¼•å­—å…¸ + å¥å­æœ€å¤§é•¿åº¦ maxLen\n",
    "#   - è¾“å‡ºï¼šäºŒç»´æ•°ç»„ï¼ˆå½¢çŠ¶ä¸º (m, maxLen)ï¼‰ï¼Œ\n",
    "#           æ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªå¥å­çš„å•è¯ç´¢å¼•åºåˆ—ï¼ˆä¸è¶³ maxLen ç”¨ 0 å¡«å……ï¼‰\n",
    "# å‚æ•°ï¼š\n",
    "#   X_train       â€”â€” è®­ç»ƒé›†æ–‡æœ¬å¥å­ï¼ˆnumpy æ•°ç»„ï¼‰\n",
    "#   word_to_index â€”â€” å•è¯ä¸ç´¢å¼•çš„æ˜ å°„å­—å…¸ï¼Œå¦‚ {\"i\":1, \"love\":2, \"food\":3, ...}\n",
    "#   maxLen        â€”â€” æ¯ä¸ªå¥å­ç»Ÿä¸€é•¿åº¦ï¼Œè¶…å‡ºéƒ¨åˆ†æˆªæ–­ï¼Œä¸è¶³éƒ¨åˆ†è¡¥ 0\n",
    "# è¿”å›ï¼š\n",
    "#   X_train_indices â€”â€” è®­ç»ƒé›†ä¸­æ¯ä¸ªå¥å­çš„ç´¢å¼•åŒ–ç»“æœ\n",
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "\n",
    "\n",
    "# =================================================\n",
    "# 2. å°†æµ‹è¯•é›†ä¸­çš„å¥å­è½¬æ¢ä¸ºç›¸åŒæ ¼å¼çš„ç´¢å¼•çŸ©é˜µ\n",
    "# =================================================\n",
    "# å‚æ•°ä¸è¿”å›ç»“æœä¸è®­ç»ƒé›†ç›¸åŒ\n",
    "# è¿™æ ·æ¨¡å‹åœ¨è®­ç»ƒä¸æµ‹è¯•é˜¶æ®µçš„è¾“å…¥æ ¼å¼å®Œå…¨ä¸€è‡´ã€‚\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "\n",
    "\n",
    "# =================================================\n",
    "# 3. å°†æ ‡ç­¾ï¼ˆY_trainï¼‰è½¬æ¢ä¸º One-hot å‘é‡\n",
    "# =================================================\n",
    "# np.eye(C) â€”â€” åˆ›å»ºä¸€ä¸ª CÃ—C çš„å•ä½çŸ©é˜µï¼ˆå¯¹è§’çº¿ä¸º 1ï¼Œå…¶ä½™ä¸º 0ï¼‰\n",
    "# ä¾‹å¦‚ C=5 æ—¶ï¼š\n",
    "# np.eye(5) =\n",
    "# [[1,0,0,0,0],\n",
    "#  [0,1,0,0,0],\n",
    "#  [0,0,1,0,0],\n",
    "#  [0,0,0,1,0],\n",
    "#  [0,0,0,0,1]]\n",
    "#\n",
    "# Y_train.reshape(-1) â€”â€” å°†æ ‡ç­¾ Y_train å±•å¹³æˆä¸€ç»´æ•°ç»„\n",
    "# ä¾‹å¦‚åŸæœ¬å½¢çŠ¶æ˜¯ (132, 1)ï¼Œreshape(-1) å˜ä¸º (132,)\n",
    "# è¿™æ · np.eye(C)[Y_train.reshape(-1)] ä¼šä¸ºæ¯ä¸ªæ ‡ç­¾å–å¯¹åº”è¡Œï¼Œ\n",
    "# ç”Ÿæˆå½¢çŠ¶ä¸º (m, C) çš„ One-hot çŸ©é˜µã€‚\n",
    "Y_train_oh = np.eye(C)[Y_train.reshape(-1)]\n",
    "\n",
    "\n",
    "# =================================================\n",
    "# 4. å°†æµ‹è¯•é›†æ ‡ç­¾ä¹Ÿè½¬æ¢ä¸º One-hot å‘é‡\n",
    "# =================================================\n",
    "# æ“ä½œä¸è®­ç»ƒé›†å®Œå…¨ç›¸åŒï¼Œç”¨äºåç»­æ¨¡å‹è¯„ä¼°ã€‚\n",
    "Y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒä»¥åˆ›å»ºæ¨¡å‹å¹¶æŸ¥çœ‹å…¶æ‘˜è¦ã€‚  \n",
    "ç”±äºæ•°æ®é›†ä¸­æ‰€æœ‰å¥å­é•¿åº¦éƒ½å°äº 10 ä¸ªå•è¯ï¼Œæˆ‘ä»¬é€‰æ‹© `max_len = 10`ã€‚  \n",
    "\n",
    "ä½ åº”è¯¥å¯ä»¥çœ‹åˆ°æ¨¡å‹æ¶æ„ï¼Œå®ƒä½¿ç”¨äº† **20,224,951** ä¸ªå‚æ•°ï¼Œå…¶ä¸­ **20,000,050**ï¼ˆè¯å‘é‡éƒ¨åˆ†ï¼‰ä¸ºä¸å¯è®­ç»ƒï¼Œå…¶ä½™ **224,901** ä¸ªä¸ºå¯è®­ç»ƒå‚æ•°ã€‚  \n",
    "ç”±äºæˆ‘ä»¬çš„è¯æ±‡è¡¨å¤§å°ä¸º 400,001 ä¸ªå•è¯ï¼ˆæœ‰æ•ˆç´¢å¼•ä» 0 åˆ° 400,000ï¼‰ï¼Œå› æ­¤ä¸å¯è®­ç»ƒå‚æ•°æ•°é‡ä¸º 400,001 Ã— 50 = 20,000,050ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# æ¨¡å‹åˆå§‹åŒ–ï¼šEmojifyV2 æ¨¡å‹åˆ›å»º\n",
    "# ========================================\n",
    "\n",
    "# -------------------------------------------------\n",
    "# maxLen = 10\n",
    "# -------------------------------------------------\n",
    "# å®šä¹‰æ¯ä¸ªè¾“å…¥å¥å­çš„æœ€å¤§é•¿åº¦ï¼ˆmax sequence lengthï¼‰ã€‚\n",
    "# æ¨¡å‹åœ¨å¤„ç†è¾“å…¥æ—¶ï¼Œæ¯ä¸ªå¥å­éƒ½ä¼šè¢«è½¬æ¢ä¸ºé•¿åº¦ä¸º 10 çš„å•è¯ç´¢å¼•åºåˆ—ï¼š\n",
    "#   - è‹¥å¥å­é•¿åº¦ < 10ï¼Œåˆ™ç”¨ 0ï¼ˆpaddingï¼‰å¡«å……ï¼›\n",
    "#   - è‹¥å¥å­é•¿åº¦ > 10ï¼Œåˆ™æˆªæ–­å¤šä½™éƒ¨åˆ†ã€‚\n",
    "# è¿™æ ·å¯ä»¥ä¿è¯æ‰€æœ‰è¾“å…¥æ ·æœ¬çš„å½¢çŠ¶ä¸€è‡´ï¼Œä¾¿äºæ‰¹é‡è®­ç»ƒã€‚\n",
    "maxLen = 10\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# æ¨¡å‹å®ä¾‹åŒ–\n",
    "# -------------------------------------------------\n",
    "# åˆ›å»º EmojifyV2 æ¨¡å‹å¯¹è±¡ï¼Œå¹¶å°†å…¶åŠ è½½åˆ°æŒ‡å®šçš„è®¡ç®—è®¾å¤‡ä¸Šï¼ˆCPU æˆ– GPUï¼‰ã€‚\n",
    "# å‚æ•°è¯´æ˜ï¼š\n",
    "#   maxLen            â€”â€” è¾“å…¥å¥å­çš„æœ€å¤§é•¿åº¦ï¼Œç”¨äºç¡®å®šåµŒå…¥å±‚è¾“å…¥ç»´åº¦\n",
    "#   word_to_vec_map   â€”â€” å•è¯åˆ° GloVe è¯å‘é‡çš„æ˜ å°„å­—å…¸\n",
    "#   word_to_index     â€”â€” å•è¯åˆ°ç´¢å¼•çš„æ˜ å°„å­—å…¸\n",
    "#   C                 â€”â€” åˆ†ç±»ç±»åˆ«æ•°é‡ï¼Œè¿™é‡Œä¸º 5ï¼ˆè¡¨ç¤º 5 ç§è¡¨æƒ…ï¼‰\n",
    "# è¿”å›ï¼š\n",
    "#   model â€”â€” åˆå§‹åŒ–å¥½çš„ PyTorch æ¨¡å‹å¯¹è±¡\n",
    "#\n",
    "# .to(device) â€”â€” å°†æ¨¡å‹è½¬ç§»åˆ°è®¾å¤‡ï¼ˆdeviceï¼‰ä¸Šè¿è¡Œï¼š\n",
    "#   - è‹¥æ£€æµ‹åˆ° GPUï¼Œåˆ™æ¨¡å‹å°†åœ¨ CUDA ä¸Šè®­ç»ƒï¼›\n",
    "#   - è‹¥æ²¡æœ‰ GPUï¼Œåˆ™è‡ªåŠ¨ä½¿ç”¨ CPUã€‚\n",
    "model = EmojifyV2(maxLen, word_to_vec_map, word_to_index, C=C).to(device)\n",
    "\n",
    "\n",
    "# å°ç»“ï¼š\n",
    "# -------------------------------------------------\n",
    "# è¿™ä¸€æ­¥å®Œæˆäº†æ¨¡å‹çš„æ ¸å¿ƒåˆå§‹åŒ–ï¼ŒåŒ…å«ï¼š\n",
    "#   - åµŒå…¥å±‚ï¼ˆåŠ è½½é¢„è®­ç»ƒ GloVe è¯å‘é‡ï¼‰\n",
    "#   - åŒå±‚ LSTM ç½‘ç»œç»“æ„\n",
    "#   - Dropout é˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "#   - å…¨è¿æ¥å±‚ + Softmax è¾“å‡ºè¡¨æƒ…ç±»åˆ«\n",
    "#\n",
    "# æ¨¡å‹æ­¤æ—¶å·²å‡†å¤‡å¥½è¿›å…¥è®­ç»ƒé˜¶æ®µã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmojifyV2(\n",
      "  (embedding): Embedding(400001, 50)\n",
      "  (lstm1): LSTM(50, 128, batch_first=True)\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (lstm2): LSTM(128, 128, batch_first=True)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
      ")\n",
      "Total params: 20,224,951\n",
      "Trainable params: 224,901\n",
      "Non-trainable params: 20,000,050\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# æ‰“å°æ¨¡å‹ç»“æ„åŠç»Ÿè®¡å‚æ•°\n",
    "# ========================================\n",
    "\n",
    "# -------------------------------------------------\n",
    "# æ‰“å°æ¨¡å‹çš„ç½‘ç»œç»“æ„\n",
    "# -------------------------------------------------\n",
    "# print(model) ä¼šè¾“å‡ºæ¨¡å‹å„å±‚çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š\n",
    "#   - å„å±‚ç±»å‹ï¼ˆEmbeddingã€LSTMã€Dropoutã€Linear ç­‰ï¼‰\n",
    "#   - è¾“å…¥è¾“å‡ºç»´åº¦\n",
    "#   - å¯è®­ç»ƒå‚æ•°æ•°é‡ï¼ˆtrainableï¼‰ç­‰\n",
    "print(model)\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# ç»Ÿè®¡æ¨¡å‹æ€»å‚æ•°æ•°é‡\n",
    "# -------------------------------------------------\n",
    "# sum(p.numel() for p in model.parameters())\n",
    "#   - model.parameters() è¿”å›æ¨¡å‹ä¸­æ‰€æœ‰å‚æ•°çš„è¿­ä»£å™¨\n",
    "#   - p.numel() ç»Ÿè®¡å¼ é‡ p çš„å…ƒç´ æ€»æ•°\n",
    "#   - sum(...) å¯¹æ‰€æœ‰å‚æ•°æ±‚å’Œï¼Œå³å¾—åˆ°æ¨¡å‹æ€»å‚æ•°æ•°é‡\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# ç»Ÿè®¡å¯è®­ç»ƒå‚æ•°æ•°é‡ï¼ˆtrainable parametersï¼‰\n",
    "# -------------------------------------------------\n",
    "# sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "#   - p.requires_grad ä¸º True è¡¨ç¤ºè¯¥å‚æ•°åœ¨åå‘ä¼ æ’­æ—¶ä¼šæ›´æ–°\n",
    "#   - ç»Ÿè®¡æ‰€æœ‰å¯è®­ç»ƒå‚æ•°æ•°é‡ï¼Œä¾¿äºäº†è§£æ¨¡å‹å­¦ä¹ èƒ½åŠ›\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# ç»Ÿè®¡ä¸å¯è®­ç»ƒå‚æ•°æ•°é‡ï¼ˆnon-trainable parametersï¼‰\n",
    "# -------------------------------------------------\n",
    "# total_params - trainable_params\n",
    "#   - è¿™éƒ¨åˆ†å‚æ•°é€šå¸¸æ˜¯å›ºå®šçš„ï¼Œæ¯”å¦‚å†»ç»“çš„åµŒå…¥å±‚ï¼ˆfreeze=Trueï¼‰\n",
    "non_trainable_params = total_params - trainable_params\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# æ‰“å°å‚æ•°ç»Ÿè®¡ç»“æœ\n",
    "# -------------------------------------------------\n",
    "# ä½¿ç”¨åƒåˆ†ä½åˆ†éš”ç¬¦â€œ,â€æ ¼å¼åŒ–è¾“å‡ºï¼Œæ›´ç›´è§‚\n",
    "print(f\"Total params: {total_params:,}\")          # æ¨¡å‹æ€»å‚æ•°\n",
    "print(f\"Trainable params: {trainable_params:,}\")  # å¯è®­ç»ƒå‚æ•°\n",
    "print(f\"Non-trainable params: {non_trainable_params:,}\")  # ä¸å¯è®­ç»ƒå‚æ•°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æ˜¯è®­ç»ƒæ¨¡å‹çš„æ—¶å€™äº†ã€‚  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨ **X_train_indices** å’Œ **Y_train_oh** ä¸Šè®­ç»ƒPytorchæ¨¡å‹ã€‚  \n",
    "è®­ç»ƒå‚æ•°è®¾ç½®ä¸ºï¼š\n",
    "- `epochs = 50`  \n",
    "- `batch_size = 32`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - loss: 1.3565 - acc: 0.5076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "5/5 [==============================] - loss: 1.3698 - acc: 0.4924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "5/5 [==============================] - loss: 1.4118 - acc: 0.4924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "5/5 [==============================] - loss: 1.3630 - acc: 0.5227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "5/5 [==============================] - loss: 1.3264 - acc: 0.5076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "5/5 [==============================] - loss: 1.3468 - acc: 0.5379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "5/5 [==============================] - loss: 1.3290 - acc: 0.5606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "5/5 [==============================] - loss: 1.3434 - acc: 0.5227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "5/5 [==============================] - loss: 1.3596 - acc: 0.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "5/5 [==============================] - loss: 1.3161 - acc: 0.5758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "5/5 [==============================] - loss: 1.3239 - acc: 0.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "5/5 [==============================] - loss: 1.3312 - acc: 0.5985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "5/5 [==============================] - loss: 1.3373 - acc: 0.6288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "5/5 [==============================] - loss: 1.2546 - acc: 0.6970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "5/5 [==============================] - loss: 1.2729 - acc: 0.7197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "5/5 [==============================] - loss: 1.1820 - acc: 0.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "5/5 [==============================] - loss: 1.1535 - acc: 0.7424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "5/5 [==============================] - loss: 1.1152 - acc: 0.7803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "5/5 [==============================] - loss: 1.1234 - acc: 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "5/5 [==============================] - loss: 1.0892 - acc: 0.7803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "5/5 [==============================] - loss: 1.1297 - acc: 0.8030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "5/5 [==============================] - loss: 1.0704 - acc: 0.8106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "5/5 [==============================] - loss: 1.0704 - acc: 0.8106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "5/5 [==============================] - loss: 1.1402 - acc: 0.7652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "5/5 [==============================] - loss: 1.1012 - acc: 0.8561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "5/5 [==============================] - loss: 1.0982 - acc: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "5/5 [==============================] - loss: 1.0517 - acc: 0.8409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "5/5 [==============================] - loss: 1.0351 - acc: 0.8712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "5/5 [==============================] - loss: 1.0301 - acc: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "5/5 [==============================] - loss: 1.0147 - acc: 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "5/5 [==============================] - loss: 1.0108 - acc: 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "5/5 [==============================] - loss: 1.0274 - acc: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "5/5 [==============================] - loss: 1.0055 - acc: 0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "5/5 [==============================] - loss: 1.0375 - acc: 0.9167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "5/5 [==============================] - loss: 1.0451 - acc: 0.8939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "5/5 [==============================] - loss: 1.0414 - acc: 0.8939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "5/5 [==============================] - loss: 1.0720 - acc: 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "5/5 [==============================] - loss: 1.0771 - acc: 0.8939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "5/5 [==============================] - loss: 0.9862 - acc: 0.9167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "5/5 [==============================] - loss: 0.9850 - acc: 0.9015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "5/5 [==============================] - loss: 1.0287 - acc: 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "5/5 [==============================] - loss: 0.9848 - acc: 0.9167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "5/5 [==============================] - loss: 1.0094 - acc: 0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "5/5 [==============================] - loss: 1.0040 - acc: 0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "5/5 [==============================] - loss: 0.9927 - acc: 0.9015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "5/5 [==============================] - loss: 0.9852 - acc: 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "5/5 [==============================] - loss: 1.0258 - acc: 0.8939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "5/5 [==============================] - loss: 0.9692 - acc: 0.9242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "5/5 [==============================] - loss: 1.0219 - acc: 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "5/5 [==============================] - loss: 0.9637 - acc: 0.9318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# ========================================\n",
    "# è®­ç»ƒ EmojifyV2 æ¨¡å‹\n",
    "# ========================================\n",
    "\n",
    "# è°ƒç”¨è®­ç»ƒå‡½æ•° train(...) æ¥è®­ç»ƒæ¨¡å‹\n",
    "# ----------------------------------------\n",
    "# å‚æ•°è¯´æ˜ï¼š\n",
    "# model               : PyTorch æ¨¡å‹å®ä¾‹ï¼Œè¿™é‡Œæ˜¯ EmojifyV2\n",
    "# X_train_indices     : è®­ç»ƒé›†è¾“å…¥çš„ç´¢å¼•çŸ©é˜µï¼ˆæ¯ä¸ªå¥å­è½¬æˆ word indexï¼‰ï¼Œå½¢çŠ¶ (m, maxLen)\n",
    "# Y_train_oh          : è®­ç»ƒé›†æ ‡ç­¾çš„ one-hot ç¼–ç ï¼Œå½¢çŠ¶ (m, C)\n",
    "# num_epochs=50       : æ€»è®­ç»ƒè½®æ•°ï¼Œå³å®Œæ•´éå†è®­ç»ƒé›† 50 æ¬¡\n",
    "# batch_size=32       : æ¯ä¸ª batch çš„æ ·æœ¬æ•°ï¼ˆæ¢¯åº¦æ›´æ–°é¢‘ç‡ï¼‰\n",
    "train(model, X_train_indices, Y_train_oh, num_epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "æ¯æ¬¡è¿è¡Œå‡†ç¡®ç‡ä¼šæœ‰å·®å¼‚ã€‚  \n",
    "\n",
    "è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒï¼Œåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°ä½ çš„æ¨¡å‹è¡¨ç°ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.75\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# æµ‹è¯•é›†è¯„ä¼°æ¨¡å‹\n",
    "# ========================================\n",
    "\n",
    "# è°ƒç”¨ evaluate(...) å‡½æ•°åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½\n",
    "# ----------------------------------------\n",
    "# å‚æ•°è¯´æ˜ï¼š\n",
    "# model               : å·²è®­ç»ƒå¥½çš„ PyTorch æ¨¡å‹å®ä¾‹ï¼ˆEmojifyV2ï¼‰\n",
    "# X_test_indices      : æµ‹è¯•é›†è¾“å…¥çš„ç´¢å¼•çŸ©é˜µï¼ˆæ¯ä¸ªå¥å­è½¬æˆ word indexï¼‰ï¼Œå½¢çŠ¶ (m_test, maxLen)\n",
    "# Y_test_oh           : æµ‹è¯•é›†æ ‡ç­¾çš„ one-hot ç¼–ç ï¼Œå½¢çŠ¶ (m_test, C)\n",
    "# è¿”å›å€¼ï¼š\n",
    "# pred_labels         : æ¨¡å‹é¢„æµ‹æ ‡ç­¾ï¼Œnumpy æ•°ç»„ï¼Œå½¢çŠ¶ (m_test,)\n",
    "pred_labels = evaluate(model, X_test_indices, Y_test_oh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é”™è¯¯ä¿¡æ¯å¦‚ä¸‹ï¼ˆä»…å±•ç¤ºé¢„æµ‹é”™è¯¯çš„æ ·æœ¬ï¼‰:\n",
      "------------------------------------------------------------\n",
      "âœ… æ­£ç¡®è¡¨æƒ…ï¼š:smile:   âŒ é¢„æµ‹ç»“æœï¼šhe got a very nice raise\t â¤ï¸\n",
      "âœ… æ­£ç¡®è¡¨æƒ…ï¼š:smile:   âŒ é¢„æµ‹ç»“æœï¼šshe got me a nice present\t â¤ï¸\n",
      "âœ… æ­£ç¡®è¡¨æƒ…ï¼š:smile:   âŒ é¢„æµ‹ç»“æœï¼šhe is a good friend\t â¤ï¸\n",
      "âœ… æ­£ç¡®è¡¨æƒ…ï¼š:smile:   âŒ é¢„æµ‹ç»“æœï¼šWe had such a lovely dinner tonight\t â¤ï¸\n",
      "âœ… æ­£ç¡®è¡¨æƒ…ï¼š:disappointed:   âŒ é¢„æµ‹ç»“æœï¼šThis girl is messing with me\t â¤ï¸\n",
      "âœ… æ­£ç¡®è¡¨æƒ…ï¼š:smile:   âŒ é¢„æµ‹ç»“æœï¼šyou brighten my day\t â¤ï¸\n",
      "âœ… æ­£ç¡®è¡¨æƒ…ï¼š:disappointed:   âŒ é¢„æµ‹ç»“æœï¼šshe is a bully\t â¤ï¸\n",
      "âœ… æ­£ç¡®è¡¨æƒ…ï¼š:disappointed:   âŒ é¢„æµ‹ç»“æœï¼šMy life is so boring\t â¤ï¸\n",
      "âœ… æ­£ç¡®è¡¨æƒ…ï¼š:smile:   âŒ é¢„æµ‹ç»“æœï¼šshe said yes\t â¤ï¸\n",
      "âœ… æ­£ç¡®è¡¨æƒ…ï¼š:smile:   âŒ é¢„æµ‹ç»“æœï¼šwill you be my valentine\t â¤ï¸\n",
      "âœ… æ­£ç¡®è¡¨æƒ…ï¼šâ¤ï¸   âŒ é¢„æµ‹ç»“æœï¼šI love you to the stars and back\t âš¾\n",
      "âœ… æ­£ç¡®è¡¨æƒ…ï¼š:smile:   âŒ é¢„æµ‹ç»“æœï¼šWhat you did was awesome\t :disappointed:\n",
      "âœ… æ­£ç¡®è¡¨æƒ…ï¼š:disappointed:   âŒ é¢„æµ‹ç»“æœï¼šgo away\t âš¾\n",
      "âœ… æ­£ç¡®è¡¨æƒ…ï¼šâ¤ï¸   âŒ é¢„æµ‹ç»“æœï¼šfamily is all I have\t :disappointed:\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# ğŸ–¨ æ‰“å°æ¯ä¸ªæµ‹è¯•æ ·æœ¬çš„é¢„æµ‹ç»“æœ\n",
    "# ========================================\n",
    "\n",
    "# è°ƒç”¨ print_predictions(...) å‡½æ•°ï¼Œå°†æ¨¡å‹å¯¹æµ‹è¯•é›†çš„é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾è¿›è¡Œå¯¹æ¯”æ‰“å°\n",
    "# ----------------------------------------\n",
    "# å‚æ•°è¯´æ˜ï¼š\n",
    "# model            : å·²è®­ç»ƒå¥½çš„ PyTorch æ¨¡å‹å®ä¾‹ï¼ˆEmojifyV2ï¼‰\n",
    "# X_test           : æµ‹è¯•é›†å¥å­æ•°ç»„ï¼Œå½¢çŠ¶ (m_test,) æˆ–åˆ—è¡¨\n",
    "# X_test_indices   : æµ‹è¯•é›†å¥å­ç´¢å¼•çŸ©é˜µï¼Œå½¢çŠ¶ (m_test, maxLen)\n",
    "# Y_test           : æµ‹è¯•é›†æ ‡ç­¾æ•°ç»„ï¼ˆæ•´æ•°å½¢å¼ï¼‰ï¼Œå½¢çŠ¶ (m_test,)\n",
    "# label_to_emoji   : å‡½æ•°ï¼Œå°†æ ‡ç­¾æ•´æ•°æ˜ å°„ä¸ºå¯¹åº”çš„ emoji å­—ç¬¦ä¸²\n",
    "\n",
    "print_predictions(model, X_test, X_test_indices, Y_test, label_to_emoji)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "è¿è¡Œä¸‹æ–¹ä»£ç å•å…ƒï¼ŒæŸ¥çœ‹è¢«é”™è¯¯æ ‡æ³¨çš„ç¤ºä¾‹ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨ä½ å¯ä»¥åœ¨è‡ªå·±çš„ç¤ºä¾‹ä¸Šå°è¯•ã€‚  \n",
    "åœ¨ä¸‹é¢å†™ä¸‹ä½ è‡ªå·±çš„å¥å­ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- å•å¥é¢„æµ‹ ---------------------------- #\n",
    "def predict_single_sentence(model, sentence, word_to_index, maxLen, label_to_emoji):\n",
    "    \"\"\"\n",
    "    å•å¥é¢„æµ‹å‡½æ•°\n",
    "    \n",
    "    åŠŸèƒ½ï¼š\n",
    "    ç»™å®šä¸€æ¡è‡ªç„¶è¯­è¨€å¥å­ï¼Œåˆ©ç”¨è®­ç»ƒå¥½çš„ Emojify æ¨¡å‹é¢„æµ‹å¯¹åº”çš„è¡¨æƒ…æ ‡ç­¾ï¼Œ\n",
    "    å¹¶è¾“å‡ºé¢„æµ‹ç»“æœã€‚\n",
    "    \n",
    "    å‚æ•°è¯´æ˜ï¼š\n",
    "    - model: è®­ç»ƒå¥½çš„ PyTorch æ¨¡å‹\n",
    "    - sentence: å¾…é¢„æµ‹çš„è¾“å…¥å¥å­ï¼ˆå­—ç¬¦ä¸²ï¼‰\n",
    "    - word_to_index: å•è¯åˆ°ç´¢å¼•çš„æ˜ å°„å­—å…¸\n",
    "    - maxLen: æ¯æ¡å¥å­å¡«å……åçš„æœ€å¤§é•¿åº¦ï¼ˆä¸è®­ç»ƒé˜¶æ®µä¿æŒä¸€è‡´ï¼‰\n",
    "    - label_to_emoji: å°†ç±»åˆ«ç´¢å¼•è½¬æ¢ä¸ºè¡¨æƒ…ç¬¦å·çš„å‡½æ•°\n",
    "    \"\"\"\n",
    "\n",
    "    # â‘  å°†è¾“å…¥å¥å­è½¬ä¸ºç´¢å¼•åºåˆ—ï¼ˆç¬¦åˆæ¨¡å‹è¾“å…¥æ ¼å¼ï¼‰\n",
    "    # sentences_to_indices() çš„è¾“å…¥éœ€è¦æ˜¯ä¸€ä¸ª numpy æ•°ç»„\n",
    "    X_indices = sentences_to_indices(np.array([sentence]), word_to_index, maxLen)\n",
    "\n",
    "    # â‘¡ è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­ dropout ç­‰ï¼‰\n",
    "    model.eval()\n",
    "\n",
    "    # â‘¢ å°†ç´¢å¼•æ•°æ®è½¬æ¢ä¸º PyTorch Tensor å¹¶ç§»åŠ¨è‡³è®¾å¤‡ï¼ˆGPU æˆ– CPUï¼‰\n",
    "    X_tensor = torch.tensor(X_indices, dtype=torch.long).to(device)\n",
    "\n",
    "    # â‘£ ç¦æ­¢æ¢¯åº¦è®¡ç®—ï¼ŒåŠ å¿«é¢„æµ‹é€Ÿåº¦\n",
    "    with torch.no_grad():\n",
    "        # å‰å‘ä¼ æ’­å¾—åˆ°é¢„æµ‹è¾“å‡ºï¼ˆæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡ï¼‰\n",
    "        pred = model(X_tensor)\n",
    "\n",
    "        # å–æ¦‚ç‡æœ€é«˜çš„ç±»åˆ«ç¼–å·ä½œä¸ºæœ€ç»ˆé¢„æµ‹æ ‡ç­¾\n",
    "        pred_label = torch.argmax(pred, dim=1).item()\n",
    "\n",
    "    # â‘¤ æ‰“å°é¢„æµ‹ç»“æœï¼ˆåŸå¥ + å¯¹åº”è¡¨æƒ…ï¼‰\n",
    "    print(sentence + ' ' + label_to_emoji(pred_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are so beautiful â¤ï¸\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# å•å¥é¢„æµ‹\n",
    "# ========================================\n",
    "\n",
    "# è°ƒç”¨ predict_single_sentence(...) å‡½æ•°ï¼Œå¯¹å•æ¡å¥å­è¿›è¡Œé¢„æµ‹\n",
    "# ----------------------------------------\n",
    "# å‚æ•°è¯´æ˜ï¼š\n",
    "# model          : å·²è®­ç»ƒå¥½çš„ PyTorch æ¨¡å‹å®ä¾‹ï¼ˆEmojifyV2ï¼‰\n",
    "# sentence       : å¾…é¢„æµ‹çš„å•æ¡å¥å­ï¼ˆå­—ç¬¦ä¸²ç±»å‹ï¼‰\n",
    "# word_to_index  : å­—å…¸ï¼Œå°†è¯æ˜ å°„ä¸ºå¯¹åº”çš„ç´¢å¼•ï¼Œç”¨äº embedding å±‚è¾“å…¥\n",
    "# maxLen         : å¥å­æœ€å¤§é•¿åº¦ï¼ˆpadding é•¿åº¦ï¼‰ï¼Œä¸æ¨¡å‹åˆå§‹åŒ–æ—¶ä¿æŒä¸€è‡´\n",
    "# label_to_emoji : å‡½æ•°ï¼Œå°†æ ‡ç­¾æ•´æ•°æ˜ å°„ä¸ºå¯¹åº”çš„ emoji å­—ç¬¦ä¸²\n",
    "\n",
    "predict_single_sentence(model, \"you are so beautiful\", word_to_index, maxLen, label_to_emoji)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¹‹å‰ï¼ŒEmojify-V1 æ¨¡å‹æ— æ³•æ­£ç¡®æ ‡æ³¨ \"*not feeling happy*\"ï¼Œä½†æˆ‘ä»¬å®ç°çš„ Emojifier-V2 èƒ½æ­£ç¡®è¯†åˆ«ã€‚ï¼ˆKeras çš„è¾“å‡ºæ¯æ¬¡ç•¥æœ‰éšæœºæ€§ï¼Œå› æ­¤ä½ å¯èƒ½æ²¡æœ‰å¾—åˆ°å®Œå…¨ç›¸åŒçš„ç»“æœã€‚ï¼‰  \n",
    "\n",
    "å½“å‰æ¨¡å‹åœ¨ç†è§£å¦å®šè¯ï¼ˆå¦‚ \"*not happy*\"ï¼‰æ–¹é¢ä»ä¸å¤Ÿç¨³å¥ï¼Œå› ä¸ºè®­ç»ƒé›†è¾ƒå°ï¼Œç¼ºå°‘å¦å®šå¥çš„ç¤ºä¾‹ã€‚  \n",
    "ä½†å¦‚æœè®­ç»ƒé›†æ›´å¤§ï¼ŒLSTM æ¨¡å‹åœ¨ç†è§£è¿™ç§å¤æ‚å¥å­æ–¹é¢å°†è¿œä¼˜äº Emojify-V1 æ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ­å–œï¼\n",
    "\n",
    "ä½ å·²ç»å®Œæˆäº†æœ¬ç¬”è®°æœ¬çš„å…¨éƒ¨å†…å®¹ï¼â¤ï¸â¤ï¸â¤ï¸\n",
    "\n",
    "<font color='blue'>\n",
    "\n",
    "**æœ¬æ¬¡å†…å®¹éœ€è¦è®°ä½çš„è¦ç‚¹ï¼ˆPyTorch ç‰ˆæœ¬ï¼‰**ï¼š\n",
    "\n",
    "- å¦‚æœä½ çš„ NLP ä»»åŠ¡è®­ç»ƒé›†è¾ƒå°ï¼Œä½¿ç”¨è¯å‘é‡ï¼ˆword embeddingsï¼‰å¯ä»¥æ˜¾è‘—æå‡ç®—æ³•æ•ˆæœã€‚è¯å‘é‡ä½¿æ¨¡å‹èƒ½å¤Ÿå¤„ç†æµ‹è¯•é›†ä¸­å¯èƒ½æœªå‡ºç°åœ¨è®­ç»ƒé›†ä¸­çš„å•è¯ã€‚  \n",
    "- åœ¨ PyTorch ä¸­è®­ç»ƒåºåˆ—æ¨¡å‹ï¼Œéœ€è¦æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š\n",
    "    - ä½¿ç”¨ mini-batch æ—¶ï¼Œéœ€è¦å¯¹åºåˆ—è¿›è¡Œå¡«å……ï¼ˆpaddingï¼‰ï¼Œç¡®ä¿ mini-batch ä¸­çš„æ‰€æœ‰æ ·æœ¬é•¿åº¦ç›¸åŒã€‚  \n",
    "    - `nn.Embedding` å±‚å¯ä»¥ç”¨é¢„è®­ç»ƒçš„è¯å‘é‡åˆå§‹åŒ–ï¼ˆ`nn.Embedding.from_pretrained()`ï¼‰ã€‚è¿™äº›è¯å‘é‡å¯ä»¥ä¿æŒå›ºå®šï¼ˆ`freeze=True`ï¼‰ï¼Œä¹Ÿå¯ä»¥åœ¨ä½ çš„æ•°æ®é›†ä¸Šè¿›ä¸€æ­¥è®­ç»ƒã€‚ä½†å¦‚æœæ ‡æ³¨æ•°æ®é›†å¾ˆå°ï¼Œé€šå¸¸ä¸å€¼å¾—è®­ç»ƒå¤§è§„æ¨¡é¢„è®­ç»ƒè¯å‘é‡ã€‚  \n",
    "    - `nn.LSTM` çš„å‚æ•° `batch_first=True` å¯ä¿è¯è¾“å…¥è¾“å‡ºå½¢çŠ¶ä¸º `(batch, seq_len, features)`ï¼Œè¿”å›å€¼ä¸­åŒ…å«éšè—çŠ¶æ€å’Œå•ä¸ªæ—¶é—´æ­¥è¾“å‡ºã€‚  \n",
    "    - å¯ä»¥åœ¨ `nn.LSTM` åä½¿ç”¨ `nn.Dropout` æ¥å¯¹ç½‘ç»œè¿›è¡Œæ­£åˆ™åŒ–ã€‚  \n",
    "    - å‰å‘ä¼ æ’­æ—¶ï¼Œé€šå¸¸åªå–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ä½œä¸ºæ•´ä¸ªåºåˆ—çš„è¡¨ç¤ºï¼Œå†ä¼ å…¥ `nn.Linear` è¾“å‡ºç±»åˆ«æ¦‚ç‡ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "æ­å–œä½ å®Œæˆäº†æœ¬æ¬¡ä½œä¸šå¹¶æˆåŠŸæ„å»ºäº†ä¸€ä¸ª Emojifierã€‚  \n",
    "å¸Œæœ›ä½ å¯¹è‡ªå·±åœ¨æœ¬ç¬”è®°æœ¬ä¸­çš„æˆæœæ„Ÿåˆ°æ»¡æ„ï¼\n",
    "\n",
    "# ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è‡´è°¢\n",
    "\n",
    "æ„Ÿè°¢ Alison Darcy å’Œ Woebot å›¢é˜Ÿã€‚  \n",
    "Woebot æ˜¯ä¸€ä¸ªå¯ä»¥éšæ—¶ä¸ä½ äº¤æµçš„èŠå¤©æœºå™¨äººæœ‹å‹ï¼Œå…¨å¤© 24 å°æ—¶åœ¨çº¿ã€‚  \n",
    "ä½œä¸º Woebot æŠ€æœ¯çš„ä¸€éƒ¨åˆ†ï¼Œå®ƒä½¿ç”¨è¯å‘é‡æ¥ç†è§£ä½ æ‰€è¯´å†…å®¹çš„æƒ…ç»ªã€‚  \n",
    "ä½ å¯ä»¥è®¿é—® [http://woebot.io](http://woebot.io) ä½“éªŒå®ƒã€‚\n",
    "\n",
    "<img src=\"images/woebot.png\" style=\"width:600px;height:300px;\">\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "RNnEs",
   "launcher_item_id": "acNYU"
  },
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
