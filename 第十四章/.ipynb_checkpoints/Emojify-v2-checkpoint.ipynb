{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# è¡¨æƒ…ç¬¦å·ç”Ÿæˆå™¨ï¼ˆEmojify!ï¼‰\n",
    "\n",
    "æ¬¢è¿æ¥åˆ°ç¬¬äºŒå‘¨çš„ç¬¬äºŒä¸ªä½œä¸šã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•åˆ©ç”¨**è¯å‘é‡è¡¨ç¤ºï¼ˆword vector representationsï¼‰**æ¥æ„å»ºä¸€ä¸ªâ€œè¡¨æƒ…ç¬¦å·ç”Ÿæˆå™¨â€ï¼ˆEmojifierï¼‰ã€‚\n",
    "\n",
    "\n",
    "### é¡¹ç›®ç›®æ ‡\n",
    "\n",
    "ä½ æ˜¯å¦æ›¾ç»å¸Œæœ›è‡ªå·±çš„çŸ­ä¿¡æ›´ç”ŸåŠ¨ã€æ›´æœ‰è¡¨ç°åŠ›ï¼Ÿè¿™ä¸ªè¡¨æƒ…ç¬¦å·ç”Ÿæˆå™¨åº”ç”¨ç¨‹åºï¼ˆemojifier appï¼‰å°†å¸®åŠ©ä½ å®ç°è¿™ä¸€ç‚¹ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼Œå°†ä¸‹é¢è¿™å¥è¯ï¼š\n",
    "\n",
    "> â€œCongratulations on the promotion! Lets get coffee and talk. Love you!â€\n",
    "\n",
    "è‡ªåŠ¨å˜æˆï¼š\n",
    "\n",
    "> â€œCongratulations on the promotion! ğŸ‘ Lets get coffee and talk. â˜•ï¸ Love you! â¤ï¸â€\n",
    "\n",
    "### ä»»åŠ¡è¯´æ˜\n",
    "\n",
    "ä½ å°†å®ç°ä¸€ä¸ªæ¨¡å‹ï¼Œå®ƒèƒ½å¤Ÿè¾“å…¥ä¸€å¥è¯ï¼ˆä¾‹å¦‚ â€œLet's go see the baseball game tonight!â€ï¼‰ï¼Œå¹¶è¾“å‡ºæœ€åˆé€‚çš„è¡¨æƒ…ç¬¦å·ï¼ˆâš¾ï¸ï¼‰ã€‚\n",
    "\n",
    "åœ¨è®¸å¤šè¡¨æƒ…ç•Œé¢ä¸­ï¼Œä½ å¿…é¡»è®°ä½ â¤ï¸ æ˜¯â€œheartâ€ï¼ˆå¿ƒå½¢ï¼‰ç¬¦å·ï¼Œè€Œä¸æ˜¯â€œloveâ€ï¼ˆçˆ±ï¼‰ç¬¦å·ã€‚ä½†é€šè¿‡ä½¿ç”¨**è¯å‘é‡**ï¼Œä½ ä¼šçœ‹åˆ°å³ä½¿è®­ç»ƒé›†ä¸­ä»…æ˜ç¡®åœ°å°†å°‘æ•°å•è¯ä¸æŸä¸ªè¡¨æƒ…ç¬¦å·å…³è”èµ·æ¥ï¼Œä½ çš„ç®—æ³•ä»ç„¶èƒ½å¤Ÿ**æ³›åŒ–ï¼ˆgeneralizeï¼‰**åˆ°æµ‹è¯•é›†ä¸­çš„å…¶ä»–å•è¯ä¸Šâ€”â€”å³ä¾¿è¿™äº›å•è¯åœ¨è®­ç»ƒé›†ä¸­ä»æœªå‡ºç°è¿‡ã€‚\n",
    "\n",
    "è¿™ç§ç‰¹æ€§è®©ä½ èƒ½å¤Ÿåœ¨**å°è§„æ¨¡è®­ç»ƒé›†**çš„åŸºç¡€ä¸Šï¼Œä¾ç„¶æ„å»ºä¸€ä¸ªå‡†ç¡®çš„â€œå¥å­åˆ°è¡¨æƒ…ç¬¦å·â€çš„åˆ†ç±»å™¨ï¼ˆclassifierï¼‰ã€‚\n",
    "\n",
    "\n",
    "### æ¨¡å‹ç‰ˆæœ¬\n",
    "\n",
    "åœ¨æœ¬ç»ƒä¹ ä¸­ï¼Œä½ å°†ä¾æ¬¡æ„å»ºä¸¤ä¸ªæ¨¡å‹ï¼š\n",
    "\n",
    "1. **Emojifier-V1**ï¼šä¸€ä¸ªä½¿ç”¨è¯åµŒå…¥ï¼ˆword embeddingsï¼‰çš„åŸºç¡€æ¨¡å‹ã€‚\n",
    "2. **Emojifier-V2**ï¼šä¸€ä¸ªè¿›ä¸€æ­¥ç»“åˆ **LSTMï¼ˆé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼‰** çš„é«˜çº§æ¨¡å‹ã€‚\n",
    "\n",
    "\n",
    "### å‡†å¤‡å¼€å§‹\n",
    "\n",
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ï¼è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒä»¥åŠ è½½æ‰€éœ€çš„åŒ…ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "   ---------------------------------------- 0.0/608.4 kB ? eta -:--:--\n",
      "   - ------------------------------------- 20.5/608.4 kB 682.7 kB/s eta 0:00:01\n",
      "   --------- ------------------------------ 143.4/608.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  604.2/608.4 kB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 608.4/608.4 kB 4.8 MB/s eta 0:00:00\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.15.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# å¯¼å…¥å¸¸ç”¨åº“\n",
    "# ----------------------------\n",
    "\n",
    "import numpy as np\n",
    "# numpyï¼šPython çš„ç§‘å­¦è®¡ç®—åº“ï¼Œæä¾›é«˜æ•ˆæ•°ç»„æ“ä½œä¸çº¿æ€§ä»£æ•°å‡½æ•°\n",
    "\n",
    "import emoji\n",
    "# emojiï¼šç”¨äºå¤„ç†æ–‡æœ¬ä¸­çš„è¡¨æƒ…ç¬¦å·ï¼Œä¾‹å¦‚è¯†åˆ«ã€æ›¿æ¢æˆ–è§£æè¡¨æƒ…\n",
    "\n",
    "import csv\n",
    "# csvï¼šç”¨äºè¯»å–å’Œå†™å…¥ CSV æ–‡ä»¶\n",
    "\n",
    "import pandas as pd\n",
    "# pandasï¼šPython æ•°æ®åˆ†æåº“ï¼Œæä¾›é«˜æ•ˆçš„ DataFrame æ•°æ®ç»“æ„\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.pyplotï¼šç»˜å›¾åº“ï¼Œç”¨äºç»˜åˆ¶æŠ˜çº¿å›¾ã€æ•£ç‚¹å›¾ã€æŸ±çŠ¶å›¾ç­‰\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# sklearn.metrics.confusion_matrixï¼šç”¨äºè®¡ç®—åˆ†ç±»æ¨¡å‹çš„æ··æ·†çŸ©é˜µ\n",
    "\n",
    "# Jupyter Notebook ä¸“ç”¨è®¾ç½®\n",
    "%matplotlib inline\n",
    "# åœ¨ Jupyter Notebook ä¸­ç›´æ¥æ˜¾ç¤º matplotlib ç»˜åˆ¶çš„å›¾ï¼Œè€Œä¸æ˜¯å¼¹å‡ºæ–°çª—å£\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¾…åŠ©å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# è¯»å– GloVe è¯å‘é‡\n",
    "# ----------------------------\n",
    "def read_glove_vecs(glove_file):\n",
    "    \"\"\"\n",
    "    ä» GloVe æ–‡ä»¶è¯»å–è¯å‘é‡ï¼ŒåŒæ—¶ç”Ÿæˆï¼š\n",
    "        - words_to_index: å•è¯ -> ç´¢å¼•\n",
    "        - index_to_words: ç´¢å¼• -> å•è¯\n",
    "        - word_to_vec_map: å•è¯ -> å‘é‡\n",
    "    \"\"\"\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        words = set()                  # å­˜å‚¨è¯è¡¨ï¼ˆå»é‡ï¼‰\n",
    "        word_to_vec_map = {}           # å­˜å‚¨è¯å‘é‡æ˜ å°„\n",
    "        for line in f:\n",
    "            line = line.strip().split()   # å»æ‰é¦–å°¾ç©ºæ ¼å¹¶æŒ‰ç©ºæ ¼æ‹†åˆ†\n",
    "            curr_word = line[0]           # ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å•è¯\n",
    "            words.add(curr_word)           # åŠ å…¥é›†åˆ\n",
    "            # å°†å‰©ä½™éƒ¨åˆ†è½¬ä¸ºæµ®ç‚¹æ•°æ•°ç»„ï¼Œå³è¯å‘é‡\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        # ----------------------------\n",
    "        # æ„å»ºå•è¯ç´¢å¼•æ˜ å°„\n",
    "        # ----------------------------\n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):           # æŒ‰å­—å…¸åºæ’åº\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i += 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Softmax å‡½æ•°\n",
    "# ----------------------------\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    è®¡ç®—å‘é‡æˆ–çŸ©é˜µçš„ softmax\n",
    "    å‚æ•°:\n",
    "        x: è¾“å…¥å‘é‡æˆ–çŸ©é˜µ\n",
    "    è¿”å›:\n",
    "        softmax åçš„æ¦‚ç‡åˆ†å¸ƒ\n",
    "    \"\"\"\n",
    "    e_x = np.exp(x - np.max(x))    # å‡å» max é˜²æ­¢æº¢å‡º\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# è¯»å– CSV æ•°æ®é›†\n",
    "# ----------------------------\n",
    "def read_csv(filename='data/emojify_data.csv'):\n",
    "    \"\"\"\n",
    "    ä» CSV æ–‡ä»¶è¯»å–å¥å­å’Œå¯¹åº”çš„ emoji æ ‡ç­¾\n",
    "    å‚æ•°:\n",
    "        filename: CSV æ–‡ä»¶è·¯å¾„\n",
    "    è¿”å›:\n",
    "        X: numpy æ•°ç»„ï¼Œå¥å­\n",
    "        Y: numpy æ•°ç»„ï¼Œæ ‡ç­¾\n",
    "    \"\"\"\n",
    "    phrase = []\n",
    "    emoji = []\n",
    "\n",
    "    with open(filename) as csvDataFile:\n",
    "        csvReader = csv.reader(csvDataFile)\n",
    "        for row in csvReader:\n",
    "            phrase.append(row[0])           # ç¬¬ä¸€åˆ—æ˜¯å¥å­\n",
    "            emoji.append(row[1])            # ç¬¬äºŒåˆ—æ˜¯æ ‡ç­¾\n",
    "\n",
    "    X = np.asarray(phrase)\n",
    "    Y = np.asarray(emoji, dtype=int)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# è½¬æ¢æ ‡ç­¾ä¸º one-hot\n",
    "# ----------------------------\n",
    "def convert_to_one_hot(Y, C):\n",
    "    \"\"\"\n",
    "    å°†æ•´æ•°æ ‡ç­¾ Y è½¬ä¸º one-hot ç¼–ç \n",
    "    å‚æ•°:\n",
    "        Y: æ ‡ç­¾æ•°ç»„ (m,)\n",
    "        C: ç±»åˆ«æ•°\n",
    "    è¿”å›:\n",
    "        one-hot ç¼–ç  (m, C)\n",
    "    \"\"\"\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# emoji æ˜ å°„å­—å…¸\n",
    "# ----------------------------\n",
    "emoji_dictionary = {\n",
    "    \"0\": \"\\u2764\\uFE0F\",  # â¤ï¸ å¿ƒ\n",
    "    \"1\": \":baseball:\",    # âš¾ æ£’çƒ\n",
    "    \"2\": \":smile:\",       # ğŸ˜„ å¾®ç¬‘\n",
    "    \"3\": \":disappointed:\",# ğŸ˜ å¤±æœ›\n",
    "    \"4\": \":fork_and_knife:\" # ğŸ´ é¤å…·\n",
    "}\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# æ ‡ç­¾è½¬ emoji\n",
    "# ----------------------------\n",
    "def label_to_emoji(label):\n",
    "    \"\"\"\n",
    "    å°†æ•´æ•°æ ‡ç­¾æˆ–å­—ç¬¦ä¸²æ ‡ç­¾è½¬ä¸º emoji\n",
    "    å‚æ•°:\n",
    "        label: æ ‡ç­¾ï¼ˆint æˆ– strï¼‰\n",
    "    è¿”å›:\n",
    "        emoji å­—ç¬¦ä¸²\n",
    "    \"\"\"\n",
    "    return emoji.emojize(emoji_dictionary[str(label)])\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# æ‰“å°é¢„æµ‹ç»“æœ\n",
    "# ----------------------------\n",
    "def print_predictions(X, pred):\n",
    "    \"\"\"\n",
    "    æ‰“å°å¥å­å’Œå¯¹åº”çš„é¢„æµ‹ emoji\n",
    "    å‚æ•°:\n",
    "        X: å¥å­æ•°ç»„ (m,)\n",
    "        pred: é¢„æµ‹æ ‡ç­¾æ•°ç»„ (m, 1)\n",
    "    \"\"\"\n",
    "    print()\n",
    "    for i in range(X.shape[0]):\n",
    "        print(X[i], label_to_emoji(int(pred[i])))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# ç»˜åˆ¶æ··æ·†çŸ©é˜µ\n",
    "# ----------------------------\n",
    "def plot_confusion_matrix(y_actu, y_pred, title='Confusion matrix', cmap=plt.cm.gray_r):\n",
    "    \"\"\"\n",
    "    ç»˜åˆ¶æ··æ·†çŸ©é˜µ\n",
    "    å‚æ•°:\n",
    "        y_actu: çœŸå®æ ‡ç­¾\n",
    "        y_pred: é¢„æµ‹æ ‡ç­¾\n",
    "        title: å›¾æ ‡é¢˜\n",
    "        cmap: é¢œè‰²æ˜ å°„\n",
    "    \"\"\"\n",
    "    # åˆ©ç”¨ pandas è®¡ç®—äº¤å‰è¡¨\n",
    "    df_confusion = pd.crosstab(\n",
    "        y_actu,\n",
    "        y_pred.reshape(y_pred.shape[0],),\n",
    "        rownames=['Actual'],\n",
    "        colnames=['Predicted'],\n",
    "        margins=True\n",
    "    )\n",
    "    \n",
    "    df_conf_norm = df_confusion / df_confusion.sum(axis=1)\n",
    "    \n",
    "    plt.matshow(df_confusion, cmap=cmap)  # ç»˜åˆ¶çŸ©é˜µå›¾\n",
    "    plt.colorbar()\n",
    "    \n",
    "    tick_marks = np.arange(len(df_confusion.columns))\n",
    "    plt.xticks(tick_marks, df_confusion.columns, rotation=45)\n",
    "    plt.yticks(tick_marks, df_confusion.index)\n",
    "    \n",
    "    plt.ylabel(df_confusion.index.name)\n",
    "    plt.xlabel(df_confusion.columns.name)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# é¢„æµ‹å‡½æ•°\n",
    "# ----------------------------\n",
    "def predict(X, Y, W, b, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    ç»™å®šå¥å­ X å’Œæƒé‡ W, b, é¢„æµ‹ emoji å¹¶è®¡ç®—å‡†ç¡®ç‡\n",
    "    å‚æ•°:\n",
    "        X: è¾“å…¥å¥å­æ•°ç»„ (m,)\n",
    "        Y: æ ‡ç­¾æ•°ç»„ (m,1)\n",
    "        W: æƒé‡çŸ©é˜µ (num_classes, word_vector_dim)\n",
    "        b: åç½®å‘é‡ (num_classes,1)\n",
    "        word_to_vec_map: å•è¯ -> å‘é‡æ˜ å°„\n",
    "    è¿”å›:\n",
    "        pred: é¢„æµ‹æ ‡ç­¾ (m,1)\n",
    "    \"\"\"\n",
    "    m = X.shape[0]                  # æ ·æœ¬æ•°é‡\n",
    "    pred = np.zeros((m, 1))         # åˆå§‹åŒ–é¢„æµ‹ç»“æœ\n",
    "\n",
    "    for j in range(m):               # éå†æ¯ä¸ªæ ·æœ¬\n",
    "        words = X[j].lower().split() # æ‹†åˆ†å¥å­ä¸ºå•è¯\n",
    "        avg = np.zeros((50,))        # åˆå§‹åŒ–å¹³å‡è¯å‘é‡\n",
    "        for w in words:\n",
    "            avg += word_to_vec_map[w] # ç´¯åŠ å•è¯å‘é‡\n",
    "        avg = avg / len(words)         # å–å¹³å‡\n",
    "        \n",
    "        Z = np.dot(W, avg) + b        # å‰å‘ä¼ æ’­è®¡ç®—åˆ†æ•°\n",
    "        A = softmax(Z)                # è®¡ç®—æ¦‚ç‡åˆ†å¸ƒ\n",
    "        pred[j] = np.argmax(A)        # å–æœ€å¤§å€¼ç´¢å¼•ä½œä¸ºé¢„æµ‹æ ‡ç­¾\n",
    "\n",
    "    # è¾“å‡ºå‡†ç¡®ç‡\n",
    "    print(\"Accuracy: \"  + str(np.mean((pred[:] == Y.reshape(Y.shape[0],1)[:]))))\n",
    "    \n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - åŸºçº¿æ¨¡å‹ï¼šEmojifier-V1\n",
    "\n",
    "### 1.1 - æ•°æ®é›† EMOJISET\n",
    "\n",
    "è®©æˆ‘ä»¬ä»æ„å»ºä¸€ä¸ªç®€å•çš„åŸºçº¿åˆ†ç±»å™¨å¼€å§‹ã€‚\n",
    "\n",
    "åœ¨è¿™ä¸ªå®éªŒä¸­ï¼Œä½ å°†ä½¿ç”¨ä¸€ä¸ªéå¸¸å°çš„æ•°æ®é›† **(X, Y)**ï¼Œå…¶ä¸­ï¼š\n",
    "\n",
    "- **X** åŒ…å« **127 æ¡å¥å­ï¼ˆå­—ç¬¦ä¸²ï¼‰**  \n",
    "- **Y** ä¸ºæ¯æ¡å¥å­å¯¹åº”çš„ **æ•´æ•°æ ‡ç­¾ï¼ˆ0 åˆ° 4 ä¹‹é—´ï¼‰**ï¼Œæ¯ä¸ªæ ‡ç­¾ä»£è¡¨ä¸€ç§è¡¨æƒ…ç¬¦å·\n",
    "\n",
    "\n",
    "<img src=\"images/data_set.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> **å›¾ 1**ï¼šEMOJISET â€”â€” ä¸€ä¸ªåŒ…å« 5 ä¸ªç±»åˆ«çš„åˆ†ç±»é—®é¢˜ã€‚ä¸Šå›¾å±•ç¤ºäº†éƒ¨åˆ†å¥å­ç¤ºä¾‹ã€‚</center></caption>\n",
    "\n",
    "\n",
    "æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç åŠ è½½è¯¥æ•°æ®é›†ã€‚  \n",
    "æˆ‘ä»¬å°†æ•°æ®é›†åˆ’åˆ†ä¸ºï¼š\n",
    "- **è®­ç»ƒé›†ï¼ˆ127 ä¸ªæ ·æœ¬ï¼‰**\n",
    "- **æµ‹è¯•é›†ï¼ˆ56 ä¸ªæ ·æœ¬ï¼‰**\n",
    "\n",
    "ï¼ˆä»¥ä¸‹ä»£ç å°†åœ¨åç»­å•å…ƒä¸­æ‰§è¡Œï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒé›†æ ·æœ¬æ•°é‡: 132\n",
      "æµ‹è¯•é›†æ ·æœ¬æ•°é‡: 56\n",
      "è®­ç»ƒé›†å‰5æ¡æ ·æœ¬å¥å­: ['never talk to me again' 'I am proud of your achievements'\n",
      " 'It is the worst day in my life' 'Miss you so much' 'food is life']\n",
      "è®­ç»ƒé›†å‰5æ¡æ ·æœ¬æ ‡ç­¾: [3 2 3 0 4]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# è¯»å–è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "# ----------------------------\n",
    "\n",
    "# è¯»å–è®­ç»ƒé›† CSV æ•°æ®\n",
    "# X_train: è®­ç»ƒå¥å­æ•°ç»„ï¼Œå½¢çŠ¶ (m_train,)\n",
    "# Y_train: è®­ç»ƒæ ‡ç­¾æ•°ç»„ï¼Œå½¢çŠ¶ (m_train,)\n",
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "\n",
    "# è¯»å–æµ‹è¯•é›† CSV æ•°æ®\n",
    "# X_test: æµ‹è¯•å¥å­æ•°ç»„ï¼Œå½¢çŠ¶ (m_test,)\n",
    "# Y_test: æµ‹è¯•æ ‡ç­¾æ•°ç»„ï¼Œå½¢çŠ¶ (m_test,)\n",
    "X_test, Y_test = read_csv('data/tesss.csv')\n",
    "\n",
    "# è¾“å‡ºæ ·æœ¬æ•°é‡ä¸å‰å‡ ä¸ªæ ·æœ¬ï¼Œä¾¿äºæ£€æŸ¥\n",
    "print(\"è®­ç»ƒé›†æ ·æœ¬æ•°é‡:\", X_train.shape[0])\n",
    "print(\"æµ‹è¯•é›†æ ·æœ¬æ•°é‡:\", X_test.shape[0])\n",
    "print(\"è®­ç»ƒé›†å‰5æ¡æ ·æœ¬å¥å­:\", X_train[:5])\n",
    "print(\"è®­ç»ƒé›†å‰5æ¡æ ·æœ¬æ ‡ç­¾:\", Y_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒé›†ä¸­æœ€é•¿å¥å­çš„å•è¯æ•°: 10\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# è®¡ç®—è®­ç»ƒé›†ä¸­å¥å­çš„æœ€å¤§é•¿åº¦\n",
    "# ----------------------------\n",
    "\n",
    "# max(X_train, key=len)  \n",
    "# - æ‰¾åˆ°è®­ç»ƒé›†ä¸­æœ€é•¿çš„å¥å­ï¼ˆæŒ‰å­—ç¬¦æ•°æ¯”è¾ƒï¼‰\n",
    "# .split()  \n",
    "# - å°†è¯¥å¥å­æŒ‰ç©ºæ ¼æ‹†åˆ†ä¸ºå•è¯åˆ—è¡¨\n",
    "# len(...)  \n",
    "# - è®¡ç®—è¯¥å¥å­çš„å•è¯æ•°\n",
    "# maxLen: è®­ç»ƒé›†ä¸­æœ€é•¿å¥å­çš„å•è¯æ•°ï¼Œç”¨äºä¹‹åå¥å­å‘é‡åŒ–å’Œå¡«å……\n",
    "maxLen = len(max(X_train, key=len).split())\n",
    "\n",
    "print(\"è®­ç»ƒé›†ä¸­æœ€é•¿å¥å­çš„å•è¯æ•°:\", maxLen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒï¼Œä»¥æ‰“å°å‡ºæ¥è‡ª **X_train** çš„å¥å­åŠå…¶åœ¨ **Y_train** ä¸­å¯¹åº”çš„æ ‡ç­¾ã€‚  \n",
    "ä½ å¯ä»¥ä¿®æ”¹å˜é‡ `index` çš„å€¼ï¼Œä»¥æŸ¥çœ‹ä¸åŒçš„ç¤ºä¾‹ã€‚\n",
    "\n",
    ">  æ³¨æ„ï¼šç”±äº iPython Notebook ä½¿ç”¨çš„å­—ä½“åŸå› ï¼Œå¿ƒå½¢è¡¨æƒ…ç¬¦å· â¤ï¸ å¯èƒ½ä¼šæ˜¾ç¤ºä¸ºé»‘è‰²ï¼ˆğŸ–¤ï¼‰ï¼Œè¿™æ˜¯æ­£å¸¸ç°è±¡ã€‚\n",
    "\n",
    "```python\n",
    "# ç¤ºä¾‹ä»£ç \n",
    "index = 10  # å¯ä¿®æ”¹ä»¥æŸ¥çœ‹ä¸åŒæ ·æœ¬\n",
    "print(X_train[index], label_to_emoji(Y_train[index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you two are cute â¤ï¸\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# æŸ¥çœ‹è®­ç»ƒé›†ä¸­çš„æŸä¸ªæ ·æœ¬åŠå…¶å¯¹åº”çš„ emoji æ ‡ç­¾\n",
    "# ----------------------------\n",
    "\n",
    "# è®¾ç½®è¦æŸ¥çœ‹çš„æ ·æœ¬ç´¢å¼•\n",
    "index = 45\n",
    "\n",
    "# æ‰“å°è®­ç»ƒé›† X_train ä¸­è¯¥ç´¢å¼•å¯¹åº”çš„å¥å­\n",
    "# åŒæ—¶è°ƒç”¨ label_to_emoji() å‡½æ•°å°† Y_train ä¸­çš„æ ‡ç­¾è½¬æ¢ä¸º emoji\n",
    "print(X_train[index], label_to_emoji(Y_train[index]))\n",
    "\n",
    "# è¯´æ˜ï¼š\n",
    "# X_train[index] -> ç¬¬ 45 ä¸ªè®­ç»ƒæ ·æœ¬ï¼ˆå¥å­ï¼‰\n",
    "# Y_train[index] -> ç¬¬ 45 ä¸ªè®­ç»ƒæ ·æœ¬å¯¹åº”çš„æ ‡ç­¾ï¼ˆæ•°å­— 0~4ï¼‰\n",
    "# label_to_emoji(...) -> å°†æ•°å­—æ ‡ç­¾æ˜ å°„ä¸ºå¯¹åº” emojiï¼Œä¾¿äºå¯è§†åŒ–\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Emojifier-V1 æ¨¡å‹æ¦‚è§ˆ\n",
    "\n",
    "åœ¨æœ¬éƒ¨åˆ†ä¸­ï¼Œä½ å°†å®ç°ä¸€ä¸ªåŸºçº¿æ¨¡å‹ï¼Œåä¸º **â€œEmojifier-V1â€**ã€‚\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"images/image_1.png\" style=\"width:900px;height:300px;\">\n",
    "<caption><center>**å›¾ 2**ï¼šåŸºçº¿æ¨¡å‹ï¼ˆEmojifier-V1ï¼‰ã€‚</center></caption>\n",
    "</center>\n",
    "\n",
    "\n",
    "è¯¥æ¨¡å‹çš„è¾“å…¥æ˜¯ä¸€ä¸ªä»£è¡¨å¥å­çš„å­—ç¬¦ä¸²ï¼ˆä¾‹å¦‚ï¼šâ€œI love youâ€ï¼‰ã€‚  \n",
    "æ¨¡å‹çš„è¾“å‡ºæ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º **(1, 5)** çš„**æ¦‚ç‡å‘é‡ï¼ˆprobability vectorï¼‰**ï¼Œè¡¨ç¤ºè¯¥å¥å­å±äºäº”ä¸ªè¡¨æƒ…ç±»åˆ«ä¸­æ¯ä¸€ç±»çš„æ¦‚ç‡ã€‚\n",
    "\n",
    "æœ€ç»ˆï¼Œä½ å°†æŠŠè¿™ä¸ªæ¦‚ç‡å‘é‡ä¼ å…¥ä¸€ä¸ª **argmax å±‚**ï¼Œä»¥æå–å‡º**æœ€å¯èƒ½çš„è¡¨æƒ…ç¬¦å·å¯¹åº”çš„ç´¢å¼•**ï¼Œä¹Ÿå°±æ˜¯æ¨¡å‹é¢„æµ‹çš„ç»“æœã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†è®©æ ‡ç­¾ **Y** é€‚ç”¨äº **Softmax åˆ†ç±»å™¨ï¼ˆsoftmax classifierï¼‰** çš„è®­ç»ƒï¼Œæˆ‘ä»¬éœ€è¦å°†å®ƒä»å½“å‰çš„å½¢çŠ¶  \n",
    "$(m, 1)$ è½¬æ¢ä¸º **â€œç‹¬çƒ­è¡¨ç¤ºâ€ï¼ˆone-hot representationï¼‰**ï¼Œå½¢çŠ¶ä¸º $(m, 5)$ã€‚\n",
    "\n",
    "åœ¨è¿™ç§è¡¨ç¤ºæ–¹å¼ä¸­ï¼Œæ¯ä¸€è¡Œæ˜¯ä¸€ä¸ª **one-hot å‘é‡**ï¼Œç”¨äºæŒ‡ç¤ºæŸä¸ªæ ·æœ¬æ‰€å±çš„ç±»åˆ«ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼š\n",
    "- è‹¥æ ‡ç­¾ä¸º 2ï¼Œåˆ™å¯¹åº”çš„ one-hot å‘é‡ä¸º `[0, 0, 1, 0, 0]`ã€‚\n",
    "\n",
    "ä¸‹é¢çš„ä»£ç ç‰‡æ®µå¯ä»¥å®Œæˆè¿™ä¸€è½¬æ¢æ“ä½œã€‚  \n",
    "å…¶ä¸­ï¼Œå˜é‡å `Y_oh_train` å’Œ `Y_oh_test` ä¸­çš„ `Y_oh` è¡¨ç¤º **â€œY çš„ one-hot å½¢å¼ï¼ˆY-one-hotï¼‰â€**ã€‚\n",
    "\n",
    "```python\n",
    "# å°†æ ‡ç­¾è½¬æ¢ä¸º one-hot å‘é‡è¡¨ç¤º\n",
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# å°†æ ‡ç­¾è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç ï¼ˆOne-Hot Encodingï¼‰\n",
    "# ----------------------------\n",
    "\n",
    "# å°†è®­ç»ƒé›†æ ‡ç­¾ Y_train è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç å½¢å¼\n",
    "# å‚æ•°è¯´æ˜ï¼š\n",
    "#   Y_train : åŸå§‹æ ‡ç­¾æ•°ç»„ï¼Œå½¢çŠ¶ (m, )ï¼Œæ¯ä¸ªå€¼ä¸º 0~4 ä¹‹é—´çš„æ•´æ•°\n",
    "#   C       : ç±»åˆ«æ€»æ•°ï¼Œè¿™é‡Œæ˜¯ 5 ä¸ª emoji\n",
    "# è¿”å›ï¼š\n",
    "#   Y_oh_train : è®­ç»ƒé›†æ ‡ç­¾çš„ç‹¬çƒ­ç¼–ç ï¼Œå½¢çŠ¶ (m, 5)\n",
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
    "\n",
    "# å°†æµ‹è¯•é›†æ ‡ç­¾ Y_test è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç å½¢å¼\n",
    "# å‚æ•°è¯´æ˜åŒä¸Š\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)\n",
    "\n",
    "# è¯´æ˜ï¼š\n",
    "# 1. ç‹¬çƒ­ç¼–ç çš„å¥½å¤„ï¼š\n",
    "#    - å¯ä»¥ç›´æ¥ç”¨äºç¥ç»ç½‘ç»œçš„è¾“å‡ºå±‚è®­ç»ƒ\n",
    "#    - å°†ç±»åˆ«æ ‡ç­¾ä»æ ‡é‡è½¬æ¢ä¸ºå‘é‡ï¼Œä¾‹å¦‚ï¼š\n",
    "#      æ ‡ç­¾ 2 â†’ [0, 0, 1, 0, 0]\n",
    "# 2. convert_to_one_hot å‡½æ•°å†…éƒ¨é€šè¿‡ np.eye(C)[Y.reshape(-1)] å®ç°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ `convert_to_one_hot()` å‡½æ•°çš„è¿è¡Œç»“æœã€‚  \n",
    "ä½ å¯ä»¥ä¿®æ”¹å˜é‡ `index` çš„å€¼ï¼Œä»¥æ‰“å°å¹¶æŸ¥çœ‹ä¸åŒæ ·æœ¬å¯¹åº”çš„ **one-hot å‘é‡è¡¨ç¤º**ã€‚\n",
    "\n",
    "```python\n",
    "# æŸ¥çœ‹æŸä¸ªæ ·æœ¬çš„ one-hot è½¬æ¢ç»“æœ\n",
    "index = 1  # å¯æ›´æ”¹ç´¢å¼•ä»¥æŸ¥çœ‹ä¸åŒæ ·æœ¬\n",
    "print(f\"æ ‡ç­¾å€¼: {Y_train[index]}\")\n",
    "print(f\"One-hot è¡¨ç¤º: {Y_oh_train[index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 is converted into one hot [0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# æŸ¥çœ‹æŸä¸ªæ ·æœ¬çš„æ ‡ç­¾åŠå…¶ç‹¬çƒ­ç¼–ç \n",
    "# ----------------------------\n",
    "\n",
    "# è®¾ç½®è¦æŸ¥çœ‹çš„æ ·æœ¬ç´¢å¼•\n",
    "index = 25\n",
    "\n",
    "# æ‰“å°è¯¥æ ·æœ¬çš„åŸå§‹æ ‡ç­¾ä»¥åŠå¯¹åº”çš„ç‹¬çƒ­ç¼–ç \n",
    "# Y_train[index]       : åŸå§‹æ ‡ç­¾ï¼ˆæ•´æ•°ï¼‰ï¼Œè¡¨ç¤ºç¬¬ index ä¸ªè®­ç»ƒæ ·æœ¬çš„ emoji ç±»åˆ«\n",
    "# Y_oh_train[index]    : ç‹¬çƒ­ç¼–ç å‘é‡ï¼Œå¯¹åº”ç±»åˆ«ä½ç½®ä¸º 1ï¼Œå…¶ä½™ä½ç½®ä¸º 0\n",
    "print(Y_train[index], \"is converted into one hot\", Y_oh_train[index])\n",
    "\n",
    "# ç¤ºä¾‹è¯´æ˜ï¼š\n",
    "# å‡è®¾ Y_train[25] = 3ï¼Œåˆ™è¾“å‡ºå¯èƒ½ä¸ºï¼š\n",
    "# 3 is converted into one hot [0. 0. 0. 1. 0.]\n",
    "# è¿™é‡Œ [0. 0. 0. 1. 0.] è¡¨ç¤ºç‹¬çƒ­ç¼–ç å½¢å¼\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨ï¼Œæ‰€æœ‰æ•°æ®éƒ½å·²ç»å‡†å¤‡å®Œæ¯•ï¼Œå¯ä»¥è¾“å…¥åˆ° **Emojifier-V1 æ¨¡å‹** ä¸­è¿›è¡Œè®­ç»ƒäº†ã€‚  \n",
    "æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å¼€å§‹å®ç°è¿™ä¸ªæ¨¡å‹å§ï¼ ğŸš€\n",
    "\n",
    "```python\n",
    "# å®ç° Emojifier-V1 æ¨¡å‹çš„å‡½æ•°æ¡†æ¶\n",
    "def model(X, Y, word_to_vec_map, learning_rate=0.01, num_iterations=400):\n",
    "    \"\"\"\n",
    "    å®ç° Emojifier-V1 æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "    X -- å¥å­åˆ—è¡¨ï¼ˆæ¯ä¸ªå…ƒç´ ä¸ºå­—ç¬¦ä¸²ï¼‰\n",
    "    Y -- å¥å­å¯¹åº”çš„æ ‡ç­¾ï¼ˆ0~4ï¼‰\n",
    "    word_to_vec_map -- è¯å‘é‡å­—å…¸ï¼šæ¯ä¸ªå•è¯æ˜ å°„åˆ°å…¶å¯¹åº”çš„ GloVe å‘é‡\n",
    "    learning_rate -- å­¦ä¹ ç‡ï¼ˆé»˜è®¤ 0.01ï¼‰\n",
    "    num_iterations -- è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤ 400ï¼‰\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    pred -- æ¨¡å‹å¯¹æ‰€æœ‰æ ·æœ¬çš„é¢„æµ‹ç»“æœ\n",
    "    \"\"\"\n",
    "    # æ¨¡å‹å®ç°ç»†èŠ‚å°†åœ¨åç»­å°èŠ‚ä¸­å®Œæˆ\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - å®ç° Emojifier-V1\n",
    "\n",
    "å¦‚å›¾ï¼ˆ2ï¼‰æ‰€ç¤ºï¼Œç¬¬ä¸€æ­¥æ˜¯å°†è¾“å…¥çš„å¥å­è½¬æ¢ä¸ºè¯å‘é‡è¡¨ç¤ºï¼Œç„¶åå¯¹è¿™äº›è¯å‘é‡å–å¹³å‡å€¼ã€‚  \n",
    "ä¸ä¹‹å‰çš„ç»ƒä¹ ç±»ä¼¼ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨é¢„è®­ç»ƒçš„ **50 ç»´ GloVe è¯å‘é‡**ã€‚  \n",
    "è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒä»¥åŠ è½½åŒ…å«æ‰€æœ‰è¯å‘é‡è¡¨ç¤ºçš„ `word_to_vec_map`ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# è¯»å– GloVe è¯å‘é‡\n",
    "# ----------------------------\n",
    "\n",
    "# è°ƒç”¨ä¹‹å‰å®šä¹‰çš„ read_glove_vecs() å‡½æ•°ï¼Œè¯»å– GloVe æ–‡ä»¶\n",
    "# 'data/glove.6B.50d.txt' ï¼šGloVe é¢„è®­ç»ƒè¯å‘é‡æ–‡ä»¶è·¯å¾„ï¼Œ50ç»´åº¦è¯å‘é‡\n",
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')\n",
    "\n",
    "# è¿”å›å€¼è¯´æ˜ï¼š\n",
    "# word_to_index : dictï¼Œå°†å•è¯æ˜ å°„ä¸ºå¯¹åº”çš„ç´¢å¼•\n",
    "#                 ä¾‹å¦‚: word_to_index['king'] = 1234\n",
    "# index_to_word : dictï¼Œå°†ç´¢å¼•æ˜ å°„å›å•è¯\n",
    "#                 ä¾‹å¦‚: index_to_word[1234] = 'king'\n",
    "# word_to_vec_map : dictï¼Œå°†å•è¯æ˜ å°„ä¸ºå¯¹åº”çš„è¯å‘é‡ï¼ˆnumpy.ndarrayï¼‰\n",
    "#                 ä¾‹å¦‚: word_to_vec_map['king'].shape = (50,) è¡¨ç¤º 50 ç»´å‘é‡\n",
    "\n",
    "# è¯»å–å®Œæˆåï¼Œå¯ç”¨äºï¼š\n",
    "# 1. å°†å•è¯è½¬æ¢ä¸ºå‘é‡è¿›è¡Œè¿ç®—\n",
    "# 2. åœ¨ç¥ç»ç½‘ç»œä¸­ä½œä¸ºè¾“å…¥çš„åµŒå…¥å‘é‡\n",
    "# 3. è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—ã€ç±»æ¯”ä»»åŠ¡ç­‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½ å·²ç»åŠ è½½äº†ä»¥ä¸‹å†…å®¹ï¼š\n",
    "\n",
    "- `word_to_index`ï¼šå°†å•è¯æ˜ å°„åˆ°è¯æ±‡è¡¨ç´¢å¼•çš„å­—å…¸ï¼ˆå…± 400,001 ä¸ªå•è¯ï¼Œæœ‰æ•ˆç´¢å¼•èŒƒå›´ 0 åˆ° 400,000ï¼‰  \n",
    "- `index_to_word`ï¼šå°†ç´¢å¼•æ˜ å°„å›è¯æ±‡è¡¨å¯¹åº”å•è¯çš„å­—å…¸  \n",
    "- `word_to_vec_map`ï¼šå°†å•è¯æ˜ å°„åˆ°å…¶ GloVe å‘é‡è¡¨ç¤ºçš„å­—å…¸  \n",
    "\n",
    "è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒä»¥æ£€æŸ¥åŠ è½½æ˜¯å¦æ­£å¸¸ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index of cucumber in the vocabulary is 113317\n",
      "the 289846th word in the vocabulary is potatos\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# æ¼”ç¤ºå•è¯ç´¢å¼•ä¸è¯å‘é‡æ˜ å°„\n",
    "# ----------------------------\n",
    "\n",
    "# å®šä¹‰è¦æŸ¥è¯¢çš„å•è¯\n",
    "word = \"cucumber\"\n",
    "\n",
    "# å®šä¹‰è¦æŸ¥è¯¢çš„ç´¢å¼•\n",
    "index = 289846\n",
    "\n",
    "# 1. æŸ¥è¯¢å•è¯å¯¹åº”çš„ç´¢å¼•\n",
    "# word_to_index[word] ä¼šè¿”å›å•è¯åœ¨è¯æ±‡è¡¨ä¸­çš„ç´¢å¼•\n",
    "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
    "# è¾“å‡ºç¤ºä¾‹: the index of cucumber in the vocabulary is 1234\n",
    "\n",
    "# 2. æŸ¥è¯¢ç´¢å¼•å¯¹åº”çš„å•è¯\n",
    "# index_to_word[index] ä¼šè¿”å›ç´¢å¼•å¯¹åº”çš„å•è¯\n",
    "print(\"the\", str(index) + \"th word in the vocabulary is\", index_to_word[index])\n",
    "# è¾“å‡ºç¤ºä¾‹: the 289846th word in the vocabulary is cucumber\n",
    "\n",
    "# è¯´æ˜ï¼š\n",
    "# - word_to_index ç”¨äºå°†å•è¯è½¬ä¸ºç´¢å¼•ï¼Œæ–¹ä¾¿åœ¨ç¥ç»ç½‘ç»œä¸­æŸ¥æ‰¾åµŒå…¥å‘é‡\n",
    "# - index_to_word ç”¨äºå°†ç´¢å¼•è½¬å›å•è¯ï¼Œä¾¿äºè§£é‡Šæ¨¡å‹è¾“å‡ºæˆ–è°ƒè¯•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ç»ƒä¹ **ï¼šå®ç° `sentence_to_avg()` å‡½æ•°ã€‚ä½ éœ€è¦å®Œæˆä»¥ä¸‹ä¸¤æ­¥ï¼š\n",
    "\n",
    "1. å°†æ¯ä¸ªå¥å­è½¬æ¢ä¸ºå°å†™å­—æ¯ï¼Œç„¶åå°†å¥å­æ‹†åˆ†ä¸ºå•è¯åˆ—è¡¨ã€‚å¯ä»¥ä½¿ç”¨ `X.lower()` å’Œ `X.split()`ã€‚  \n",
    "2. å¯¹å¥å­ä¸­çš„æ¯ä¸ªå•è¯ï¼Œè·å–å…¶å¯¹åº”çš„ GloVe å‘é‡è¡¨ç¤ºã€‚ç„¶åï¼Œå¯¹æ‰€æœ‰è¯å‘é‡å–å¹³å‡å€¼ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# å°†å¥å­è½¬æ¢ä¸ºå¹³å‡è¯å‘é‡\n",
    "# ----------------------------\n",
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    åŠŸèƒ½ï¼š\n",
    "        å°†ä¸€å¥è¯ï¼ˆsentenceï¼‰è½¬æ¢ä¸ºå•è¯åˆ—è¡¨ï¼Œæå–æ¯ä¸ªå•è¯çš„ GloVe è¯å‘é‡ï¼Œå¹¶è®¡ç®—å¹³å‡å‘é‡ã€‚\n",
    "        æœ€ç»ˆè¿”å›ä¸€ä¸ªè¡¨ç¤ºæ•´å¥è¯è¯­ä¹‰çš„å‘é‡ã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        sentence -- å­—ç¬¦ä¸²ç±»å‹ï¼Œä¸€æ¡è®­ç»ƒæ ·æœ¬ï¼ˆä¾‹å¦‚ X_train ä¸­çš„ä¸€æ¡å¥å­ï¼‰\n",
    "        word_to_vec_map -- å­—å…¸ç±»å‹ï¼Œå°†è¯æ±‡è¡¨ä¸­æ¯ä¸ªå•è¯æ˜ å°„ä¸º 50 ç»´è¯å‘é‡\n",
    "        \n",
    "    è¿”å›ï¼š\n",
    "        avg -- å¥å­çš„å¹³å‡è¯å‘é‡ï¼Œnumpy æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (50,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # ----------------------------\n",
    "    # 1. å°†å¥å­æ‹†åˆ†æˆå•è¯åˆ—è¡¨ï¼Œå¹¶å…¨éƒ¨è½¬æ¢ä¸ºå°å†™\n",
    "    # ä¾‹å¦‚ \"I love NLP\" -> [\"i\", \"love\", \"nlp\"]\n",
    "    # ----------------------------\n",
    "    words = sentence.lower().split()\n",
    "    \n",
    "    # ----------------------------\n",
    "    # 2. åˆå§‹åŒ–ä¸€ä¸ªå…¨é›¶çš„å‘é‡ï¼Œç”¨äºç´¯åŠ è¯å‘é‡\n",
    "    # ç»´åº¦ä¸ GloVe å‘é‡ç›¸åŒï¼Œè¿™é‡Œæ˜¯ 50 ç»´\n",
    "    # ----------------------------\n",
    "    avg = np.zeros(50,)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # 3. éå†å¥å­ä¸­çš„æ¯ä¸ªå•è¯ï¼Œå°†å¯¹åº”è¯å‘é‡ç´¯åŠ \n",
    "    # ----------------------------\n",
    "    for w in words:\n",
    "        avg += word_to_vec_map[w]   # ç´¯åŠ æ¯ä¸ªå•è¯çš„ 50 ç»´è¯å‘é‡\n",
    "    \n",
    "    # ----------------------------\n",
    "    # 4. å°†ç´¯åŠ çš„å‘é‡é™¤ä»¥å•è¯æ•°ï¼Œå¾—åˆ°å¹³å‡å‘é‡\n",
    "    # ----------------------------\n",
    "    avg = np.divide(avg, len(words))   # avg = avg / len(words)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # 5. è¿”å›å¥å­çš„å¹³å‡å‘é‡\n",
    "    # ----------------------------\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg =  [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
      " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
      "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
      "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
      "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
      "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
      " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
      " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
      "  0.1445417   0.09808667]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# ç¤ºä¾‹ï¼šå°†ä¸€å¥è¯è½¬æ¢ä¸ºå¹³å‡è¯å‘é‡\n",
    "# ----------------------------\n",
    "\n",
    "# å¥å­ç¤ºä¾‹\n",
    "sentence = \"Morrocan couscous is my favorite dish\"\n",
    "\n",
    "# è°ƒç”¨ sentence_to_avg å‡½æ•°ï¼Œå°†å¥å­è½¬æ¢ä¸º 50 ç»´å¹³å‡è¯å‘é‡\n",
    "avg = sentence_to_avg(sentence, word_to_vec_map)\n",
    "\n",
    "# æ‰“å°ç»“æœ\n",
    "print(\"avg = \", avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **avg= **\n",
    "        </td>\n",
    "        <td>\n",
    "           [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
    " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
    "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
    "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
    "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
    "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
    " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
    " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
    "  0.1445417   0.09808667]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#### æ¨¡å‹\n",
    "\n",
    "ç°åœ¨ï¼Œä½ å·²ç»å…·å¤‡å®Œæˆ `model()` å‡½æ•°å®ç°çš„æ‰€æœ‰ç»„ä»¶ã€‚  \n",
    "åœ¨ä½¿ç”¨ `sentence_to_avg()` åï¼Œä½ éœ€è¦å°†å¹³å‡å‘é‡è¾“å…¥åˆ°å‰å‘ä¼ æ’­ä¸­ï¼Œè®¡ç®—æŸå¤±ï¼Œç„¶åè¿›è¡Œåå‘ä¼ æ’­ä»¥æ›´æ–° softmax å‚æ•°ã€‚\n",
    "\n",
    "**ç»ƒä¹ **ï¼šå®ç°å›¾ï¼ˆ2ï¼‰ä¸­æè¿°çš„ `model()` å‡½æ•°ã€‚  \n",
    "å‡è®¾è¿™é‡Œçš„ $Yoh$ï¼ˆâ€œY one hotâ€ï¼‰æ˜¯è¾“å‡ºæ ‡ç­¾çš„ one-hot ç¼–ç ï¼Œå‰å‘ä¼ æ’­å’Œäº¤å‰ç†µæŸå¤±è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š\n",
    "\n",
    "$$ z^{(i)} = W . avg^{(i)} + b$$  \n",
    "$$ a^{(i)} = softmax(z^{(i)})$$  \n",
    "$$ \\mathcal{L}^{(i)} = - \\sum_{k = 0}^{n_y - 1} Yoh^{(i)}_k * log(a^{(i)}_k)$$\n",
    "\n",
    "å½“ç„¶å¯ä»¥å®ç°ä¸€ä¸ªæ›´é«˜æ•ˆçš„å‘é‡åŒ–å®ç°ã€‚ä½†ç”±äºæˆ‘ä»¬è¿™æ¬¡ä»ç„¶ä½¿ç”¨ for å¾ªç¯å°†å¥å­é€ä¸€è½¬æ¢ä¸º $avg^{(i)}$ è¡¨ç¤ºï¼Œè¿™é‡Œå°±ä¸å†ä¼˜åŒ–äº†ã€‚\n",
    "\n",
    "æˆ‘ä»¬å·²ç»ä¸ºä½ æä¾›äº†ä¸€ä¸ª `softmax()` å‡½æ•°ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# GRADED FUNCTION: model\n",
    "# ----------------------------\n",
    "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n",
    "    \"\"\"\n",
    "    åŸºäºå¹³å‡è¯å‘é‡çš„ç®€å•ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œç”¨äºè®­ç»ƒè¯å‘é‡è¡¨ç¤ºå’Œ emoji é¢„æµ‹\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "    X -- è¾“å…¥æ•°æ®ï¼Œnumpy æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå¥å­ï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼Œå½¢çŠ¶ (m, 1)\n",
    "    Y -- æ ‡ç­¾ï¼Œnumpy æ•°ç»„ï¼Œæ•´æ•°å½¢å¼ï¼ˆ0~4 å¯¹åº” emoji ç±»åˆ«ï¼‰ï¼Œå½¢çŠ¶ (m, 1)\n",
    "    word_to_vec_map -- å­—å…¸ï¼Œå°†è¯æ˜ å°„åˆ° 50 ç»´ GloVe å‘é‡\n",
    "    learning_rate -- å­¦ä¹ ç‡ï¼Œç”¨äºéšæœºæ¢¯åº¦ä¸‹é™\n",
    "    num_iterations -- è¿­ä»£æ¬¡æ•°\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "    pred -- æ¨¡å‹é¢„æµ‹ç»“æœï¼Œnumpy æ•°ç»„ï¼Œå½¢çŠ¶ (m, 1)\n",
    "    W -- softmax å±‚æƒé‡çŸ©é˜µï¼Œå½¢çŠ¶ (n_y, n_h)\n",
    "    b -- softmax å±‚åç½®ï¼Œå½¢çŠ¶ (n_y,)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)  # è®¾ç½®éšæœºç§å­ï¼Œä¿è¯ç»“æœå¯å¤ç°\n",
    "\n",
    "    # ----------------------------\n",
    "    # åˆå§‹åŒ–å‚æ•°\n",
    "    # ----------------------------\n",
    "    m = Y.shape[0]      # è®­ç»ƒæ ·æœ¬æ•°é‡\n",
    "    n_y = 5             # åˆ†ç±»ç±»åˆ«æ•°ï¼ˆemoji ç±»åˆ«ï¼‰\n",
    "    n_h = 50            # GloVe å‘é‡ç»´åº¦\n",
    "    \n",
    "    # Xavier åˆå§‹åŒ–æƒé‡çŸ©é˜µ Wï¼Œä½¿æƒé‡åˆ†å¸ƒæ›´å‡åŒ€\n",
    "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)  \n",
    "    b = np.zeros((n_y,))  # åç½®å‘é‡åˆå§‹åŒ–ä¸º 0\n",
    "\n",
    "    # å°†æ ‡ç­¾ Y è½¬æ¢ä¸º one-hot ç¼–ç ï¼Œä¾¿äº softmax è®¡ç®—\n",
    "    Y_oh = convert_to_one_hot(Y, C = n_y) \n",
    "    \n",
    "    # ----------------------------\n",
    "    # æ¢¯åº¦ä¸‹é™ä¼˜åŒ–å¾ªç¯\n",
    "    # ----------------------------\n",
    "    for t in range(num_iterations):            # éå†è¿­ä»£æ¬¡æ•°\n",
    "        for i in range(m):                     # éå†æ¯ä¸ªè®­ç»ƒæ ·æœ¬\n",
    "            \n",
    "            # ----------------------------\n",
    "            # ç¬¬ i ä¸ªè®­ç»ƒæ ·æœ¬ï¼šè®¡ç®—å¥å­å¹³å‡è¯å‘é‡\n",
    "            # ----------------------------\n",
    "            avg = sentence_to_avg(X[i], word_to_vec_map)  # avg å½¢çŠ¶ (50,)\n",
    "\n",
    "            # ----------------------------\n",
    "            # å‰å‘ä¼ æ’­\n",
    "            # z = WÂ·avg + b\n",
    "            # ----------------------------\n",
    "            z = np.dot(W, avg) + b                        # çº¿æ€§ç»„åˆï¼Œå½¢çŠ¶ (n_y,)\n",
    "            a = softmax(z)                                # softmax è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒ\n",
    "\n",
    "            # ----------------------------\n",
    "            # è®¡ç®—æŸå¤±ï¼ˆäº¤å‰ç†µæŸå¤±ï¼‰\n",
    "            # ----------------------------\n",
    "            cost = -np.sum(Y_oh[i]*np.log(a))             # ç¬¬ i ä¸ªæ ·æœ¬çš„æŸå¤±\n",
    "\n",
    "            # ----------------------------\n",
    "            # åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦\n",
    "            # ----------------------------\n",
    "            dz = a - Y_oh[i]                              # softmax è¯¯å·®\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))  # æƒé‡æ¢¯åº¦\n",
    "            db = dz                                       # åç½®æ¢¯åº¦\n",
    "\n",
    "            # ----------------------------\n",
    "            # å‚æ•°æ›´æ–°ï¼ˆéšæœºæ¢¯åº¦ä¸‹é™ï¼‰\n",
    "            # ----------------------------\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "        \n",
    "        # æ¯ 100 ä¸ª epoch è¾“å‡ºä¸€æ¬¡æŸå¤±å’Œå‡†ç¡®ç‡ï¼Œä¾¿äºè§‚å¯Ÿè®­ç»ƒæ•ˆæœ\n",
    "        if t % 100 == 0:\n",
    "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
    "            pred = predict(X, Y, W, b, word_to_vec_map)  # è¾“å‡ºå½“å‰é¢„æµ‹å‡†ç¡®ç‡\n",
    "\n",
    "    # è¿”å›æœ€ç»ˆé¢„æµ‹ã€æƒé‡å’Œåç½®\n",
    "    return pred, W, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,)\n",
      "(132,)\n",
      "(132, 5)\n",
      "never talk to me again\n",
      "<class 'numpy.ndarray'>\n",
      "(20,)\n",
      "(20,)\n",
      "(132, 5)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# è¾“å‡ºè®­ç»ƒé›† X_train çš„å½¢çŠ¶\n",
    "print(X_train.shape)\n",
    "# X_train æ˜¯å¥å­åˆ—è¡¨ï¼Œé€šå¸¸å½¢çŠ¶ä¸º (m, ) æˆ– (m,1)ï¼Œm = æ ·æœ¬æ•°\n",
    "\n",
    "# è¾“å‡ºè®­ç»ƒæ ‡ç­¾ Y_train çš„å½¢çŠ¶\n",
    "print(Y_train.shape)\n",
    "# Y_train æ˜¯æ•´æ•°æ ‡ç­¾æ•°ç»„ï¼Œå½¢çŠ¶ (m, 1)\n",
    "\n",
    "# å°† Y_train è½¬ä¸º one-hot ç¼–ç å¹¶æŸ¥çœ‹å½¢çŠ¶\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "# np.eye(5) ç”Ÿæˆ 5x5 å•ä½çŸ©é˜µ\n",
    "# Y_train.reshape(-1) å°† Y_train æ‹‰æˆä¸€ç»´\n",
    "# np.eye(5)[Y_train.reshape(-1)] å¾—åˆ°æ¯ä¸ªæ ‡ç­¾å¯¹åº”çš„ one-hot ç¼–ç \n",
    "# ç»“æœå½¢çŠ¶ (m, 5)\n",
    "\n",
    "# æ‰“å°è®­ç»ƒé›†ç¬¬ä¸€ä¸ªæ ·æœ¬\n",
    "print(X_train[0])\n",
    "# è¾“å‡ºç¤ºä¾‹å¥å­å­—ç¬¦ä¸²\n",
    "\n",
    "# æŸ¥çœ‹ X_train çš„æ•°æ®ç±»å‹\n",
    "print(type(X_train))\n",
    "# é€šå¸¸æ˜¯ numpy.ndarray æˆ– list\n",
    "\n",
    "# æ„å»ºä¸€ä¸ªå°å‹æ ‡ç­¾æ•°ç»„ Yï¼ˆ16 ä¸ªæ ·æœ¬ï¼‰\n",
    "Y = np.asarray([5,0,0,5, 4, 4, 4, 6, 6, 4, 1, 1, 5, 6, 6, 3, 6, 3, 4, 4])\n",
    "print(Y.shape)\n",
    "# è¾“å‡º Y çš„å½¢çŠ¶ (20,)\n",
    "\n",
    "# æ„å»ºä¸€ä¸ªå°å‹å¥å­æ•°ç»„ Xï¼Œå¯¹åº”ä¸Šé¢çš„æ ‡ç­¾ Y\n",
    "X = np.asarray([\n",
    "    'I am going to the bar tonight', \n",
    "    'I love you', \n",
    "    'miss you my dear',\n",
    "    'Lets go party and drinks',\n",
    "    'Congrats on the new job',\n",
    "    'Congratulations',\n",
    "    'I am so happy for you',\n",
    "    'Why are you feeling bad',\n",
    "    'What is wrong with you',\n",
    "    'You totally deserve this prize',\n",
    "    'Let us go play football',\n",
    "    'Are you down for football this afternoon',\n",
    "    'Work hard play harder',\n",
    "    'It is suprising how people can be dumb sometimes',\n",
    "    'I am very disappointed',\n",
    "    'It is the best day in my life',\n",
    "    'I think I will end up alone',\n",
    "    'My life is so boring',\n",
    "    'Good job',\n",
    "    'Great so awesome'\n",
    "])\n",
    "print(X.shape)\n",
    "# è¾“å‡º X çš„å½¢çŠ¶ (20,)\n",
    "\n",
    "# å†æ¬¡æ‰“å° Y_train çš„ one-hot ç¼–ç å½¢çŠ¶\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "\n",
    "# å†æ¬¡æ‰“å° X_train çš„ç±»å‹\n",
    "print(type(X_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿è¡Œä¸‹ä¸€ä¸ªä»£ç å•å…ƒä»¥è®­ç»ƒä½ çš„æ¨¡å‹ï¼Œå¹¶å­¦ä¹  softmax å‚æ•° **(W, b)**ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = 1.9520498812810072\n",
      "Accuracy: 0.3484848484848485\n",
      "Epoch: 100 --- cost = 0.07971818726014807\n",
      "Accuracy: 0.9318181818181818\n",
      "Epoch: 200 --- cost = 0.04456369243681402\n",
      "Accuracy: 0.9545454545454546\n",
      "Epoch: 300 --- cost = 0.03432267378786059\n",
      "Accuracy: 0.9696969696969697\n",
      "[[3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "# è®­ç»ƒæ¨¡å‹\n",
    "pred, W, b = model(X_train, Y_train, word_to_vec_map)\n",
    "# model(...) è¿”å›ä¸‰ä¸ªå€¼ï¼š\n",
    "# pred -- numpy æ•°ç»„ï¼Œæ¨¡å‹å¯¹è®­ç»ƒé›† X_train çš„é¢„æµ‹æ ‡ç­¾ï¼Œå½¢çŠ¶ (m, 1)\n",
    "# W    -- softmax å±‚çš„æƒé‡çŸ©é˜µï¼Œå½¢çŠ¶ (n_y, n_h)ï¼Œè¿™é‡Œ n_y=5ï¼ˆç±»åˆ«æ•°ï¼‰ï¼Œn_h=50ï¼ˆGloVe å‘é‡ç»´åº¦ï¼‰\n",
    "# b    -- softmax å±‚çš„åç½®å‘é‡ï¼Œå½¢çŠ¶ (n_y,)\n",
    "\n",
    "# è¾“å‡ºè®­ç»ƒåçš„é¢„æµ‹ç»“æœ\n",
    "print(pred)\n",
    "# pred çš„æ¯ä¸ªå…ƒç´ æ˜¯è®­ç»ƒé›†ä¸­æ¯ä¸ªå¥å­çš„é¢„æµ‹ emoji ç±»åˆ«ï¼ˆæ•´æ•°ç´¢å¼•ï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output** (on a subset of iterations):\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Epoch: 0**\n",
    "        </td>\n",
    "        <td>\n",
    "           cost = 1.95204988128\n",
    "        </td>\n",
    "        <td>\n",
    "           Accuracy: 0.348484848485\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "\n",
    "<tr>\n",
    "        <td>\n",
    "            **Epoch: 100**\n",
    "        </td>\n",
    "        <td>\n",
    "           cost = 0.0797181872601\n",
    "        </td>\n",
    "        <td>\n",
    "           Accuracy: 0.931818181818\n",
    "        </td>\n",
    "    </tr>\n",
    "    \n",
    "<tr>\n",
    "        <td>\n",
    "            **Epoch: 200**\n",
    "        </td>\n",
    "        <td>\n",
    "           cost = 0.0445636924368\n",
    "        </td>\n",
    "        <td>\n",
    "           Accuracy: 0.954545454545\n",
    "        </td>\n",
    "    </tr>\n",
    "    \n",
    "    <tr>\n",
    "        <td>\n",
    "            **Epoch: 300**\n",
    "        </td>\n",
    "        <td>\n",
    "           cost = 0.0343226737879\n",
    "        </td>\n",
    "        <td>\n",
    "           Accuracy: 0.969696969697\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¤ªæ£’äº†ï¼ä½ çš„æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„å‡†ç¡®ç‡ç›¸å½“é«˜ã€‚  \n",
    "ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å®ƒåœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°å¦‚ä½•ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### 1.4 - æµ‹è¯•é›†æ€§èƒ½è¯„ä¼°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.9772727272727273\n",
      "Test set:\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# å¯¹è®­ç»ƒé›†è¿›è¡Œé¢„æµ‹\n",
    "# ----------------------------\n",
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "# è°ƒç”¨ predict å‡½æ•°ï¼š\n",
    "# X_train -- è¾“å…¥å¥å­åˆ—è¡¨\n",
    "# Y_train -- çœŸå®æ ‡ç­¾\n",
    "# W, b -- æ¨¡å‹è®­ç»ƒå¾—åˆ°çš„ softmax å‚æ•°\n",
    "# word_to_vec_map -- GloVe è¯å‘é‡å­—å…¸\n",
    "# è¿”å› pred_trainï¼šè®­ç»ƒé›†çš„é¢„æµ‹ç»“æœï¼Œå½¢çŠ¶ (m, 1)\n",
    "# å‡½æ•°å†…éƒ¨ä¼šï¼š\n",
    "#   1. å°†æ¯ä¸ªå¥å­æ‹†åˆ†æˆå•è¯\n",
    "#   2. å–æ¯ä¸ªå•è¯çš„ GloVe å‘é‡å¹¶æ±‚å¹³å‡å¾—åˆ°å¥å­å‘é‡\n",
    "#   3. è®¡ç®— Z = WÂ·avg + b\n",
    "#   4. é€šè¿‡ softmax å¾—åˆ°æ¦‚ç‡å‘é‡\n",
    "#   5. å–æœ€å¤§æ¦‚ç‡ç´¢å¼•ä½œä¸ºé¢„æµ‹\n",
    "#   6. è®¡ç®—é¢„æµ‹å‡†ç¡®ç‡å¹¶æ‰“å°\n",
    "\n",
    "# ----------------------------\n",
    "# å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹\n",
    "# ----------------------------\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)\n",
    "# ç”¨è®­ç»ƒå¥½çš„ W å’Œ b å¯¹æµ‹è¯•é›† X_test è¿›è¡Œé¢„æµ‹\n",
    "# è¿”å› pred_testï¼šæµ‹è¯•é›†çš„é¢„æµ‹ç»“æœï¼Œå½¢çŠ¶ (m_test, 1)\n",
    "# åŒæ ·å†…éƒ¨ä¼šæ‰“å°æµ‹è¯•é›†çš„å‡†ç¡®ç‡\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Train set accuracy**\n",
    "        </td>\n",
    "        <td>\n",
    "           97.7\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Test set accuracy**\n",
    "        </td>\n",
    "        <td>\n",
    "           85.7\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨æœ‰ 5 ä¸ªç±»åˆ«çš„æƒ…å†µä¸‹ï¼ŒéšæœºçŒœæµ‹çš„å‡†ç¡®ç‡åªæœ‰ 20%ã€‚  \n",
    "è€Œåœ¨ä»…ç”¨ 127 ä¸ªæ ·æœ¬è®­ç»ƒåï¼Œä½ çš„æ¨¡å‹å°±èƒ½è¾¾åˆ°è¿™æ ·çš„æ€§èƒ½ï¼Œå·²ç»ç›¸å½“ä¸é”™äº†ã€‚\n",
    "\n",
    "åœ¨è®­ç»ƒé›†ä¸­ï¼Œç®—æ³•è§è¿‡å¥å­ \"*I love you*\"ï¼Œå¯¹åº”æ ‡ç­¾ä¸º â¤ï¸ã€‚  \n",
    "ç„¶è€Œï¼Œä½ å¯ä»¥æ³¨æ„åˆ°å•è¯ \"adore\" å¹¶æœªå‡ºç°åœ¨è®­ç»ƒé›†ä¸­ã€‚  \n",
    "å°½ç®¡å¦‚æ­¤ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹è¾“å…¥ \"*I adore you*\" æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n",
      "\n",
      "i adore you â¤ï¸\n",
      "i love you â¤ï¸\n",
      "funny lol :smile:\n",
      "lets play with a ball âš¾\n",
      "food is ready ğŸ´\n",
      "not feeling happy :smile:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luxia\\AppData\\Local\\Temp\\ipykernel_26760\\3157549296.py:129: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(X[i], label_to_emoji(int(pred[i])))\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# è‡ªå®šä¹‰å¥å­åŠå¯¹åº”æ ‡ç­¾\n",
    "# ----------------------------\n",
    "X_my_sentences = np.array([\n",
    "    \"i adore you\",             # å¥å­1\n",
    "    \"i love you\",              # å¥å­2\n",
    "    \"funny lol\",               # å¥å­3\n",
    "    \"lets play with a ball\",   # å¥å­4\n",
    "    \"food is ready\",           # å¥å­5\n",
    "    \"not feeling happy\"        # å¥å­6\n",
    "])\n",
    "\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "# æ¯ä¸ªå¥å­çš„çœŸå®æ ‡ç­¾\n",
    "# 0: â¤ï¸ (heart)\n",
    "# 1: âš¾ (baseball)\n",
    "# 2: ğŸ˜„ (smile)\n",
    "# 3: ğŸ˜ (disappointed)\n",
    "# 4: ğŸ´ (fork_and_knife)\n",
    "\n",
    "# ----------------------------\n",
    "# å¯¹è‡ªå®šä¹‰å¥å­è¿›è¡Œé¢„æµ‹\n",
    "# ----------------------------\n",
    "pred = predict(X_my_sentences, Y_my_labels, W, b, word_to_vec_map)\n",
    "# predict å‡½æ•°å†…éƒ¨æ­¥éª¤ï¼š\n",
    "# 1. éå†æ¯ä¸ªå¥å­ï¼Œå°†å¥å­æ‹†æˆå•è¯\n",
    "# 2. å¯¹æ¯ä¸ªå•è¯å– GloVe è¯å‘é‡\n",
    "# 3. æ±‚å¥å­æ‰€æœ‰è¯å‘é‡çš„å¹³å‡ï¼Œå¾—åˆ°å¥å­å‘é‡ avg\n",
    "# 4. å‰å‘ä¼ æ’­è®¡ç®— Z = W Â· avg + b\n",
    "# 5. é€šè¿‡ softmax å¾—åˆ°æ¦‚ç‡åˆ†å¸ƒ\n",
    "# 6. å–æ¦‚ç‡æœ€å¤§å€¼å¯¹åº”ç´¢å¼•ä½œä¸ºé¢„æµ‹ç»“æœ\n",
    "# 7. æ‰“å°é¢„æµ‹çš„å‡†ç¡®ç‡\n",
    "\n",
    "# ----------------------------\n",
    "# æ‰“å°é¢„æµ‹ç»“æœ\n",
    "# ----------------------------\n",
    "print_predictions(X_my_sentences, pred)\n",
    "# print_predictions å‡½æ•°ï¼š\n",
    "# éå†æ¯ä¸ªå¥å­\n",
    "# è°ƒç”¨ label_to_emoji(pred[i]) å°†é¢„æµ‹çš„æ ‡ç­¾ç´¢å¼•è½¬æ¢ä¸º emoji\n",
    "# æ‰“å° \"å¥å­ â†’ emoji\"\n",
    "# ä¾‹å¦‚è¾“å‡ºï¼š\n",
    "# i adore you â¤ï¸\n",
    "# funny lol ğŸ˜„\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¤ªæ£’äº†ï¼ç”±äº *adore* ä¸ *love* çš„è¯å‘é‡ç›¸ä¼¼ï¼Œç®—æ³•èƒ½å¤Ÿæ­£ç¡®æ³›åŒ–ï¼Œå³ä½¿æ˜¯ä¸€ä¸ªä»æœªè§è¿‡çš„å•è¯ä¹Ÿèƒ½å¤„ç†æ­£ç¡®ã€‚  \n",
    "åƒ *heart*ã€*dear*ã€*beloved* æˆ– *adore* è¿™æ ·çš„è¯ï¼Œå…¶è¯å‘é‡éƒ½ä¸ *love* ç±»ä¼¼ï¼Œå› æ­¤ä¹Ÿå¯èƒ½åŒæ ·æœ‰æ•ˆâ€”â€”ä½ å¯ä»¥è‡ªç”±ä¿®æ”¹ä¸Šè¿°è¾“å…¥ï¼Œå°è¯•å„ç§å¥å­ï¼Œçœ‹çœ‹æ•ˆæœå¦‚ä½•ã€‚\n",
    "\n",
    "éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç®—æ³•æ— æ³•æ­£ç¡®å¤„ç† \"*not feeling happy*\" è¿™ç§æƒ…å†µã€‚  \n",
    "è¿™æ˜¯å› ä¸ºè¯¥ç®—æ³•å¿½ç•¥äº†**å•è¯é¡ºåº**ï¼Œå› æ­¤ä¸æ“…é•¿ç†è§£è¯¸å¦‚ \"*not happy*\" è¿™æ ·çš„çŸ­è¯­ã€‚\n",
    "\n",
    "æ‰“å° **æ··æ·†çŸ©é˜µï¼ˆconfusion matrixï¼‰** ä¹Ÿèƒ½å¸®åŠ©ç†è§£å“ªäº›ç±»åˆ«å¯¹ä½ çš„æ¨¡å‹æ¥è¯´æ›´éš¾ã€‚  \n",
    "æ··æ·†çŸ©é˜µæ˜¾ç¤ºäº†æŸä¸ªå®é™…æ ‡ç­¾ä¸ºæŸç±»åˆ«ï¼ˆ\"actual\" classï¼‰çš„æ ·æœ¬ï¼Œè¢«ç®—æ³•è¯¯æ ‡ä¸ºå…¶ä»–ç±»åˆ«ï¼ˆ\"predicted\" class\"ï¼‰çš„é¢‘ç‡ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n",
      "           â¤ï¸    âš¾    :smile:    :disappointed:   ğŸ´\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# æŸ¥çœ‹æµ‹è¯•é›†æ ‡ç­¾çš„å½¢çŠ¶\n",
    "# ----------------------------\n",
    "print(Y_test.shape)\n",
    "# è¾“å‡º (56,) â†’ æµ‹è¯•é›†æœ‰ 56 ä¸ªå¥å­\n",
    "\n",
    "# ----------------------------\n",
    "# æ‰“å°åˆ—æ ‡é¢˜ï¼ˆemoji è¡¨ç¤ºæ¯ä¸ªç±»åˆ«ï¼‰\n",
    "# ----------------------------\n",
    "print('           ' + label_to_emoji(0) + '    ' + label_to_emoji(1) + '    ' + label_to_emoji(2) + '    ' + label_to_emoji(3) + '   ' + label_to_emoji(4))\n",
    "# label_to_emoji å‡½æ•°å°†ç±»åˆ«ç´¢å¼•è½¬æ¢ä¸º emoji\n",
    "# è¾“å‡ºç¤ºä¾‹ï¼š           â¤ï¸    âš¾    ğŸ˜„    ğŸ˜   ğŸ´\n",
    "\n",
    "# ----------------------------\n",
    "# ç”Ÿæˆæµ‹è¯•é›†æ··æ·†çŸ©é˜µ\n",
    "# ----------------------------\n",
    "pd.crosstab(\n",
    "    Y_test,                        # è¡Œï¼šçœŸå®æ ‡ç­¾\n",
    "    pred_test.reshape(56,),        # åˆ—ï¼šé¢„æµ‹æ ‡ç­¾\n",
    "    rownames=['Actual'],           # è¡Œå\n",
    "    colnames=['Predicted'],        # åˆ—å\n",
    "    margins=True                   # æ·»åŠ è¡Œ/åˆ—æ€»è®¡\n",
    ")\n",
    "# è¾“å‡ºä¸€ä¸ª DataFrameï¼Œæ˜¾ç¤ºæ¯ä¸ªçœŸå®ç±»åˆ«è¢«é¢„æµ‹ä¸ºå„ç±»åˆ«çš„æ¬¡æ•°\n",
    "# margins=True ä¼šåœ¨æœ€åä¸€è¡Œ/åˆ—æ˜¾ç¤ºæ€»å’Œ\n",
    "\n",
    "# ----------------------------\n",
    "# å¯è§†åŒ–æ··æ·†çŸ©é˜µ\n",
    "# ----------------------------\n",
    "plot_confusion_matrix(Y_test, pred_test)\n",
    "# plot_confusion_matrix å‡½æ•°æ­¥éª¤ï¼š\n",
    "# 1. ç”¨ pd.crosstab æ„å»ºæ··æ·†çŸ©é˜µ\n",
    "# 2. å½’ä¸€åŒ–ï¼ˆé™¤ä»¥æ¯è¡Œæ€»å’Œï¼‰å¾—åˆ°æ¯ä¸ªç±»åˆ«é¢„æµ‹æ¯”ä¾‹\n",
    "# 3. plt.matshow æ˜¾ç¤ºçŸ©é˜µï¼Œé¢œè‰²è¡¨ç¤ºé¢„æµ‹æ•°é‡\n",
    "# 4. è®¾ç½®åæ ‡è½´æ ‡ç­¾ã€æ ‡é¢˜ã€é¢œè‰²æ¡\n",
    "# 5. è¾“å‡ºå›¾åƒæ–¹ä¾¿ç›´è§‚åˆ†ææ¨¡å‹é¢„æµ‹æƒ…å†µ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**æœ¬éƒ¨åˆ†éœ€è¦è®°ä½çš„å†…å®¹**ï¼š\n",
    "- å³ä½¿åªæœ‰ 127 ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œä½ ä¹Ÿå¯ä»¥å¾—åˆ°ä¸€ä¸ªç›¸å½“ä¸é”™çš„è¡¨æƒ…ç¬¦å·ç”Ÿæˆæ¨¡å‹ã€‚è¿™è¦å½’åŠŸäºè¯å‘é‡æä¾›çš„æ³›åŒ–èƒ½åŠ›ã€‚  \n",
    "- Emojify-V1 åœ¨å¤„ç†åƒ *\"This movie is not good and not enjoyable\"* è¿™æ ·çš„å¥å­æ—¶è¡¨ç°ä¸ä½³ï¼Œå› ä¸ºå®ƒæ— æ³•ç†è§£å•è¯ç»„åˆâ€”â€”å®ƒåªæ˜¯å°†æ‰€æœ‰å•è¯çš„è¯å‘é‡å¹³å‡ï¼Œè€Œä¸å…³æ³¨å•è¯çš„é¡ºåºã€‚ä½ å°†åœ¨ä¸‹ä¸€éƒ¨åˆ†æ„å»ºä¸€ä¸ªæ›´å¥½çš„ç®—æ³•ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Emojifier-V2ï¼šåœ¨Pytorchä¸­ä½¿ç”¨ LSTM\n",
    "\n",
    "è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ª **LSTM æ¨¡å‹**ï¼Œè¾“å…¥ä¸ºå•è¯åºåˆ—ã€‚  \n",
    "è¯¥æ¨¡å‹èƒ½å¤Ÿè€ƒè™‘å•è¯çš„é¡ºåºã€‚Emojifier-V2 å°†ç»§ç»­ä½¿ç”¨**é¢„è®­ç»ƒè¯å‘é‡**æ¥è¡¨ç¤ºå•è¯ï¼Œä½†ä¼šå°†è¿™äº›è¯å‘é‡è¾“å…¥åˆ° LSTM ä¸­ï¼Œç”± LSTM é¢„æµ‹æœ€åˆé€‚çš„è¡¨æƒ…ç¬¦å·ã€‚\n",
    "\n",
    "è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒä»¥åŠ è½½Pytorchæ‰€éœ€çš„åŒ…ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# å¯¼å…¥å¸¸ç”¨åº“\n",
    "# ----------------------------\n",
    "import numpy as np  \n",
    "# å¯¼å…¥ NumPy åº“ï¼Œç”¨äºé«˜æ•ˆçš„æ•°å€¼è®¡ç®—ã€æ•°ç»„æ“ä½œå’Œçº¿æ€§ä»£æ•°è¿ç®—\n",
    "\n",
    "import torch  \n",
    "# å¯¼å…¥ PyTorch ä¸»åº“ï¼Œç”¨äºå¼ é‡æ“ä½œã€è‡ªåŠ¨æ±‚å¯¼å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹æ„å»º\n",
    "\n",
    "import torch.nn as nn  \n",
    "# å¯¼å…¥ torch.nn æ¨¡å—ï¼Œå…¶ä¸­åŒ…å«æ„å»ºç¥ç»ç½‘ç»œçš„å„ç±»å±‚ï¼ˆå¦‚ Linear, Conv2d, LSTM ç­‰ï¼‰\n",
    "# nn æ˜¯æ„å»ºæ¨¡å‹çš„åŸºç¡€æ¨¡å—\n",
    "\n",
    "import torch.nn.functional as F  \n",
    "# å¯¼å…¥ torch.nn.functional æ¨¡å—ï¼Œæä¾›äº†å¤§é‡å‡½æ•°åŒ–çš„æ“ä½œï¼Œå¦‚æ¿€æ´»å‡½æ•°ï¼ˆrelu, softmax ç­‰ï¼‰ã€æŸå¤±å‡½æ•°ç­‰\n",
    "# ä¸ nn.Module ä¸­çš„å±‚ä¸åŒï¼Œfunctional æä¾›çš„æ˜¯â€œå‡½æ•°å¼â€æ“ä½œï¼Œä¸åŒ…å«å¯å­¦ä¹ å‚æ•°\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "# Datasetï¼šç”¨äºå°è£…è‡ªå®šä¹‰æ•°æ®é›†ï¼Œå¿…é¡»å®ç° __len__() å’Œ __getitem__() æ–¹æ³•\n",
    "# DataLoaderï¼šæä¾›æ‰¹é‡è¯»å–æ•°æ®ã€æ‰“ä¹±é¡ºåºå’Œå¤šçº¿ç¨‹åŠ è½½çš„åŠŸèƒ½\n",
    "# å¸¸ç”¨äºè®­ç»ƒå¾ªç¯ä¸­æŒ‰ batch è·å–æ•°æ®\n",
    "\n",
    "import random  \n",
    "# Python æ ‡å‡†åº“çš„ random æ¨¡å—ï¼Œç”¨äºç”Ÿæˆéšæœºæ•°ã€éšæœºé€‰æ‹©æˆ–æ‰“ä¹±æ•°æ®\n",
    "# åœ¨è®­ç»ƒæˆ–åˆå§‹åŒ–æƒé‡æ—¶å¸¸ç”¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# è®¾å¤‡é€‰æ‹©ï¼ˆCPU / GPUï¼‰\n",
    "# ----------------------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "# torch.device()ï¼šPyTorch ä¸­è¡¨ç¤ºå­˜æ”¾å¼ é‡å’Œæ¨¡å‹çš„è®¾å¤‡å¯¹è±¡\n",
    "# \"cuda\"ï¼šè¡¨ç¤º GPUï¼Œå¦‚æœæœ‰å¯ç”¨çš„ NVIDIA GPUï¼Œå¯ç”¨äºåŠ é€Ÿè®¡ç®—\n",
    "# \"cpu\"ï¼šè¡¨ç¤ºä½¿ç”¨ CPU è¿›è¡Œè®¡ç®—\n",
    "# torch.cuda.is_available()ï¼šæ£€æŸ¥å½“å‰ç³»ç»Ÿæ˜¯å¦æœ‰å¯ç”¨çš„ GPU\n",
    "# è¯­å¥å«ä¹‰ï¼šå¦‚æœæœ‰å¯ç”¨ GPUï¼Œåˆ™ä½¿ç”¨ GPUï¼›å¦åˆ™é€€å›åˆ° CPU\n",
    "# å°† device å¯¹è±¡ä¼ ç»™å¼ é‡æˆ–æ¨¡å‹ï¼Œå¯ä»¥å®ç°å¼ é‡/æ¨¡å‹åœ¨ GPU ä¸Šè¿ç®—\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - æ¨¡å‹æ¦‚è§ˆï¼ˆPyTorch ç‰ˆæœ¬ï¼‰\n",
    "\n",
    "ä¸‹é¢æ˜¯ä½ å°†è¦å®ç°çš„ **Emojifier-V2** PyTorch ç‰ˆæœ¬ï¼š\n",
    "\n",
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center> **å›¾ 3**ï¼šEmojifier-V2ã€‚ä¸€ä¸ªä¸¤å±‚ LSTM åºåˆ—åˆ†ç±»å™¨ã€‚</center></caption>\n",
    "\n",
    "åœ¨ PyTorch ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ `nn.Embedding`ã€`nn.LSTM` å’Œ `nn.Linear` æ¥å®ç°è¿™ä¸ªæ¨¡å‹ã€‚  \n",
    "è®­ç»ƒæ–¹å¼ä¹Ÿå°†ä½¿ç”¨ mini-batchï¼Œä½† PyTorch ä¸­è¦æ±‚åŒä¸€ mini-batch çš„æ‰€æœ‰åºåˆ—é•¿åº¦ç›¸åŒï¼Œè¿™ä¸ Keras ç›¸åŒã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Mini-batch ä¸å¡«å……ï¼ˆPaddingï¼‰\n",
    "\n",
    "åœ¨ PyTorch ä¸­å¤„ç†ä¸åŒé•¿åº¦çš„åºåˆ—æ—¶ä¹Ÿå¿…é¡»è¿›è¡Œ **å¡«å……ï¼ˆpaddingï¼‰**ã€‚  \n",
    "å…·ä½“æ–¹æ³•ä¸ Keras ç›¸åŒï¼šè®¾å®šæœ€å¤§å¥å­é•¿åº¦ `max_len`ï¼Œå°†æ‰€æœ‰åºåˆ—å¡«å……æˆ–æˆªæ–­åˆ°ç›¸åŒé•¿åº¦ã€‚ä¾‹å¦‚ï¼š\n",
    "å› æ­¤ï¼Œå¥å­ \"i love you\" å°†è¡¨ç¤ºä¸ºï¼š\n",
    "$$(e_{i}, e_{love}, e_{you}, \\vec{0}, \\vec{0}, \\ldots, \\vec{0})$$\n",
    "\n",
    "å…¶ä¸­ 0 è¡¨ç¤ºå¡«å……å€¼ï¼Œé•¿åº¦ç»Ÿä¸€ä¸º `max_len`ã€‚  \n",
    "è¿™ä½¿å¾—åºåˆ—å¯ä»¥åŒæ—¶è¢«é€å…¥ LSTMï¼Œä¾¿äºæ‰¹é‡è®¡ç®—ã€‚\n",
    "\n",
    "åœ¨ PyTorch ä¸­ï¼Œå¯ä»¥é€šè¿‡è‡ªå®šä¹‰å‡½æ•° `sentences_to_indices()` å°†å¥å­è½¬æ¢ä¸ºç´¢å¼•çŸ©é˜µã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - åµŒå…¥å±‚ï¼ˆEmbedding layerï¼‰\n",
    "\n",
    "åœ¨ PyTorch ä¸­ï¼ŒåµŒå…¥çŸ©é˜µç”± `nn.Embedding` è¡¨ç¤ºï¼Œå®ƒå°†æ­£æ•´æ•°ï¼ˆå•è¯ç´¢å¼•ï¼‰æ˜ å°„åˆ°å›ºå®šå¤§å°çš„ç¨ å¯†å‘é‡ï¼ˆembedding å‘é‡ï¼‰ã€‚  \n",
    "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒçš„ GloVe è¯å‘é‡åˆå§‹åŒ–è¯¥å±‚ï¼Œå¹¶å°†å…¶è®¾ç½®ä¸º **ä¸å¯è®­ç»ƒï¼ˆfreeze=Trueï¼‰**ï¼Œä¿æŒè¯å‘é‡å›ºå®šã€‚\n",
    "\n",
    "`Embedding()` å±‚çš„è¾“å…¥æ˜¯ä¸€ä¸ªæ•´æ•°çŸ©é˜µï¼Œå½¢çŠ¶ä¸º **(batch size, max input length)**ã€‚  \n",
    "è¿™å¯¹åº”äºå°†å¥å­è½¬æ¢ä¸ºç´¢å¼•åˆ—è¡¨ï¼ˆæ•´æ•°ï¼‰ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\n",
    "\n",
    "<img src=\"images/embedding1.png\" style=\"width:700px;height:250px;\">\n",
    "<caption><center> **å›¾ 4**ï¼šåµŒå…¥å±‚ç¤ºæ„å›¾ã€‚è¯¥ç¤ºä¾‹å±•ç¤ºäº†ä¸¤ä¸ªæ ·æœ¬é€šè¿‡åµŒå…¥å±‚çš„ä¼ æ’­è¿‡ç¨‹ã€‚  \n",
    "ä¸¤ä¸ªæ ·æœ¬éƒ½è¢«ç”¨ 0 å¡«å……è‡³é•¿åº¦ `max_len=5`ã€‚æœ€ç»ˆè¡¨ç¤ºçš„ç»´åº¦ä¸º `(2, max_len, 50)`ï¼Œå› ä¸ºä½¿ç”¨çš„è¯å‘é‡ä¸º 50 ç»´ã€‚</center></caption>\n",
    "\n",
    "è¾“å…¥ä¸­çš„æœ€å¤§æ•´æ•°ï¼ˆå³å•è¯ç´¢å¼•ï¼‰ä¸åº”å¤§äºè¯æ±‡è¡¨å¤§å°ã€‚  \n",
    "è¯¥å±‚è¾“å‡ºå½¢çŠ¶ä¸º **(batch size, max input length, è¯å‘é‡ç»´åº¦)**ã€‚\n",
    "\n",
    "ç¬¬ä¸€æ­¥æ˜¯å°†æ‰€æœ‰è®­ç»ƒå¥å­è½¬æ¢ä¸ºç´¢å¼•åˆ—è¡¨ï¼Œç„¶åå¯¹è¿™äº›åˆ—è¡¨è¿›è¡Œ **é›¶å¡«å……ï¼ˆzero-paddingï¼‰**ï¼Œä½¿å…¶é•¿åº¦ç­‰äºæœ€é•¿å¥å­çš„é•¿åº¦ã€‚\n",
    "\n",
    "å®ç°ä¸‹åˆ—å‡½æ•°ï¼Œå°† **X**ï¼ˆå¥å­æ•°ç»„ï¼Œå­—ç¬¦ä¸²å½¢å¼ï¼‰è½¬æ¢ä¸ºå¯¹åº”å•è¯ç´¢å¼•çš„æ•°ç»„ã€‚  \n",
    "è¾“å‡ºå½¢çŠ¶åº”é€‚ç”¨äº `Embedding()` å±‚ï¼ˆå¦‚å›¾ 4 æ‰€ç¤ºï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# å‡½æ•°ï¼šsentences_to_indices\n",
    "# ----------------------------\n",
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    åŠŸèƒ½ï¼š\n",
    "        å°†æ–‡æœ¬å¥å­è½¬æ¢ä¸ºç´¢å¼•çŸ©é˜µï¼Œæ¯ä¸ªå•è¯ç”¨è¯è¡¨ä¸­çš„ç´¢å¼•è¡¨ç¤ºã€‚\n",
    "        ç”¨äºå°†æ–‡æœ¬æ•°æ®è¾“å…¥åˆ°ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ˆå¦‚ Embedding å±‚ï¼‰ä¸­ã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        X           -- è¾“å…¥å¥å­åˆ—è¡¨ï¼Œé•¿åº¦ä¸º mï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ˆå¥å­ï¼‰\n",
    "        word_to_index -- å­—å…¸ï¼Œå°†å•è¯æ˜ å°„ä¸ºç´¢å¼•ã€‚ä¾‹å¦‚ {'i':1, 'love':2, ...}\n",
    "        max_len     -- æ¯ä¸ªå¥å­çš„æœ€å¤§é•¿åº¦ï¼Œè¶…è¿‡çš„å•è¯æˆªæ–­ï¼Œä¸è¶³çš„å¥å­è¡¥ 0\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "        X_indices   -- numpy æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (m, max_len)ï¼Œæ¯è¡Œæ˜¯å¥å­å¯¹åº”çš„å•è¯ç´¢å¼•\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1. è·å–å¥å­æ•°é‡ m\n",
    "    # ----------------------------\n",
    "    m = len(X)  # len(X) è¿”å›å¥å­æ€»æ•°\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2. åˆå§‹åŒ–ç´¢å¼•çŸ©é˜µ X_indices\n",
    "    # ----------------------------\n",
    "    X_indices = np.zeros((m, max_len))  \n",
    "    # ä½¿ç”¨å…¨ 0 åˆå§‹åŒ–\n",
    "    # shape: (å¥å­æ•°é‡ m, æ¯å¥æœ€å¤§é•¿åº¦ max_len)\n",
    "    # å¦‚æœå¥å­é•¿åº¦ä¸è¶³ max_lenï¼Œè‡ªåŠ¨è¡¥ 0\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3. éå†æ¯ä¸ªå¥å­\n",
    "    # ----------------------------\n",
    "    for i, sentence in enumerate(X):  # enumerate è¿”å›ç´¢å¼• i å’Œå¥å­å†…å®¹ sentence\n",
    "        words = sentence.lower().split()  # å°†å¥å­å°å†™å¹¶æ‹†åˆ†ä¸ºå•è¯åˆ—è¡¨\n",
    "\n",
    "        # ----------------------------\n",
    "        # 4. éå†å¥å­ä¸­çš„å•è¯\n",
    "        # ----------------------------\n",
    "        for j, w in enumerate(words):  # j: å•è¯ä½ç½®, w: å•è¯\n",
    "            if j >= max_len:  # å¦‚æœå¥å­é•¿åº¦è¶…è¿‡ max_lenï¼Œåˆ™æˆªæ–­\n",
    "                break\n",
    "\n",
    "            # ä½¿ç”¨ word_to_index.get() è·å–å•è¯ç´¢å¼•\n",
    "            # å¦‚æœå•è¯ä¸åœ¨è¯è¡¨ä¸­ï¼Œè¿”å› 0\n",
    "            X_indices[i, j] = word_to_index.get(w, 0)\n",
    "\n",
    "    # ----------------------------\n",
    "    # 5. è¿”å›ç´¢å¼•çŸ©é˜µ\n",
    "    # ----------------------------\n",
    "    return X_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒï¼Œä»¥æŸ¥çœ‹ `sentences_to_indices()` çš„ä½œç”¨ï¼Œå¹¶æ£€æŸ¥ä½ çš„ç»“æœã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
      "X1_indices = [[155345. 225122.      0.      0.      0.]\n",
      " [220930. 286375.  69714.      0.      0.]\n",
      " [151204. 192973. 302254. 151349. 394475.]]\n"
     ]
    }
   ],
   "source": [
    "# è¾“å…¥å¥å­åˆ—è¡¨\n",
    "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
    "\n",
    "# è°ƒç”¨ sentences_to_indices å‡½æ•°ï¼Œå°†å¥å­è½¬æˆç´¢å¼•çŸ©é˜µ\n",
    "X1_indices = sentences_to_indices(X1, word_to_index, max_len=5)\n",
    "\n",
    "# è¾“å‡ºå¥å­å’Œå¯¹åº”çš„ç´¢å¼•çŸ©é˜µ\n",
    "print(\"X1 =\", X1)\n",
    "print(\"X1_indices =\", X1_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **X1 =**\n",
    "        </td>\n",
    "        <td>\n",
    "           ['funny lol' 'lets play football' 'food is ready for you']\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **X1_indices =**\n",
    "        </td>\n",
    "        <td>\n",
    "           [[ 155345.  225122.       0.       0.       0.] <br>\n",
    "            [ 220930.  286375.  151266.       0.       0.] <br>\n",
    "            [ 151204.  192973.  302254.  151349.  394475.]]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬åœ¨ **PyTorch** ä¸­æ„å»º `nn.Embedding` å±‚ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„è¯å‘é‡ã€‚  \n",
    "åœ¨æ„å»ºå¥½è¯¥å±‚åï¼Œä½ å°†æŠŠ `sentences_to_indices()` çš„è¾“å‡ºä½œä¸ºè¾“å…¥ä¼ å…¥ï¼ŒEmbedding å±‚å°†è¿”å›å¥å­çš„è¯å‘é‡è¡¨ç¤ºã€‚\n",
    "\n",
    "å®ç° `pretrained_embedding_layer()` çš„æ­¥éª¤å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. åˆå§‹åŒ–åµŒå…¥çŸ©é˜µä¸ºå…¨é›¶çš„ numpy æ•°ç»„ï¼Œå½¢çŠ¶ä¸º `(vocab_len, embedding_dim)`ã€‚  \n",
    "2. éå† `word_to_vec_map`ï¼Œå°†æ¯ä¸ªè¯å¯¹åº”çš„ GloVe å‘é‡å¡«å…¥åµŒå…¥çŸ©é˜µçš„æ­£ç¡®è¡Œã€‚  \n",
    "3. å®šä¹‰ PyTorch çš„ `nn.Embedding` å±‚ï¼Œå¹¶ä½¿ç”¨ `nn.Embedding.from_pretrained()` å°†åµŒå…¥çŸ©é˜µåŠ è½½è¿›å»ï¼š  \n",
    "   - è®¾ç½® `freeze=True`ï¼Œä¿è¯è¯å‘é‡åœ¨è®­ç»ƒä¸­ä¿æŒå›ºå®šã€‚  \n",
    "   - è‹¥è®¾ç½® `freeze=False`ï¼Œè®­ç»ƒæ—¶åµŒå…¥å‘é‡ä¼šè¢«æ›´æ–°ã€‚  \n",
    "4. è¿”å›æ„å»ºå¥½çš„ Embedding å±‚ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    åŠŸèƒ½ï¼š\n",
    "        åˆ›å»ºä¸€ä¸ª PyTorch çš„ Embedding å±‚ï¼Œå¹¶ç”¨é¢„è®­ç»ƒçš„è¯å‘é‡ï¼ˆå¦‚ GloVeï¼‰åˆå§‹åŒ–ã€‚\n",
    "        è¯¥å±‚å¯ä»¥ç›´æ¥ç”¨äºç¥ç»ç½‘ç»œè¾“å…¥ï¼Œå°†å•è¯ç´¢å¼•æ˜ å°„ä¸ºè¯å‘é‡ã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        word_to_vec_map (dict): å­—å…¸ï¼Œå°†æ¯ä¸ªå•è¯æ˜ å°„åˆ°å…¶é¢„è®­ç»ƒè¯å‘é‡ï¼Œä¾‹å¦‚ GloVe\n",
    "                                 æ ¼å¼: {'word': np.array([50ç»´å‘é‡])}\n",
    "        word_to_index (dict): å­—å…¸ï¼Œå°†æ¯ä¸ªå•è¯æ˜ å°„åˆ°å”¯ä¸€ç´¢å¼•\n",
    "                              æ ¼å¼: {'word': index}\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "        embedding_layer (nn.Embedding): PyTorch Embedding å±‚ï¼Œæƒé‡å·²ç»ç”¨é¢„è®­ç»ƒè¯å‘é‡åˆå§‹åŒ–\n",
    "                                        å¹¶ä¸”å‚æ•°å†»ç»“ (freeze=True)ï¼Œä¸å¯è®­ç»ƒ\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1. è·å–è¯æ±‡è¡¨é•¿åº¦ + 1\n",
    "    # ----------------------------\n",
    "    # vocab_len: è¯æ±‡è¡¨å¤§å° + 1ï¼Œå› ä¸ºç´¢å¼•é€šå¸¸ä»1å¼€å§‹ï¼Œ0ä¿ç•™ç»™padding\n",
    "    vocab_len = len(word_to_index) + 1\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2. è·å–è¯å‘é‡ç»´åº¦\n",
    "    # ----------------------------\n",
    "    # emb_dim: è¯å‘é‡çš„ç»´åº¦ï¼Œä¾‹å¦‚ GloVe 50ç»´ã€100ç»´ç­‰\n",
    "    emb_dim = list(word_to_vec_map.values())[0].shape[0]\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3. åˆå§‹åŒ–è¯å‘é‡çŸ©é˜µ\n",
    "    # ----------------------------\n",
    "    # emb_matrix: å½¢çŠ¶ä¸º (vocab_len, emb_dim)\n",
    "    # ç¬¬ i è¡Œå­˜å‚¨ç´¢å¼• i å¯¹åº”çš„è¯å‘é‡\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "\n",
    "    # ----------------------------\n",
    "    # 4. å°†é¢„è®­ç»ƒè¯å‘é‡å¡«å…¥çŸ©é˜µ\n",
    "    # ----------------------------\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]  # ç¬¬ idx è¡Œå°±æ˜¯ word çš„è¯å‘é‡\n",
    "\n",
    "    # ----------------------------\n",
    "    # 5. è½¬ä¸º PyTorch å¼ é‡\n",
    "    # ----------------------------\n",
    "    emb_matrix = torch.tensor(emb_matrix, dtype=torch.float32)\n",
    "\n",
    "    # ----------------------------\n",
    "    # 6. åˆ›å»º PyTorch Embedding å±‚\n",
    "    # ----------------------------\n",
    "    # from_pretrained: ç”¨ç»™å®šæƒé‡åˆå§‹åŒ– Embedding\n",
    "    # freeze=True: å†»ç»“æƒé‡ï¼Œä¸åœ¨è®­ç»ƒä¸­æ›´æ–°\n",
    "    embedding_layer = nn.Embedding.from_pretrained(emb_matrix, freeze=True)\n",
    "\n",
    "    return embedding_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights[0][1][3] = -0.3403\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 1. åˆ›å»ºé¢„è®­ç»ƒåµŒå…¥å±‚\n",
    "# ----------------------------\n",
    "# è°ƒç”¨ä¹‹å‰å®šä¹‰çš„å‡½æ•°ï¼Œç”¨ GloVe è¯å‘é‡åˆå§‹åŒ– Embedding å±‚\n",
    "# embedding_layer: nn.Embedding ç±»å‹ï¼Œæƒé‡å·²å†»ç»“\n",
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. è®¿é—®åµŒå…¥çŸ©é˜µæƒé‡\n",
    "# ----------------------------\n",
    "# embedding_layer.weight è¿”å› Embedding å±‚çš„æƒé‡å¼ é‡\n",
    "# detach(): å°†å¼ é‡ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»ï¼Œä¸è¿½è¸ªæ¢¯åº¦\n",
    "# numpy(): è½¬ä¸º NumPy æ•°ç»„ï¼Œæ–¹ä¾¿ç´¢å¼•æˆ–æ‰“å°\n",
    "weights = embedding_layer.weight.detach().numpy()  # å½¢çŠ¶: (vocab_len, emb_dim)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. æ‰“å°æŒ‡å®šç´¢å¼•çš„è¯å‘é‡å…ƒç´ \n",
    "# ----------------------------\n",
    "# ä¾‹å¦‚ï¼šweights[1][3]\n",
    "# - weights[1] è¡¨ç¤ºè¯æ±‡è¡¨ç´¢å¼•ä¸º 1 çš„å•è¯çš„è¯å‘é‡\n",
    "# - weights[1][3] è¡¨ç¤ºè¯¥è¯å‘é‡çš„ç¬¬ 4 ä¸ªç»´åº¦çš„å€¼\n",
    "print(\"weights[0][1][3] =\", weights[1][3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **weights[0][1][3] =**\n",
    "        </td>\n",
    "        <td>\n",
    "           -0.3403\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 æ„å»º Emojifier-V2\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬æ„å»º **Emojifier-V2** æ¨¡å‹ã€‚  \n",
    "ä½ å°†ä½¿ç”¨ä¹‹å‰æ„å»ºçš„åµŒå…¥å±‚ï¼Œå¹¶å°†å…¶è¾“å‡ºä¼ å…¥ä¸¤å±‚ LSTM ç½‘ç»œï¼Œæœ€åé€šè¿‡å…¨è¿æ¥å±‚è¾“å‡º softmax æ¦‚ç‡ã€‚\n",
    "\n",
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center> **å›¾ 3**ï¼šEmojifier-V2ã€‚ä¸€ä¸ªä¸¤å±‚ LSTM åºåˆ—åˆ†ç±»å™¨ã€‚</center></caption>\n",
    "\n",
    "---\n",
    "\n",
    "åœ¨ PyTorch ä¸­ï¼Œæˆ‘ä»¬ç”¨ `nn.Module` æ„å»ºè¯¥æ¨¡å‹ï¼Œä¸»è¦ç»“æ„å¦‚ä¸‹ï¼š\n",
    "\n",
    "- **è¾“å…¥**ï¼šå¥å­ç´¢å¼•çŸ©é˜µï¼Œå½¢çŠ¶ä¸º `(batch_size, max_len)`  \n",
    "- **Embedding å±‚**ï¼šå°†æ¯ä¸ªå•è¯ç´¢å¼•æ˜ å°„ä¸ºå…¶ GloVe è¯å‘é‡ `(batch_size, max_len, emb_dim)`  \n",
    "- **LSTM å±‚ 1**ï¼šéšè—çŠ¶æ€å¤§å° 128ï¼Œè¿”å›æ•´åºåˆ— `(batch_size, max_len, 128)`  \n",
    "- **Dropout 1**ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæ¦‚ç‡ 0.5  \n",
    "- **LSTM å±‚ 2**ï¼šéšè—çŠ¶æ€å¤§å° 128ï¼Œåªè¿”å›æœ€åä¸€ä¸ªéšè—çŠ¶æ€ `(batch_size, 128)`  \n",
    "- **Dropout 2**ï¼šæ¦‚ç‡ 0.5  \n",
    "- **å…¨è¿æ¥å±‚**ï¼šè¾“å‡ºå¤§å°ä¸º `C=5`  \n",
    "- **Softmax æ¿€æ´»**ï¼šè¾“å‡ºæ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- 2. Emojify-V2 æ¨¡å‹ ---------------------------- #\n",
    "class EmojifyV2(nn.Module):\n",
    "    def __init__(self, max_len, word_to_vec_map, word_to_index, C=5):\n",
    "        super(EmojifyV2, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.embedding = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "        self.lstm1 = nn.LSTM(input_size=self.embedding.embedding_dim, hidden_size=128,\n",
    "                             batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.lstm2 = nn.LSTM(input_size=128, hidden_size=128,\n",
    "                             batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(128, C)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        emb = self.embedding(X.long())                 # (batch, max_len, emb_dim)\n",
    "        lstm_out1, _ = self.lstm1(emb)               # (batch, max_len, 128)\n",
    "        lstm_out1 = self.dropout1(lstm_out1)\n",
    "        lstm_out2, (h_n, _) = self.lstm2(lstm_out1) # h_n: (1, batch, 128)\n",
    "        lstm_out2 = self.dropout2(h_n[-1])          # (batch, 128)\n",
    "        out = self.fc(lstm_out2)                     # (batch, C)\n",
    "        return F.softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- 3. è®­ç»ƒå‡½æ•°ï¼ˆå¸¦è¿›åº¦æ˜¾ç¤ºï¼‰ ---------------------------- #\n",
    "from tqdm import tqdm   # ç”¨äºè¿›åº¦æ¡æ˜¾ç¤º\n",
    "\n",
    "def train(model, X_train_indices, Y_train_oh, num_epochs=50, batch_size=32, lr=0.001):\n",
    "    \"\"\"\n",
    "    æ¨¡å‹è®­ç»ƒå‡½æ•°ï¼ˆå¸¦éšæœºç§å­å›ºå®šä¸è¿›åº¦æ˜¾ç¤ºï¼‰\n",
    "    å‚æ•°è¯´æ˜ï¼š\n",
    "    - model: PyTorch æ¨¡å‹\n",
    "    - X_train_indices: è®­ç»ƒé›†è¾“å…¥ç´¢å¼•ï¼ˆnumpy æ•°ç»„ï¼‰\n",
    "    - Y_train_oh: è®­ç»ƒé›†æ ‡ç­¾çš„ one-hot ç¼–ç \n",
    "    - num_epochs: è®­ç»ƒè½®æ•°\n",
    "    - batch_size: æ¯æ‰¹æ ·æœ¬æ•°\n",
    "    - lr: å­¦ä¹ ç‡\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # å°† numpy æ•°æ®è½¬ä¸º TensorDataset\n",
    "    dataset = torch.utils.data.TensorDataset(\n",
    "        torch.tensor(X_train_indices, dtype=torch.long),\n",
    "        torch.tensor(np.argmax(Y_train_oh, axis=1), dtype=torch.long)\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # tqdm è¿›åº¦æ¡æ˜¾ç¤º\n",
    "        pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        for X_batch, Y_batch in pbar:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "\n",
    "            # å‰å‘ä¼ æ’­\n",
    "            out = model(X_batch)\n",
    "            loss = criterion(out, Y_batch)\n",
    "\n",
    "            # åå‘ä¼ æ’­\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # ç´¯åŠ  loss ä¸æ­£ç¡®é¢„æµ‹æ•°\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(out, dim=1)\n",
    "            correct += (preds == Y_batch).sum().item()\n",
    "            total += Y_batch.size(0)\n",
    "\n",
    "            # tqdm å®æ—¶æ˜¾ç¤º\n",
    "            pbar.set_postfix({\n",
    "                \"loss\": f\"{loss.item():.4f}\",\n",
    "                \"acc\": f\"{(correct / total):.4f}\"\n",
    "            })\n",
    "\n",
    "        # æ¯ä¸ª epoch æ‰“å°æ±‡æ€»\n",
    "        avg_loss = total_loss / len(loader)\n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"{len(loader)}/{len(loader)} [==============================] - loss: {avg_loss:.4f} - acc: {acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test_indices, Y_test_oh):\n",
    "    model.eval()\n",
    "    X_test_tensor = torch.tensor(X_test_indices, dtype=torch.long).to(device)\n",
    "    Y_test_tensor = torch.tensor(np.argmax(Y_test_oh, axis=1), dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_test_tensor)\n",
    "        pred_labels = torch.argmax(pred, dim=1)\n",
    "        acc = (pred_labels == Y_test_tensor).float().mean().item()\n",
    "    print(\"Test accuracy =\", acc)\n",
    "    return pred_labels.cpu().numpy()  # ğŸ‘ˆ è¿”å›é¢„æµ‹æ ‡ç­¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- 5. æ‰“å°é¢„æµ‹å‡½æ•° ---------------------------- #\n",
    "def print_predictions(model, X_test, X_test_indices, Y_test, label_to_emoji):\n",
    "    model.eval()\n",
    "    X_test_tensor = torch.tensor(X_test_indices, dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_test_tensor)\n",
    "        pred_labels = torch.argmax(pred, dim=1).cpu().numpy()\n",
    "\n",
    "    print(f\"é”™è¯¯ä¿¡æ¯å¦‚ä¸‹\")\n",
    "    for i in range(len(X_test)):\n",
    "        if pred_labels[i] != Y_test[i]:\n",
    "            print(f\"æ­£ç¡®è¡¨æƒ…ï¼š{label_to_emoji(Y_test[i])}   é¢„æµ‹ç»“æœï¼š {X_test[i]} {label_to_emoji(pred_labels[i]).strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- 6. å•å¥é¢„æµ‹ ---------------------------- #\n",
    "def predict_single_sentence(model, sentence, word_to_index, maxLen, label_to_emoji):\n",
    "    X_indices = sentences_to_indices(np.array([sentence]), word_to_index, maxLen)\n",
    "    model.eval()\n",
    "    X_tensor = torch.tensor(X_indices, dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_tensor)\n",
    "        pred_label = torch.argmax(pred, dim=1).item()\n",
    "    print(sentence + ' ' + label_to_emoji(pred_label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½ çš„ Emojifier-V2 **æ¨¡å‹**è¾“å…¥ä¸ºå½¢çŠ¶ (`m`, `max_len`) çš„æ•°ç»„ï¼Œè¾“å‡ºä¸ºå½¢çŠ¶ (`m`, ç±»åˆ«æ•°) çš„æ¦‚ç‡å‘é‡ã€‚  \n",
    "\n",
    "å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦åšä¸¤ä»¶äº‹ï¼š\n",
    "\n",
    "1. å°†è®­ç»ƒé›†å¥å­ä»å­—ç¬¦ä¸²å½¢å¼è½¬æ¢ä¸ºç´¢å¼•å½¢å¼ï¼Œæ–¹ä¾¿åµŒå…¥å±‚å¤„ç†ï¼š\n",
    "\n",
    "```python\n",
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "```\n",
    "\n",
    "2. å°†æ ‡ç­¾ä»æ•´æ•°ç´¢å¼•è½¬æ¢ä¸º one-hot ç¼–ç ï¼Œä»¥ä¾¿ç”¨äºäº¤å‰ç†µæŸå¤±ï¼š\n",
    "```python\n",
    "Y_train_oh = np.eye(C)[Y_train.reshape(-1)]\n",
    "Y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
    "```\n",
    "\n",
    "è¿™æ ·å¤„ç†åï¼š\n",
    "\n",
    "- X_train_indices å’Œ X_test_indices çš„å½¢çŠ¶ä¸º (æ ·æœ¬æ•°, max_len)ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯å¯¹åº”å•è¯çš„ç´¢å¼•\n",
    "\n",
    "- Y_train_oh å’Œ Y_test_oh çš„å½¢çŠ¶ä¸º (æ ·æœ¬æ•°, C)ï¼Œæ¯è¡Œæ˜¯æ ‡ç­¾çš„ one-hot ç¼–ç \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡è®¾ X_train, Y_train, X_test, Y_test, word_to_index, word_to_vec_map å·²å®šä¹‰\n",
    "C = 5\n",
    "\n",
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "Y_train_oh = np.eye(C)[Y_train.reshape(-1)]\n",
    "Y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒä»¥åˆ›å»ºæ¨¡å‹å¹¶æŸ¥çœ‹å…¶æ‘˜è¦ã€‚  \n",
    "ç”±äºæ•°æ®é›†ä¸­æ‰€æœ‰å¥å­é•¿åº¦éƒ½å°äº 10 ä¸ªå•è¯ï¼Œæˆ‘ä»¬é€‰æ‹© `max_len = 10`ã€‚  \n",
    "\n",
    "ä½ åº”è¯¥å¯ä»¥çœ‹åˆ°æ¨¡å‹æ¶æ„ï¼Œå®ƒä½¿ç”¨äº† **20,224,951** ä¸ªå‚æ•°ï¼Œå…¶ä¸­ **20,000,050**ï¼ˆè¯å‘é‡éƒ¨åˆ†ï¼‰ä¸ºä¸å¯è®­ç»ƒï¼Œå…¶ä½™ **224,901** ä¸ªä¸ºå¯è®­ç»ƒå‚æ•°ã€‚  \n",
    "ç”±äºæˆ‘ä»¬çš„è¯æ±‡è¡¨å¤§å°ä¸º 400,001 ä¸ªå•è¯ï¼ˆæœ‰æ•ˆç´¢å¼•ä» 0 åˆ° 400,000ï¼‰ï¼Œå› æ­¤ä¸å¯è®­ç»ƒå‚æ•°æ•°é‡ä¸º 400,001 Ã— 50 = 20,000,050ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = 10\n",
    "\n",
    "# 1. æ¨¡å‹å®ä¾‹\n",
    "model = EmojifyV2(maxLen, word_to_vec_map, word_to_index, C=C).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmojifyV2(\n",
      "  (embedding): Embedding(400001, 50)\n",
      "  (lstm1): LSTM(50, 128, batch_first=True)\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (lstm2): LSTM(128, 128, batch_first=True)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
      ")\n",
      "Total params: 20,224,951\n",
      "Trainable params: 224,901\n",
      "Non-trainable params: 20,000,050\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "\n",
    "# ç»Ÿè®¡å‚æ•°æ•°é‡\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "non_trainable_params = total_params - trainable_params\n",
    "\n",
    "print(f\"Total params: {total_params:,}\")\n",
    "print(f\"Trainable params: {trainable_params:,}\")\n",
    "print(f\"Non-trainable params: {non_trainable_params:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æ˜¯è®­ç»ƒæ¨¡å‹çš„æ—¶å€™äº†ã€‚  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨ **X_train_indices** å’Œ **Y_train_oh** ä¸Šè®­ç»ƒPytorchæ¨¡å‹ã€‚  \n",
    "è®­ç»ƒå‚æ•°è®¾ç½®ä¸ºï¼š\n",
    "- `epochs = 50`  \n",
    "- `batch_size = 32`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - loss: 0.9424 - acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "5/5 [==============================] - loss: 0.9921 - acc: 0.9470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "5/5 [==============================] - loss: 0.9614 - acc: 0.9318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "5/5 [==============================] - loss: 0.9547 - acc: 0.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "5/5 [==============================] - loss: 0.9540 - acc: 0.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "5/5 [==============================] - loss: 0.9870 - acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "5/5 [==============================] - loss: 0.9521 - acc: 0.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "5/5 [==============================] - loss: 0.9490 - acc: 0.9470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "5/5 [==============================] - loss: 0.9548 - acc: 0.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "5/5 [==============================] - loss: 0.9588 - acc: 0.9318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "5/5 [==============================] - loss: 0.9437 - acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "5/5 [==============================] - loss: 0.9428 - acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "5/5 [==============================] - loss: 0.9449 - acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "5/5 [==============================] - loss: 0.9503 - acc: 0.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "5/5 [==============================] - loss: 0.9425 - acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "5/5 [==============================] - loss: 0.9406 - acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "5/5 [==============================] - loss: 0.9631 - acc: 0.9318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "5/5 [==============================] - loss: 0.9589 - acc: 0.9318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "5/5 [==============================] - loss: 1.0131 - acc: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "5/5 [==============================] - loss: 1.0326 - acc: 0.8409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "5/5 [==============================] - loss: 1.0103 - acc: 0.9242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "5/5 [==============================] - loss: 0.9598 - acc: 0.9318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "5/5 [==============================] - loss: 0.9759 - acc: 0.9470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "5/5 [==============================] - loss: 0.9399 - acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "5/5 [==============================] - loss: 1.0152 - acc: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "5/5 [==============================] - loss: 1.0785 - acc: 0.7803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "5/5 [==============================] - loss: 1.1000 - acc: 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "5/5 [==============================] - loss: 1.1426 - acc: 0.7576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "5/5 [==============================] - loss: 1.0774 - acc: 0.8030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "5/5 [==============================] - loss: 1.0070 - acc: 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "5/5 [==============================] - loss: 1.0746 - acc: 0.7879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "5/5 [==============================] - loss: 1.0012 - acc: 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "5/5 [==============================] - loss: 0.9969 - acc: 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "5/5 [==============================] - loss: 1.0534 - acc: 0.8712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "5/5 [==============================] - loss: 1.0328 - acc: 0.8939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "5/5 [==============================] - loss: 0.9904 - acc: 0.8939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "5/5 [==============================] - loss: 0.9977 - acc: 0.8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "5/5 [==============================] - loss: 1.0216 - acc: 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "5/5 [==============================] - loss: 1.0024 - acc: 0.9318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "5/5 [==============================] - loss: 0.9531 - acc: 0.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "5/5 [==============================] - loss: 0.9438 - acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "5/5 [==============================] - loss: 0.9424 - acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "5/5 [==============================] - loss: 0.9423 - acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "5/5 [==============================] - loss: 0.9425 - acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "5/5 [==============================] - loss: 0.9413 - acc: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "5/5 [==============================] - loss: 0.9367 - acc: 0.9621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50\n",
      "5/5 [==============================] - loss: 0.9365 - acc: 0.9621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "5/5 [==============================] - loss: 0.9363 - acc: 0.9621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "5/5 [==============================] - loss: 0.9365 - acc: 0.9621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "5/5 [==============================] - loss: 0.9365 - acc: 0.9621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# 2. è®­ç»ƒ\n",
    "train(model, X_train_indices, Y_train_oh, num_epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "æ¯æ¬¡è¿è¡Œå‡†ç¡®ç‡ä¼šæœ‰å·®å¼‚ã€‚  \n",
    "\n",
    "è¿è¡Œä»¥ä¸‹ä»£ç å•å…ƒï¼Œåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°ä½ çš„æ¨¡å‹è¡¨ç°ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.75\n"
     ]
    }
   ],
   "source": [
    "# 3. æµ‹è¯•è¯„ä¼°\n",
    "pred_labels = evaluate(model, X_test_indices, Y_test_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é”™è¯¯ä¿¡æ¯å¦‚ä¸‹\n",
      "æ­£ç¡®è¡¨æƒ…ï¼š:smile:   é¢„æµ‹ç»“æœï¼š he got a very nice raise\t â¤ï¸\n",
      "æ­£ç¡®è¡¨æƒ…ï¼š:smile:   é¢„æµ‹ç»“æœï¼š she got me a nice present\t â¤ï¸\n",
      "æ­£ç¡®è¡¨æƒ…ï¼š:smile:   é¢„æµ‹ç»“æœï¼š he is a good friend\t â¤ï¸\n",
      "æ­£ç¡®è¡¨æƒ…ï¼š:disappointed:   é¢„æµ‹ç»“æœï¼š This girl is messing with me\t â¤ï¸\n",
      "æ­£ç¡®è¡¨æƒ…ï¼šğŸ´   é¢„æµ‹ç»“æœï¼š any suggestions for dinner\t :smile:\n",
      "æ­£ç¡®è¡¨æƒ…ï¼šâ¤ï¸   é¢„æµ‹ç»“æœï¼š I love taking breaks\t :disappointed:\n",
      "æ­£ç¡®è¡¨æƒ…ï¼š:smile:   é¢„æµ‹ç»“æœï¼š you brighten my day\t â¤ï¸\n",
      "æ­£ç¡®è¡¨æƒ…ï¼š:disappointed:   é¢„æµ‹ç»“æœï¼š she is a bully\t â¤ï¸\n",
      "æ­£ç¡®è¡¨æƒ…ï¼š:disappointed:   é¢„æµ‹ç»“æœï¼š My life is so boring\t â¤ï¸\n",
      "æ­£ç¡®è¡¨æƒ…ï¼š:smile:   é¢„æµ‹ç»“æœï¼š will you be my valentine\t â¤ï¸\n",
      "æ­£ç¡®è¡¨æƒ…ï¼šâš¾   é¢„æµ‹ç»“æœï¼š he can pitch really well\t â¤ï¸\n",
      "æ­£ç¡®è¡¨æƒ…ï¼šğŸ´   é¢„æµ‹ç»“æœï¼š I am hungry :disappointed:\n",
      "æ­£ç¡®è¡¨æƒ…ï¼šâš¾   é¢„æµ‹ç»“æœï¼š I will  run â¤ï¸\n",
      "æ­£ç¡®è¡¨æƒ…ï¼šâ¤ï¸   é¢„æµ‹ç»“æœï¼š I love you to the stars and back\t âš¾\n"
     ]
    }
   ],
   "source": [
    "# 4. æ‰“å°æ¯ä¸ªæµ‹è¯•æ ·æœ¬é¢„æµ‹ç»“æœï¼ˆè¯¾ç¨‹é£æ ¼ï¼‰\n",
    "print_predictions(model, X_test, X_test_indices, Y_test, label_to_emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "è¿è¡Œä¸‹æ–¹ä»£ç å•å…ƒï¼ŒæŸ¥çœ‹è¢«é”™è¯¯æ ‡æ³¨çš„ç¤ºä¾‹ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨ä½ å¯ä»¥åœ¨è‡ªå·±çš„ç¤ºä¾‹ä¸Šå°è¯•ã€‚  \n",
    "åœ¨ä¸‹é¢å†™ä¸‹ä½ è‡ªå·±çš„å¥å­ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are so beautiful :smile:\n"
     ]
    }
   ],
   "source": [
    "# 5. å•å¥é¢„æµ‹\n",
    "predict_single_sentence(model, \"you are so beautiful\", word_to_index, maxLen, label_to_emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¹‹å‰ï¼ŒEmojify-V1 æ¨¡å‹æ— æ³•æ­£ç¡®æ ‡æ³¨ \"*not feeling happy*\"ï¼Œä½†æˆ‘ä»¬å®ç°çš„ Emojifier-V2 èƒ½æ­£ç¡®è¯†åˆ«ã€‚ï¼ˆKeras çš„è¾“å‡ºæ¯æ¬¡ç•¥æœ‰éšæœºæ€§ï¼Œå› æ­¤ä½ å¯èƒ½æ²¡æœ‰å¾—åˆ°å®Œå…¨ç›¸åŒçš„ç»“æœã€‚ï¼‰  \n",
    "\n",
    "å½“å‰æ¨¡å‹åœ¨ç†è§£å¦å®šè¯ï¼ˆå¦‚ \"*not happy*\"ï¼‰æ–¹é¢ä»ä¸å¤Ÿç¨³å¥ï¼Œå› ä¸ºè®­ç»ƒé›†è¾ƒå°ï¼Œç¼ºå°‘å¦å®šå¥çš„ç¤ºä¾‹ã€‚  \n",
    "ä½†å¦‚æœè®­ç»ƒé›†æ›´å¤§ï¼ŒLSTM æ¨¡å‹åœ¨ç†è§£è¿™ç§å¤æ‚å¥å­æ–¹é¢å°†è¿œä¼˜äº Emojify-V1 æ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ­å–œï¼\n",
    "\n",
    "ä½ å·²ç»å®Œæˆäº†æœ¬ç¬”è®°æœ¬çš„å…¨éƒ¨å†…å®¹ï¼â¤ï¸â¤ï¸â¤ï¸\n",
    "\n",
    "<font color='blue'>\n",
    "\n",
    "**æœ¬æ¬¡å†…å®¹éœ€è¦è®°ä½çš„è¦ç‚¹ï¼ˆPyTorch ç‰ˆæœ¬ï¼‰**ï¼š\n",
    "\n",
    "- å¦‚æœä½ çš„ NLP ä»»åŠ¡è®­ç»ƒé›†è¾ƒå°ï¼Œä½¿ç”¨è¯å‘é‡ï¼ˆword embeddingsï¼‰å¯ä»¥æ˜¾è‘—æå‡ç®—æ³•æ•ˆæœã€‚è¯å‘é‡ä½¿æ¨¡å‹èƒ½å¤Ÿå¤„ç†æµ‹è¯•é›†ä¸­å¯èƒ½æœªå‡ºç°åœ¨è®­ç»ƒé›†ä¸­çš„å•è¯ã€‚  \n",
    "- åœ¨ PyTorch ä¸­è®­ç»ƒåºåˆ—æ¨¡å‹ï¼Œéœ€è¦æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š\n",
    "    - ä½¿ç”¨ mini-batch æ—¶ï¼Œéœ€è¦å¯¹åºåˆ—è¿›è¡Œå¡«å……ï¼ˆpaddingï¼‰ï¼Œç¡®ä¿ mini-batch ä¸­çš„æ‰€æœ‰æ ·æœ¬é•¿åº¦ç›¸åŒã€‚  \n",
    "    - `nn.Embedding` å±‚å¯ä»¥ç”¨é¢„è®­ç»ƒçš„è¯å‘é‡åˆå§‹åŒ–ï¼ˆ`nn.Embedding.from_pretrained()`ï¼‰ã€‚è¿™äº›è¯å‘é‡å¯ä»¥ä¿æŒå›ºå®šï¼ˆ`freeze=True`ï¼‰ï¼Œä¹Ÿå¯ä»¥åœ¨ä½ çš„æ•°æ®é›†ä¸Šè¿›ä¸€æ­¥è®­ç»ƒã€‚ä½†å¦‚æœæ ‡æ³¨æ•°æ®é›†å¾ˆå°ï¼Œé€šå¸¸ä¸å€¼å¾—è®­ç»ƒå¤§è§„æ¨¡é¢„è®­ç»ƒè¯å‘é‡ã€‚  \n",
    "    - `nn.LSTM` çš„å‚æ•° `batch_first=True` å¯ä¿è¯è¾“å…¥è¾“å‡ºå½¢çŠ¶ä¸º `(batch, seq_len, features)`ï¼Œè¿”å›å€¼ä¸­åŒ…å«éšè—çŠ¶æ€å’Œå•ä¸ªæ—¶é—´æ­¥è¾“å‡ºã€‚  \n",
    "    - å¯ä»¥åœ¨ `nn.LSTM` åä½¿ç”¨ `nn.Dropout` æ¥å¯¹ç½‘ç»œè¿›è¡Œæ­£åˆ™åŒ–ã€‚  \n",
    "    - å‰å‘ä¼ æ’­æ—¶ï¼Œé€šå¸¸åªå–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ä½œä¸ºæ•´ä¸ªåºåˆ—çš„è¡¨ç¤ºï¼Œå†ä¼ å…¥ `nn.Linear` è¾“å‡ºç±»åˆ«æ¦‚ç‡ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "æ­å–œä½ å®Œæˆäº†æœ¬æ¬¡ä½œä¸šå¹¶æˆåŠŸæ„å»ºäº†ä¸€ä¸ª Emojifierã€‚  \n",
    "å¸Œæœ›ä½ å¯¹è‡ªå·±åœ¨æœ¬ç¬”è®°æœ¬ä¸­çš„æˆæœæ„Ÿåˆ°æ»¡æ„ï¼\n",
    "\n",
    "# ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€ğŸ˜€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è‡´è°¢\n",
    "\n",
    "æ„Ÿè°¢ Alison Darcy å’Œ Woebot å›¢é˜Ÿã€‚  \n",
    "Woebot æ˜¯ä¸€ä¸ªå¯ä»¥éšæ—¶ä¸ä½ äº¤æµçš„èŠå¤©æœºå™¨äººæœ‹å‹ï¼Œå…¨å¤© 24 å°æ—¶åœ¨çº¿ã€‚  \n",
    "ä½œä¸º Woebot æŠ€æœ¯çš„ä¸€éƒ¨åˆ†ï¼Œå®ƒä½¿ç”¨è¯å‘é‡æ¥ç†è§£ä½ æ‰€è¯´å†…å®¹çš„æƒ…ç»ªã€‚  \n",
    "ä½ å¯ä»¥è®¿é—® [http://woebot.io](http://woebot.io) ä½“éªŒå®ƒã€‚\n",
    "\n",
    "<img src=\"images/woebot.png\" style=\"width:600px;height:300px;\">\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "RNnEs",
   "launcher_item_id": "acNYU"
  },
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
