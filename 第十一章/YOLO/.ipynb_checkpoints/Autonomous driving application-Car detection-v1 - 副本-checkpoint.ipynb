{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自动驾驶 - 汽车检测\r\n",
    "\r\n",
    "欢迎来到第三周的编程作业。你将学习如何使用非常强大的 YOLO 模型进行目标检测。本笔记本中的许多思想来自两篇 YOLO 论文：Redmon 等人, 2016 (https://arxiv.org/abs/1506.02640) 和 Redmon 与 Farhadi, 2016 (https://arxiv.org/abs/1612.08242)。\r\n",
    "\r\n",
    "**你将学到如何**：\r\n",
    "- 在汽车检测数据集上使用目标检测  \r\n",
    "- 处理边界框（bounding boxes）\r\n",
    "\r\n",
    "运行下面的单元格以加载在本次学习过程中将用到的软件包和依赖项！\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Conv2D\n",
    "from keras.models import load_model, Model\n",
    "from yolo_utils import read_classes, read_anchors, generate_colors, preprocess_image, draw_boxes, scale_boxes\n",
    "from yad2k.models.keras_yolo import yolo_head, yolo_boxes_to_corners, preprocess_true_boxes, yolo_loss, yolo_body\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**重要说明**：如你所见，我们将 Keras 的后端导入为 `K`。这意味着在本笔记本中使用 Keras 函数时，需要写作：`K.function(...)`。\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - 问题描述\r\n",
    "\r\n",
    "你正在开发一辆自动驾驶汽车。作为该项目的关键组成部分，你希望首先构建一个汽车检测系统。为了收集数据，你在汽车前引擎盖上安装了一台摄像头，它会在你驾驶时每隔几秒拍摄前方道路的照片。\r\n",
    "\r\n",
    "<center>\r\n",
    "<video width=\"400\" height=\"200\" src=\"nb_images/road_video_compressed2.mp4\" type=\"video/mp4\" controls>\r\n",
    "</video>\r\n",
    "</center>\r\n",
    "\r\n",
    "<caption><center> 汽车行驶过程中，从车载摄像头拍摄的照片。<br>特别感谢 [drive.ai](https://www.drive.ai/) 提供的数据集！Drive.ai 是一家为自动驾驶车辆提供“大脑”的公司。\r\n",
    "</center></caption>\r\n",
    "\r\n",
    "<img src=\"nb_images/driveai.png\" style=\"width:100px;height:100;\">\r\n",
    "\r\n",
    "你已将这些图片收集到一个文件夹中，并通过在每辆车上绘制边界框进行了标注。下面是一个边界框的示例。\r\n",
    "\r\n",
    "<img src=\"nb_images/box_label.png\" style=\"width:500px;height:250;\">\r\n",
    "<caption><center> <u> **图1** </u>: **边界框示例**<br> </center></caption>\r\n",
    "\r\n",
    "如果你希望 YOLO 识别 80 个类别，可以将类别标签 $c$ 表示为 1 到 80 的整数，或者表示为一个 80 维向量（80 个数字），其中一个分量为 1，其余为 0。视频课程中使用的是后一种表示方式；在本笔记本中，我们将根据具体步骤的便利性，使用这两种表示方式。\r\n",
    "\r\n",
    "在本练习中，你将学习 YOLO 的工作原理，然后将其应用于汽车检测。由于 YOLO 模型训练计算量非常大，我们将为你加载预训练权重以供使用。\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO（\"you only look once\"）是一种流行的算法，因为它在实现高精度的同时还能实时运行。该算法之所以称为“只看一次”，是因为它只需要对图像进行一次前向传播就能进行预测。经过非极大值抑制（non-max suppression）后，它会输出识别出的对象及其边界框。\r\n",
    "\r\n",
    "### 2.1 - 模型细节\r\n",
    "\r\n",
    "首先需要了解：\r\n",
    "- **输入** 是形状为 (m, 608, 608, 3) 的图像批次\r\n",
    "- **输出** 是一个包含边界框及识别类别的列表。每个边界框由 6 个数字表示 $(p_c, b_x, b_y, b_h, b_w, c)$，如上所述。如果将 $c$ 展开成 80 维向量，则每个边界框由 85 个数字表示。\r\n",
    "\r\n",
    "我们将使用 5 个 anchor 框。因此可以将 YOLO 架构理解为：IMAGE (m, 608, 608, 3) -> DEEP CNN -> ENCODING (m, 19, 19, 5, 85)。\r\n",
    "\r\n",
    "下面详细介绍这个编码表示的内容。\r\n",
    "\r\n",
    "<img src=\"nb_images/architecture.png\" style=\"width:700px;height:400;\">\r\n",
    "<caption><center> <u> **图2** </u>: **YOLO 编码架构**<br> </center></caption>\r\n",
    "\r\n",
    "如果一个物体的中心/中点落在某个网格单元内，那么该网格单元负责检测该物体。\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于我们使用了 5 个 anchor 框，因此每个 19 x 19 的网格单元会编码 5 个框的信息。Anchor 框仅由其宽度和高度定义。\r\n",
    "\r\n",
    "为了简化，我们将形状为 (19, 19, 5, 85) 编码的最后两个维度展平。因此，Deep CNN 的输出为 (19, 19, 425)。\r\n",
    "\r\n",
    "<img src=\"nb_images/flatten.png\" style=\"width:700px;height:400;\">\r\n",
    "<caption><center> <u> **图3** </u>: **展平最后两个维度**<br> </center></caption>\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，对于每个框（每个网格单元中的每个框），我们将计算以下元素级乘积，并提取该框包含某个类别的概率。\r\n",
    "\r\n",
    "<img src=\"nb_images/probability_extraction.png\" style=\"width:700px;height:400;\">\r\n",
    "<caption><center> <u> **图4** </u>: **找出每个框检测到的类别**<br> </center></caption>\r\n",
    "\r\n",
    "这是一种可视化 YOLO 在图像上预测的方法：\r\n",
    "- 对于每个 19x19 的网格单元，找到概率分数的最大值（在 5 个 anchor 框和不同类别之间取最大值）。\r\n",
    "- 根据该网格单元认为最可能的对象为该单元上色。\r\n",
    "\r\n",
    "得到的结果如下图：\r\n",
    "\r\n",
    "<img src=\"nb_images/proba_map.png\" style=\"width:300px;height:300;\">\r\n",
    "<caption><center> <u> **图5** </u>: 每个 19x19 网格单元根据其预测概率最大的类别着色。<br> </center></caption>\r\n",
    "\r\n",
    "注意，这种可视化并不是 YOLO 算法本身用于预测的核心部分；它只是可视化算法中间结果的一种方式。\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一种可视化 YOLO 输出的方法是绘制它输出的边界框（bounding boxes）。结果如下图所示：  \r\n",
    "\r\n",
    "<img src=\"nb_images/anchor_map.png\" style=\"width:200px;height:200;\">\r\n",
    "<caption><center> <u> **图6** </u>: 每个网格单元提供 5 个框。总计，模型仅通过一次看图（一次前向传播）就预测了 19x19x5 = 1805 个框！不同颜色表示不同类别。<br> </center></caption>\r\n",
    "\r\n",
    "在上图中，我们只绘制了模型分配高概率的框，但这仍然太多。你希望将算法的输出过滤为更少的检测对象。为此，你将使用非极大值抑制（Non-Max Suppression）。具体步骤如下：\r\n",
    "- 去掉低分数的框（即模型对该框检测某个类别信心不足）\r\n",
    "- 当多个框重叠并检测到相同对象时，只选择一个框。\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - 使用类别分数阈值过滤\r\n",
    "\r\n",
    "你将通过阈值进行第一次过滤。希望去掉任何类别“分数”低于选定阈值的框。\r\n",
    "\r\n",
    "模型给出了总共 19x19x5x85 个数，每个框由 85 个数表示。为了方便处理，将 (19,19,5,85)（或 (19,19,425)）张量重新整理为以下变量：\r\n",
    "- `box_confidence`：形状为 $(19 \\times 19, 5, 1)$ 的张量，包含每个网格单元 5 个预测框的 $p_c$（表示该框包含对象的置信概率）。\r\n",
    "- `boxes`：形状为 $(19 \\times 19, 5, 4)$ 的张量，包含每个网格单元 5 个框的 $(b_x, b_y, b_h, b_w)$。\r\n",
    "- `box_class_probs`：形状为 $(19 \\times 19, 5, 80)$ 的张量，包含每个网格单元 5 个框在 80 个类别上的检测概率 $(c_1, c_2, ... c_{80})$。\r\n",
    "\r\n",
    "**练习**：实现 `yolo_filter_boxes()`。\r\n",
    "1. 按照图 4 所述计算 box scores（框分数），可用以下代码帮助选择正确的操作符：\r\n",
    "```python\r\n",
    "a = np.random.randn(19*19, 5, 1)\r\n",
    "b = np.random.randn(19*19, 5, 80)\r\n",
    "c = a * b # c 的形状将为 (19*192. 对每个框，找到：\r\n",
    "    - 最大框分数对应的类别索引（[提示](https://keras.io/backend/#argmax)）（注意选择正确的轴，建议使用 axis=-1）\r\n",
    "    - 对应的最大框分数（[提示](https://keras.io/backend/#max)）（注意选择正确的轴，建议使用 axis=-1）\r\n",
    "\r\n",
    "3. 使用阈值创建 mask。例如：`([0.9, 0.3, 0.4, 0.5, 0.1] < 0.4)` 返回 `[False, True, False, False, True]`。mask 中为 True 的框是你想保留的。\r\n",
    "\r\n",
    "4. 使用 TensorFlow 将 mask 应用于 `box_class_scores`、`boxes` 和 `box_classes`，以过滤掉不需要的框。最终，你将只保留需要的框子集（[提示](https://www.tensorflow.org/api_docs/python/tf/boolean_mask)）。\r\n",
    "\r\n",
    "**提醒**：调用 Keras 函数时，请使用 `K.function(...)`。\r\n",
    "function(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: yolo_filter_boxes\n",
    "\n",
    "def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = .6):\n",
    "    \"\"\"Filters YOLO boxes by thresholding on object and class confidence.\n",
    "    \n",
    "    Arguments:\n",
    "    box_confidence -- tensor of shape (19, 19, 5, 1)\n",
    "    boxes -- tensor of shape (19, 19, 5, 4)\n",
    "    box_class_probs -- tensor of shape (19, 19, 5, 80)\n",
    "    threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box\n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (None,), containing the class probability score for selected boxes\n",
    "    boxes -- tensor of shape (None, 4), containing (b_x, b_y, b_h, b_w) coordinates of selected boxes\n",
    "    classes -- tensor of shape (None,), containing the index of the class detected by the selected boxes\n",
    "    \n",
    "    Note: \"None\" is here because you don't know the exact number of selected boxes, as it depends on the threshold. \n",
    "    For example, the actual output size of scores would be (10,) if there are 10 boxes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Compute box scores\n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 2: Find the box_classes thanks to the max box_scores, keep track of the corresponding score\n",
    "    ### START CODE HERE ### (≈ 2 lines)\n",
    "\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 3: Create a filtering mask based on \"box_class_scores\" by using \"threshold\". The mask should have the\n",
    "    # same dimension as box_class_scores, and be True for the boxes you want to keep (with probability >= threshold)\n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Step 4: Apply the mask to scores, boxes and classes\n",
    "    ### START CODE HERE ### (≈ 3 lines)\n",
    "\n",
    "\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as test_a:\n",
    "    box_confidence = tf.random_normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1)\n",
    "    boxes = tf.random_normal([19, 19, 5, 4], mean=1, stddev=4, seed = 1)\n",
    "    box_class_probs = tf.random_normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1)\n",
    "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = 0.5)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.shape))\n",
    "    print(\"classes.shape = \" + str(classes.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **scores[2]**\n",
    "        </td>\n",
    "        <td>\n",
    "           10.7506\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **boxes[2]**\n",
    "        </td>\n",
    "        <td>\n",
    "           [ 8.42653275  3.27136683 -0.5313437  -4.94137383]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "    <tr>\n",
    "        <td>\n",
    "            **classes[2]**\n",
    "        </td>\n",
    "        <td>\n",
    "           7\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **scores.shape**\n",
    "        </td>\n",
    "        <td>\n",
    "           (?,)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **boxes.shape**\n",
    "        </td>\n",
    "        <td>\n",
    "           (?, 4)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "    <tr>\n",
    "        <td>\n",
    "            **classes.shape**\n",
    "        </td>\n",
    "        <td>\n",
    "           (?,)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - 非极大值抑制（Non-max suppression, NMS） ###\r\n",
    "\r\n",
    "即使在对类别分数进行阈值过滤后，你仍然可能得到很多重叠的框。为了进一步筛选出正确的框，需要使用第二种方法：非极大值抑制（NMS）。\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "<img src=\"nb_images/non-max-suppression.png\" style=\"width:500px;height:400;\">\r\n",
    "<caption><center> <u> **Figure 7** </u>: 在这个例子中，模型预测了 3 辆车，但实际上这只是对同一辆车的 3 个预测。运行非极大值抑制（NMS）会从这 3 个框中只选择最准确（概率最高）的一个。 <br> </center></caption>\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非极大值抑制使用一个非常重要的函数，称为 **“交并比”（Intersection over Union, IoU）**。\r\n",
    "<img src=\"nb_images/iou.png\" style=\"width:500px;height:400;\">\r\n",
    "<caption><center> <u> **Figure 8** </u>: “交并比”的定义。 <br> </center></caption>\r\n",
    "\r\n",
    "**练习**：实现 `iou()` 函数。一些提示：\r\n",
    "- 在本练习中，我们用矩形的两个角（左上角和右下角）来定义一个框：(x1, y1, x2, y2)，而不是用中心点和高/宽。\r\n",
    "- 计算矩形面积时，需要用高度 (y2 - y1) 乘以宽度 (x2 - x1)。\r\n",
    "- 还需要找到两个框的交集坐标 (xi1, yi1, xi2, yi2)。记住：\r\n",
    "    - xi1 = 两个框的 x1 坐标的最大值\r\n",
    "    - yi1 = 两个框的 y1 坐标的最大值\r\n",
    "    - xi2 = 两个框的 x2 坐标的最小值\r\n",
    "    - yi2 = 两个框的 y2 坐标的最小值\r\n",
    "\r\n",
    "在此代码中，我们使用的坐标约定是：图像左上角为 (0,0)，右上角为 (1,0)，右下角为 (1,1)。\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: iou\n",
    "\n",
    "def iou(box1, box2):\n",
    "    \"\"\"Implement the intersection over union (IoU) between box1 and box2\n",
    "    \n",
    "    Arguments:\n",
    "    box1 -- first box, list object with coordinates (x1, y1, x2, y2)\n",
    "    box2 -- second box, list object with coordinates (x1, y1, x2, y2)\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the (y1, x1, y2, x2) coordinates of the intersection of box1 and box2. Calculate its Area.\n",
    "    ### START CODE HERE ### (≈ 5 lines)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### END CODE HERE ###    \n",
    "\n",
    "    # Calculate the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)\n",
    "    ### START CODE HERE ### (≈ 3 lines)\n",
    "\n",
    "    \n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # compute the IoU\n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1 = (2, 1, 4, 3)\n",
    "box2 = (1, 2, 3, 4) \n",
    "print(\"iou = \" + str(iou(box1, box2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **iou = **\n",
    "        </td>\n",
    "        <td>\n",
    "           0.14285714285714285\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在你已经可以实现非极大值抑制（Non-max Suppression, NMS）了。关键步骤如下：  \r\n",
    "1. 选择得分最高的框。  \r\n",
    "2. 计算它与所有其他框的重叠情况，并删除与它重叠超过 `iou_threshold` 的框。  \r\n",
    "3. 返回步骤 1，迭代，直到没有比当前选定框得分更低的框为止。  \r\n",
    "\r\n",
    "这样可以移除与选定框高度重叠的所有框，只保留“最佳”的框。\r\n",
    "\r\n",
    "**练习**：使用 TensorFlow 实现 `yolo_non_max_suppression()`。TensorFlow 提供了两个内置函数可用于实现非极大值抑制（因此实际上不需要使用你之前实现的 `iou()`）：\r\n",
    "- [tf.image.non_max_suppression()](https://www.tensorflow.org/api_docs/python/tf/image/non_max_suppression)  \r\n",
    "- [K.gather()](https://www.tensorflow.org/api_docs/python/tf/gather)  \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: yolo_non_max_suppression\n",
    "\n",
    "def yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5):\n",
    "    \"\"\"\n",
    "    Applies Non-max suppression (NMS) to set of boxes\n",
    "    \n",
    "    Arguments:\n",
    "    scores -- tensor of shape (None,), output of yolo_filter_boxes()\n",
    "    boxes -- tensor of shape (None, 4), output of yolo_filter_boxes() that have been scaled to the image size (see later)\n",
    "    classes -- tensor of shape (None,), output of yolo_filter_boxes()\n",
    "    max_boxes -- integer, maximum number of predicted boxes you'd like\n",
    "    iou_threshold -- real value, \"intersection over union\" threshold used for NMS filtering\n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (, None), predicted score for each box\n",
    "    boxes -- tensor of shape (4, None), predicted box coordinates\n",
    "    classes -- tensor of shape (, None), predicted class for each box\n",
    "    \n",
    "    Note: The \"None\" dimension of the output tensors has obviously to be less than max_boxes. Note also that this\n",
    "    function will transpose the shapes of scores, boxes, classes. This is made for convenience.\n",
    "    \"\"\"\n",
    "    \n",
    "    max_boxes_tensor = K.variable(max_boxes, dtype='int32')     # tensor to be used in tf.image.non_max_suppression()\n",
    "    K.get_session().run(tf.variables_initializer([max_boxes_tensor])) # initialize variable max_boxes_tensor\n",
    "    \n",
    "    # Use tf.image.non_max_suppression() to get the list of indices corresponding to boxes you keep\n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Use K.gather() to select only nms_indices from scores, boxes and classes\n",
    "    ### START CODE HERE ### (≈ 3 lines)\n",
    "\n",
    "    \n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as test_b:\n",
    "    scores = tf.random_normal([54,], mean=1, stddev=4, seed = 1)\n",
    "    boxes = tf.random_normal([54, 4], mean=1, stddev=4, seed = 1)\n",
    "    classes = tf.random_normal([54,], mean=1, stddev=4, seed = 1)\n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
    "    print(\"classes.shape = \" + str(classes.eval().shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **scores[2]**\n",
    "        </td>\n",
    "        <td>\n",
    "           6.9384\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **boxes[2]**\n",
    "        </td>\n",
    "        <td>\n",
    "           [-5.299932    3.13798141  4.45036697  0.95942086]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "    <tr>\n",
    "        <td>\n",
    "            **classes[2]**\n",
    "        </td>\n",
    "        <td>\n",
    "           -2.24527\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **scores.shape**\n",
    "        </td>\n",
    "        <td>\n",
    "           (10,)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **boxes.shape**\n",
    "        </td>\n",
    "        <td>\n",
    "           (10, 4)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "    <tr>\n",
    "        <td>\n",
    "            **classes.shape**\n",
    "        </td>\n",
    "        <td>\n",
    "           (10,)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 总结过滤步骤\r\n",
    "\r\n",
    "现在你需要实现一个函数，该函数接收深度卷积网络输出（19x19x5x85维的编码），并使用你刚实现的函数对所有预测框进行过滤。  \r\n",
    "\r\n",
    "**练习**：实现 `yolo_eval()`，它接收 YOLO 编码的输出，并通过得分阈值和非极大值抑制（NMS）来筛选框。  \r\n",
    "\r\n",
    "在实现时有一个细节需要注意：预测框有多种表示方式，例如通过框的两个角坐标，或者通过中点和宽高来表示。YOLO 在不同步骤会转换框的表示方式，提供了以下函数（已给出）：  \r\n",
    "\r\n",
    "```python\r\n",
    "boxes = yolo_boxes_to_corners(box_xy, box_w该函数将 YOLO 的框坐标 (x, y, w, h) 转换为角坐标 (x1, y1, x2, y2)，以便输入到 yolo_filter_boxes 中。ter_boxes`\n",
    "```python\n",
    "boxes = scale_boxes(boxes, image_sYOLO 的网络在 608x608 图像上训练。如果你在不同尺寸的图像上测试（例如车检测数据集是 720x1280 图像），这一步会对框进行缩放，使它们能够正确绘制在原始图像上。\n",
    "\n",
    "不必担心这两个函数的内部实现，我们会在调用 yolo_eval() 时展示如何使用它们。 called.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: yolo_eval\n",
    "\n",
    "def yolo_eval(yolo_outputs, image_shape = (720., 1280.), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n",
    "    \"\"\"\n",
    "    Converts the output of YOLO encoding (a lot of boxes) to your predicted boxes along with their scores, box coordinates and classes.\n",
    "    \n",
    "    Arguments:\n",
    "    yolo_outputs -- output of the encoding model (for image_shape of (608, 608, 3)), contains 4 tensors:\n",
    "                    box_confidence: tensor of shape (None, 19, 19, 5, 1)\n",
    "                    box_xy: tensor of shape (None, 19, 19, 5, 2)\n",
    "                    box_wh: tensor of shape (None, 19, 19, 5, 2)\n",
    "                    box_class_probs: tensor of shape (None, 19, 19, 5, 80)\n",
    "    image_shape -- tensor of shape (2,) containing the input shape, in this notebook we use (608., 608.) (has to be float32 dtype)\n",
    "    max_boxes -- integer, maximum number of predicted boxes you'd like\n",
    "    score_threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box\n",
    "    iou_threshold -- real value, \"intersection over union\" threshold used for NMS filtering\n",
    "    \n",
    "    Returns:\n",
    "    scores -- tensor of shape (None, ), predicted score for each box\n",
    "    boxes -- tensor of shape (None, 4), predicted box coordinates\n",
    "    classes -- tensor of shape (None,), predicted class for each box\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    # Retrieve outputs of the YOLO model (≈1 line)\n",
    "\n",
    "    \n",
    "    # Convert boxes to be ready for filtering functions \n",
    "\n",
    "    \n",
    "    # Use one of the functions you've implemented to perform Score-filtering with a threshold of score_threshold (≈1 line)\n",
    "\n",
    "    \n",
    "    # Scale boxes back to original image shape.\n",
    "\n",
    "    \n",
    "    # Use one of the functions you've implemented to perform Non-max suppression with a threshold of iou_threshold (≈1 line)\n",
    "\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as test_b:\n",
    "    yolo_outputs = (tf.random_normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random_normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1))\n",
    "    scores, boxes, classes = yolo_eval(yolo_outputs)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
    "    print(\"classes.shape = \" + str(classes.eval().shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **scores[2]**\n",
    "        </td>\n",
    "        <td>\n",
    "           138.791\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **boxes[2]**\n",
    "        </td>\n",
    "        <td>\n",
    "           [ 1292.32971191  -278.52166748  3876.98925781  -835.56494141]\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "    <tr>\n",
    "        <td>\n",
    "            **classes[2]**\n",
    "        </td>\n",
    "        <td>\n",
    "           54\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            **scores.shape**\n",
    "        </td>\n",
    "        <td>\n",
    "           (10,)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **boxes.shape**\n",
    "        </td>\n",
    "        <td>\n",
    "           (10, 4)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "    <tr>\n",
    "        <td>\n",
    "            **classes.shape**\n",
    "        </td>\n",
    "        <td>\n",
    "           (10,)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\r\n",
    "**YOLO 总结**：\r\n",
    "- 输入图像尺寸为 (608, 608, 3)\r\n",
    "- 输入图像经过卷积神经网络（CNN），输出为 (19,19,5,85) 维度的张量。\r\n",
    "- 将最后两个维度展开后，输出变为 (19, 19, 425) 的体积：\r\n",
    "    - 输入图像的每个 19x19 网格单元输出 425 个数。\r\n",
    "    - 425 = 5 x 85，因为每个单元预测 5 个框，对应 5 个锚框（anchor boxes），如课程中讲解。\r\n",
    "    - 85 = 5 + 80，其中 5 是 $(p_c, b_x, b_y, b_h, b_w)$ 五个值，80 是类别数。\r\n",
    "- 接着根据以下方式选择部分预测框：\r\n",
    "    - 分数阈值筛选（Score-thresholding）：丢弃预测某类概率低于阈值的框\r\n",
    "    - 非极大值抑制（Non-max suppression）：计算交并比（IoU），避免选择重叠框\r\n",
    "- 这样就得到 YOLO 的最终输出。\r\n",
    "</font>\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - 在图像上测试 YOLO 预训练模型\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，你将使用一个预训练模型，并在汽车检测数据集上进行测试。和往常一样，首先需要**创建一个会话以启动计算图**。运行下方单元格。\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - 定义类别、锚框（anchors）和图像形状\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回顾一下，我们希望检测 80 个类别，并使用 5 个锚框（anchor boxes）。我们已经将这 80 个类别和 5 个锚框的信息保存在两个文件中：“coco_classes.txt”和“yolo_anchors.txt”。接下来运行单元格，将这些信息加载到模型中。\r\n",
    "\r\n",
    "车检测数据集的原始图像是 720x1280，我们已经将其预处理为 608x608 的图像。\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = read_classes(\"model_data/coco_classes.txt\")\n",
    "anchors = read_anchors(\"model_data/yolo_anchors.txt\")\n",
    "image_shape = (720., 1280.)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - 加载预训练模型\r\n",
    "\r\n",
    "训练一个 YOLO 模型需要很长时间，并且需要一个相当大的、带有标注边界框的数据集来覆盖大量目标类别。这里，你将加载一个现有的预训练 Keras YOLO 模型，存储在文件 \"yolo.h5\" 中。（这些权重来自 YOLO 官方网站，并使用 Allan Zelener 编写的函数进行了转换。参考文献在本笔记本末尾给出。技术上来说，这些参数来自 \"YOLOv2\" 模型，但在本笔记本中我们为了简便，统称为 \"YOLO\"。）运行下面的单元格以从该文件加载模型。\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = load_model(\"model_data/yolo.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这将加载一个已训练 YOLO 模型的权重。下面给出了该模型所包含层的摘要。\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意**：在某些计算机上，你可能会看到来自 Keras 的警告信息。如果看到也不用担心——这是正常的。\r\n",
    "\r\n",
    "**提醒**：该模型会将预处理后的输入图像批次（形状为 (m, 608, 608, 3)）转换为形状为 (m, 19, 19, 5, 85) 的张量，如图 2 所示。\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - 将模型输出转换为可用的边界框张量\r\n",
    "\r\n",
    "`yolo_model` 的输出是一个形状为 (m, 19, 19, 5, 85) 的张量，需要经过一定的处理和转换才能使用。下面的单元格会为你完成这一步。\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你已经将 `yolo_outputs` 添加到计算图中。这组 4 个张量已经准备好，可以作为 `yolo_eval` 函数的输入使用。\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`yolo_outputs` 已经给出了 `yolo_model` 预测的所有边界框，并且格式正确。现在你可以进行筛选，只保留最优的框。接下来调用你之前实现的 `yolo_eval` 函数来完成这一步。\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, boxes, classes = yolo_eval(yolo_outputs, image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 - 在图像上运行图\r\n",
    "\r\n",
    "现在开始有趣的部分。你已经创建了一个 (`sess`) 图，其流程可以总结如下：\r\n",
    "\r\n",
    "1. <font color='purple'> yolo_model.input </font> 作为输入给 `yolo_model`，模型计算输出 <font color='purple'> yolo_model.output </font>  \r\n",
    "2. <font color='purple'> yolo_model.output </font> 经过 `yolo_head` 处理，得到 <font color='purple'> yolo_outputs </font>  \r\n",
    "3. <font color='purple'> yolo_outputs </font> 经过筛选函数 `yolo_eval`，输出预测结果：<font color='purple'> scores, boxes, classes </font>\r\n",
    "\r\n",
    "**练习**：实现 `predict()` 函数，用于在图像上测试 YOLO。  \r\n",
    "你需要运行 TensorFlow 会话来计算 `scores, boxes, classes`。\r\n",
    "\r\n",
    "下面的代码还会用到以下函数：\r\n",
    "```python\r\n",
    "image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608输出：\r\n",
    "- `image`：Python (PIL) 图像对象，用于绘制边界框（你不必使用它）  \r\n",
    "- `image_data`：numpy 数组表示的图像，这将作为 CNN 的输入\r\n",
    "\r\n",
    "**重要提示**：当模型使用 BatchNorm（如 YOLO）时，需要在 `feed_dict` 中额外传入占位符 `{K.learning_phase(): 0}`。\r\n",
    "g_phase(): 0}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sess, image_file):\n",
    "    \"\"\"\n",
    "    Runs the graph stored in \"sess\" to predict boxes for \"image_file\". Prints and plots the preditions.\n",
    "    \n",
    "    Arguments:\n",
    "    sess -- your tensorflow/Keras session containing the YOLO graph\n",
    "    image_file -- name of an image stored in the \"images\" folder.\n",
    "    \n",
    "    Returns:\n",
    "    out_scores -- tensor of shape (None, ), scores of the predicted boxes\n",
    "    out_boxes -- tensor of shape (None, 4), coordinates of the predicted boxes\n",
    "    out_classes -- tensor of shape (None, ), class index of the predicted boxes\n",
    "    \n",
    "    Note: \"None\" actually represents the number of predicted boxes, it varies between 0 and max_boxes. \n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess your image\n",
    "    image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608, 608))\n",
    "\n",
    "    # Run the session with the correct tensors and choose the correct placeholders in the feed_dict.\n",
    "    # You'll need to use feed_dict={yolo_model.input: ... , K.learning_phase(): 0})\n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Print predictions info\n",
    "    print('Found {} boxes for {}'.format(len(out_boxes), image_file))\n",
    "    # Generate colors for drawing bounding boxes.\n",
    "    colors = generate_colors(class_names)\n",
    "    # Draw bounding boxes on the image file\n",
    "    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)\n",
    "    # Save the predicted bounding box on the image\n",
    "    image.save(os.path.join(\"out\", image_file), quality=90)\n",
    "    # Display the results in the notebook\n",
    "    output_image = scipy.misc.imread(os.path.join(\"out\", image_file))\n",
    "    imshow(output_image)\n",
    "    \n",
    "    return out_scores, out_boxes, out_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell on the \"test.jpg\" image to verify that your function is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_scores, out_boxes, out_classes = predict(sess, \"test.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **Found 7 boxes for test.jpg**\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **car**\n",
    "        </td>\n",
    "        <td>\n",
    "           0.60 (925, 285) (1045, 374)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **car**\n",
    "        </td>\n",
    "        <td>\n",
    "           0.66 (706, 279) (786, 350)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **bus**\n",
    "        </td>\n",
    "        <td>\n",
    "           0.67 (5, 266) (220, 407)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **car**\n",
    "        </td>\n",
    "        <td>\n",
    "           0.70 (947, 324) (1280, 705)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **car**\n",
    "        </td>\n",
    "        <td>\n",
    "           0.74 (159, 303) (346, 440)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **car**\n",
    "        </td>\n",
    "        <td>\n",
    "           0.80 (761, 282) (942, 412)\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **car**\n",
    "        </td>\n",
    "        <td>\n",
    "           0.89 (367, 300) (745, 648)\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你刚刚运行的模型实际上可以检测 \"coco_classes.txt\" 中列出的 80 个不同类别。要在你自己的图像上测试模型：\r\n",
    "\r\n",
    "1. 点击笔记本上方的 “File”，然后选择 “Open” 进入 Coursera Hub。  \r\n",
    "2. 将你的图像添加到此 Jupyter Notebook 的目录中的 \"images\" 文件夹。  \r\n",
    "3. 在上面的代码单元中写入你的图像名称。  \r\n",
    "4. 运行代码，查看算法的输出！\r\n",
    "\r\n",
    "如果你将 session 放在循环中对所有图像运行，结果大概如下：\r\n",
    "\r\n",
    "<center>\r\n",
    "<video width=\"400\" height=\"200\" src=\"nb_images/pred_video_compressed2.mp4\" type=\"video/mp4\" controls>\r\n",
    "</video>\r\n",
    "</center>\r\n",
    "\r\n",
    "<caption><center>YOLO 模型对从硅谷路上摄像头拍摄的图像进行预测的结果 <br> 感谢 [drive.ai](https://www.drive.ai/) 提供数据集！</center></caption>\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "<font color='blue'>\r\n",
    "**你需要记住的要点**：\r\n",
    "- YOLO 是一个先进的目标检测模型，既快速又准确。\r\n",
    "- 它将输入图像通过 CNN，输出一个 19x19x5x85 的张量。\r\n",
    "- 这个编码可以看作一个网格，每个 19x19 的单元包含 5 个预测框的信息。\r\n",
    "- 通过非极大值抑制（Non-Max Suppression, NMS）过滤所有预测框。具体来说：\r\n",
    "    - 对检测类别的概率进行分数阈值筛选，只保留高概率的框；\r\n",
    "    - 对预测框的重叠部分进行交并比（IoU）阈值筛选，剔除重叠框。\r\n",
    "- 由于从随机初始化权重训练 YOLO 模型比较复杂，需要大量数据和计算，本练习中使用了预训练模型参数。如果你愿意，也可以尝试用自己的数据集微调 YOLO 模型，但这将是一个相当有挑战的任务。\r\n",
    "</font>\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**参考资料**：本笔记本中的内容主要来源于两篇 YOLO 论文。实现部分也参考了 Allan Zelener 的 GitHub 仓库，并使用了官方 YOLO 网站提供的预训练权重。  \r\n",
    "- Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi - [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640) (2015)  \r\n",
    "- Joseph Redmon, Ali Farhadi - [YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242) (2016)  \r\n",
    "- Allan Zelener - [YAD2K: Yet Another Darknet 2 Keras](https://github.com/allanzelener/YAD2K)  \r\n",
    "- 官方 YOLO 网站: [https://pjreddie.com/darknet/yolo/](https://pjreddie.com/darknet/yolo/)  \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**汽车检测数据集**：  \r\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />\r\n",
    "<span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">The Drive.ai Sample Dataset</span>（由 drive.ai 提供）依据 <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">知识共享署名 4.0 国际许可协议</a>许可。我们特别感谢 Brody Huval、Chih Hu 和 Rahul Patel 收集并提供了此数据集。\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "OMdut",
   "launcher_item_id": "bbBOL"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
