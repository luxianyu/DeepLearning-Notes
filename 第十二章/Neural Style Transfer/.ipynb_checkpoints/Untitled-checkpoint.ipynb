{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c86ba75-d9a5-41d2-9d2b-310ad8459dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 神经风格迁移 - PyTorch 实现（修复版）\n",
    "# =========================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# =========================================\n",
    "# 配置\n",
    "# =========================================\n",
    "class CONFIG:\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    IMG_SIZE = 512\n",
    "    OUTPUT_DIR = \"output\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# =========================================\n",
    "# 工具函数 (等价于 nst_utils)\n",
    "# =========================================\n",
    "def image_loader(path, imsize=CONFIG.IMG_SIZE):\n",
    "    loader = transforms.Compose([\n",
    "        transforms.Resize(imsize),\n",
    "        transforms.CenterCrop(imsize),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    img = loader(img).unsqueeze(0)  # [1,3,H,W]\n",
    "    return img.to(CONFIG.DEVICE, torch.float)\n",
    "\n",
    "def imshow(tensor, title=None):\n",
    "    img = tensor.cpu().clone().squeeze(0)\n",
    "    img = transforms.ToPILImage()(img)\n",
    "    plt.imshow(img)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def save_image(tensor, path):\n",
    "    img = tensor.clone().cpu().squeeze(0)\n",
    "    vutils.save_image(img, path)\n",
    "\n",
    "# =========================================\n",
    "# 模型准备\n",
    "# =========================================\n",
    "cnn = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).features.to(CONFIG.DEVICE).eval()\n",
    "\n",
    "# 禁用 inplace ReLU\n",
    "for module in cnn.modules():\n",
    "    if isinstance(module, nn.ReLU):\n",
    "        module.inplace = False\n",
    "\n",
    "# =========================================\n",
    "# 特征提取 & Gram 矩阵\n",
    "# =========================================\n",
    "def get_features(x, model, layers):\n",
    "    features = {}\n",
    "    cur = x\n",
    "    for name, layer in model._modules.items():\n",
    "        cur = layer(cur)\n",
    "        if name in layers:\n",
    "            features[name] = cur\n",
    "    return features\n",
    "\n",
    "def gram_of_feature(feat):\n",
    "    b, C, H, W = feat.shape\n",
    "    F = feat.view(C, H*W)\n",
    "    G = torch.mm(F, F.t())\n",
    "    return G, C, H, W\n",
    "\n",
    "# =========================================\n",
    "# 内容 & 风格层定义\n",
    "# =========================================\n",
    "STYLE_LAYER_IDS = ['0','5','10','19','28']\n",
    "CONTENT_LAYER_ID = '21'\n",
    "\n",
    "# =========================================\n",
    "# 损失函数\n",
    "# =========================================\n",
    "def compute_content_cost(a_C, a_G):\n",
    "    return torch.mean((a_C - a_G)**2)\n",
    "\n",
    "def style_loss_from_gram(G_target, G_current, C, H, W):\n",
    "    denom = 4.0 * (C**2) * (H*W)**2\n",
    "    return torch.sum((G_target - G_current)**2) / denom\n",
    "\n",
    "def total_cost(J_content, J_style, alpha=10, beta=40):\n",
    "    return alpha * J_content + beta * J_style\n",
    "\n",
    "# =========================================\n",
    "# 预处理 target\n",
    "# =========================================\n",
    "def prepare_targets(cnn, content_img, style_img):\n",
    "    needed = STYLE_LAYER_IDS + [CONTENT_LAYER_ID]\n",
    "    content_feats = get_features(content_img, cnn, needed)\n",
    "    style_feats = get_features(style_img, cnn, needed)\n",
    "\n",
    "    content_target = content_feats[CONTENT_LAYER_ID].detach().clone()\n",
    "\n",
    "    style_targets = {}\n",
    "    for lid in STYLE_LAYER_IDS:\n",
    "        G, C, H, W = gram_of_feature(style_feats[lid])\n",
    "        style_targets[lid] = {'G': G.detach().clone(), 'C': C, 'H': H, 'W': W}\n",
    "\n",
    "    return content_target, style_targets\n",
    "\n",
    "# =========================================\n",
    "# 风格迁移主函数\n",
    "# =========================================\n",
    "def run_style_transfer(cnn, content_img, style_img, input_img,\n",
    "                       num_steps=200, style_weight=40, content_weight=10):\n",
    "    for p in cnn.parameters():\n",
    "        p.requires_grad = False\n",
    "    cnn.eval()\n",
    "\n",
    "    content_target, style_targets = prepare_targets(cnn, content_img, style_img)\n",
    "\n",
    "    generated = input_img.clone().to(CONFIG.DEVICE)\n",
    "    generated.requires_grad_(True)\n",
    "\n",
    "    optimizer = optim.LBFGS([generated], max_iter=20)\n",
    "    run = [0]\n",
    "\n",
    "    while run[0] < num_steps:\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            gen_feats = get_features(generated, cnn, STYLE_LAYER_IDS + [CONTENT_LAYER_ID])\n",
    "\n",
    "            a_C = content_target\n",
    "            a_G = gen_feats[CONTENT_LAYER_ID]\n",
    "            J_content = compute_content_cost(a_C, a_G)\n",
    "\n",
    "            J_style = 0.0\n",
    "            for lid, coeff in zip(STYLE_LAYER_IDS, [0.2]*len(STYLE_LAYER_IDS)):\n",
    "                G_current, C, H, W = gram_of_feature(gen_feats[lid])\n",
    "                target = style_targets[lid]['G']\n",
    "                J_style += coeff * style_loss_from_gram(target, G_current, C, H, W)\n",
    "\n",
    "            J = total_cost(J_content, J_style, alpha=content_weight, beta=style_weight)\n",
    "            J.backward()\n",
    "\n",
    "            if run[0] % 20 == 0:\n",
    "                print(f\"Iteration {run[0]}:\")\n",
    "                print(f\"  Total loss: {J.item():.4f}, Content: {J_content.item():.4f}, Style: {J_style.item():.4f}\")\n",
    "                save_path = os.path.join(CONFIG.OUTPUT_DIR, f\"step_{run[0]}.png\")\n",
    "                save_image(generated.detach(), save_path)\n",
    "                print(f\"  Saved intermediate result to {save_path}\")\n",
    "\n",
    "            run[0] += 1\n",
    "            return J\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    return generated.detach()\n",
    "\n",
    "# =========================================\n",
    "# 主流程\n",
    "# =========================================\n",
    "content_img = image_loader(\"images/louvre.jpg\")\n",
    "style_img = image_loader(\"images/monet_800600.jpg\")\n",
    "generated_img = content_img.clone()\n",
    "\n",
    "output = run_style_transfer(cnn, content_img, style_img, generated_img, num_steps=200)\n",
    "\n",
    "imshow(output, title=\"Final Generated Image\")\n",
    "save_image(output, os.path.join(CONFIG.OUTPUT_DIR, \"final.png\"))\n",
    "print(\"最终结果已保存到 output/final.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
